{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus...\n",
      "Read 4 sentence pairs\n",
      "Trimmed to 4 sentence pairs\n",
      "Counting words...\n",
      "source vocab size = 17\n",
      "target vocab size = 13\n",
      "['pytorch is very clear to use.', '파이토치는 사용하기 매우 직관적이다.']\n",
      "[1000 - 20.0%] loss = 0.7416\n",
      "[2000 - 40.0%] loss = 0.1081\n",
      "[3000 - 60.0%] loss = 0.0338\n",
      "[4000 - 80.0%] loss = 0.0181\n",
      "[5000 - 100.0%] loss = 0.0122\n",
      "> i feel hungry.\n",
      "= 나는 배가 고프다.\n",
      "< 나는 배가 고프다. <EOS>\n",
      "\n",
      "> pytorch is very easy.\n",
      "= 파이토치는 매우 쉽다.\n",
      "< 파이토치는 매우 쉽다. <EOS>\n",
      "\n",
      "> pytorch is a framework for deep learning.\n",
      "= 파이토치는 딥러닝을 위한 프레임워크이다.\n",
      "< 파이토치는 딥러닝을 위한 프레임워크이다. <EOS>\n",
      "\n",
      "> pytorch is very clear to use.\n",
      "= 파이토치는 사용하기 매우 직관적이다.\n",
      "< 파이토치는 사용하기 매우 직관적이다. <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main reference\n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "raw = [\"I feel hungry.\t나는 배가 고프다.\",\n",
    "       \"Pytorch is very easy.\t파이토치는 매우 쉽다.\",\n",
    "       \"Pytorch is a framework for deep learning.\t파이토치는 딥러닝을 위한 프레임워크이다.\",\n",
    "       \"Pytorch is very clear to use.\t파이토치는 사용하기 매우 직관적이다.\"]\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.vocab2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token}\n",
    "        self.index2vocab = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n",
    "        self.vocab_count = {}\n",
    "        self.n_vocab = len(self.vocab2index)\n",
    "\n",
    "    def add_vocab(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in self.vocab2index:\n",
    "                self.vocab2index[word] = self.n_vocab\n",
    "                self.vocab_count[word] = 1\n",
    "                self.index2vocab[self.n_vocab] = word\n",
    "                self.n_vocab += 1\n",
    "            else:\n",
    "                self.vocab_count[word] += 1                         #word가 vocab_count에 있으면 value를 +1\n",
    "\n",
    "\n",
    "def filter_pair(pair, source_max_length, target_max_length):        # pair는 문장.\n",
    "    return len(pair[0].split(\" \")) < source_max_length and len(pair[1].split(\" \")) < target_max_length  #source_max_length보다 작은지 and target_max_length보다 작은지 확인\n",
    "\n",
    "\n",
    "def preprocess(corpus, source_max_length, target_max_length):\n",
    "    print(\"reading corpus...\")\n",
    "    pairs = []\n",
    "    for line in corpus:\n",
    "        pairs.append([s for s in line.strip().lower().split(\"\\t\")])                         #strip()은 양면의 공백제거. append하는 대상은 리스트다. 아래의 예시를 봐라.\n",
    "    print(\"Read {} sentence pairs\".format(len(pairs)))\n",
    "\n",
    "    pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]     # if True면ㅇㅇ.\n",
    "    print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n",
    "\n",
    "    source_vocab = Vocab()\n",
    "    target_vocab = Vocab()\n",
    "\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        source_vocab.add_vocab(pair[0])\n",
    "        target_vocab.add_vocab(pair[1])\n",
    "    print(\"source vocab size =\", source_vocab.n_vocab)\n",
    "    print(\"target vocab size =\", target_vocab.n_vocab)\n",
    "\n",
    "    return pairs, source_vocab, target_vocab\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)  # input_size는 source text를 이루는 corpus에서 사용되는 단어의 개수\n",
    "                                                                # hidden_size만큼 줄어들은 vector로 표현하는 matrix를 embedding이라 한다.  \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)             # 배치사이즈와 시퀀스는 자동으로 인식한다.\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x).view(1, 1, -1)                    #embedding의 결과의 shape을 바꾸는 거임. (1, 1, hidden_size)\n",
    "        x, hidden = self.gru(x, hidden)\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)                             \n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):#아래의 tensorize에서 들어가는 x의 형태 [\"I\", \"feel\", \"hungry\", \"<EOS>\"] → [1, 2, 3, 4] 인덱스 형태가 됨. 그러고는 view로 (4,1)이 됨.\n",
    "        x = self.embedding(x).view(1, 1, -1)           #1,1,hidden_size\n",
    "        x, hidden = self.gru(x, hidden)                 #gru의 출력은 1,1,hidden_size\n",
    "        x = self.softmax(self.out(x[0]))                #x[0]은 1,hiddensize를 넣는거임.\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "def tensorize(vocab, sentence):\n",
    "    indexes = [vocab.vocab2index[word] for word in sentence.split(\" \")]     #vocab.vocab2index라는 dictionary의 [word]에 해당하는 인덱스 추출.\n",
    "    indexes.append(vocab.vocab2index[\"<EOS>\"])\n",
    "    return torch.Tensor(indexes).long().to(device).view(-1, 1)\n",
    "#tensorize에서 들어가는 x의 형태 [\"I\", \"feel\", \"hungry\", \"<EOS>\"] → [1, 2, 3, 4] 인덱스 형태가 됨. 그러고는 view로 (4,1)이 됨\n",
    "\n",
    "\n",
    "def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every=1000, learning_rate=0.01):\n",
    "    loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_batch = [random.choice(pairs) for _ in range(n_iter)]          # n_iter만큼 문장을 넣음.\n",
    "    training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n",
    "    training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for i in range(1, n_iter + 1):\n",
    "        source_tensor = training_source[i - 1]                  # i=1부터이니.\n",
    "        target_tensor = training_target[i - 1]\n",
    "\n",
    "        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        source_length = source_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for enc_input in range(source_length):\n",
    "            _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # teacher forcing\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()        #순서는 딱히 상관없음.\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        loss_iter = loss.item() / target_length                 #문장마다 단어수가 다르기 때문에에\n",
    "        loss_total += loss_iter\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            loss_avg = loss_total / print_every\n",
    "            loss_total = 0\n",
    "            print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))\n",
    "\n",
    "\n",
    "def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, target_max_length):\n",
    "    for pair in pairs:\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        source_tensor = tensorize(source_vocab, pair[0])\n",
    "        source_length = source_tensor.size()[0]\n",
    "        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)            #\n",
    "\n",
    "        for ei in range(source_length):\n",
    "            _, encoder_hidden = encoder(source_tensor[ei], encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device).long()               #이미 존재하는 데이터를 tesor로 바꾸고 싶을 때 torch.tenseor()를 사용\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(target_max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            _, top_index = decoder_output.data.topk(1) #topk(k) 함수는 주어진 텐서에서 상위 k개의 값과 그에 대응하는 인덱스를 반환합니다. \n",
    "                                                       #여기서 k=1이므로 가장 큰 값 하나만을 반환\n",
    "                                                       #topk(1)의 결과로 반환되는 값은 두 가지입니다:\n",
    "                                                       #1. 가장 큰 값들 (topk()에서 얻은 값들)\n",
    "                                                       #2. 그 값들의 인덱스 (가장 큰 값들이 어디에 위치하는지)\n",
    "                                                       #참고로  top_index는 2D 텐서 (1,1)형태의 ㅇㅇ. ([[]])\n",
    "            if top_index.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(target_vocab.index2vocab[top_index.item()])\n",
    "\n",
    "            decoder_input = top_index.squeeze().detach()    #decoder_input을 top_index로 바꿈.\n",
    "                                                            \n",
    "                                                            #top_index는 (1,1)형태인데 squeeze() 함수는 텐서에서 차원이 1인 축을 제거. (1,)의 1D 텐서로 변경됨.\n",
    "                                                            #detach() method는 gradient의 전파를 멈추는 역할을 함.\n",
    "                                                            #PyTorch에서는 기본적으로 연산을 할 때마다 계산 그래프가 자동으로 추적됩니다. \n",
    "                                                            #그런데, 평가 단계에서는 기울기를 계산할 필요가 없기 때문에, 계산 그래프가 계속 추적되지 않도록 끊어\n",
    "                                                            #메모리 사용을 줄인다.\n",
    "\n",
    "                                                            # detach는 주어진 Tensor 객체에 대한 연산의 결과로 생성된 새로운 Tensor 객체가 있을 때, \n",
    "                                                            # 이 새로운 Tensor 객체를 사용하여 추가적인 계산을 수행하고자 할 때, \n",
    "                                                            # 기존 Tensor 객체의 연산 그래프와의 의존성을 제거하여 메모리 사용량을 줄이고 계산 속도를 향상시키는 데 유용\n",
    "\n",
    "                                                            \n",
    "\n",
    "        predict_words = decoded_words\n",
    "        predict_sentence = \" \".join(predict_words)\n",
    "        print(\"<\", predict_sentence)\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "SOURCE_MAX_LENGTH = 10\n",
    "TARGET_MAX_LENGTH = 12\n",
    "load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH, TARGET_MAX_LENGTH)\n",
    "print(random.choice(load_pairs))\n",
    "\n",
    "enc_hidden_size = 16\n",
    "dec_hidden_size = enc_hidden_size\n",
    "enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n",
    "dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)\n",
    "\n",
    "train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every=1000)\n",
    "evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) torch.Tensor와 torch.tensor의 차이\n",
    "\n",
    "https://velog.io/@minchoul2/torch.Tensor%EC%99%80-torch.tensor%EC%9D%98-%EC%B0%A8%EC%9D%B4\n",
    "\n",
    "torch.tensor\n",
    "\n",
    "int 입력시 int 그대로 입력\n",
    "입력받은 데이터를 새로운 메모리 공간에 복사해 Tensor 객체 생성 (call by value)\n",
    "torch.Tensor\n",
    "\n",
    "int 입력시 float으로 변환\n",
    "데이터 입력 시(Tensor 객체로) 입력 받은 메모리 공간을 그대로 사용 (call by reference)\n",
    "데이터 입력 시(list나 numpy 로) 입력 받은 값을 복사하여 Tensor 객체 생성(call by value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'in', 'sentence']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"word in sentence\"\n",
    "a.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i feel hungry.', '나는 배가 고프다.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I feel hungry.\t나는 배가 고프다.\".strip().lower().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2420263525.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    a.1\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "a.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
