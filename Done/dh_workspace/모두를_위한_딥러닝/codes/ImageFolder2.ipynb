{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=transforms.Compose([transforms.ToTensor()])   # transforms.Compose(): 여러 개의 이미지 변환(transform)을 하나로 묶어서 적용할 수 있도록 도와주는 함수 \n",
    "                                                    # 여러 개의 변환을 순차적으로 진행하기 때문에 []안에 넣는다.\n",
    "                                                    # transforms.ToTensor(): 이 변환을 적용하면 이미지를 [0, 1] 범위의 실수형 텐서로 변환\n",
    "train_data=torchvision.datasets.ImageFolder(root='./custom_data/train_data',transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=DataLoader(dataset=train_data, batch_size=8, shuffle=True, num_workers=2)   #num_workers는 돌아가는 cpu의 개수를 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(3,6,5),           # input_channel, output_channel, kernel_size순. stride는 기본값이 1임. padding 도 기본값이 0임.\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),            # MaxPool2d는 stride 설정을 안하면 kernel_size와 같다.\n",
    "        )\n",
    "\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(6,16,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.layer3=nn.Sequential(      # fully connected이다.\n",
    "            nn.Linear(16*13*29, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        #print(out.shape)                #크기가 헷갈리면 print로 출력을 해보는 것도 방법이다.\n",
    "        out=self.layer2(out)\n",
    "        #print(out.shape)\n",
    "        out=out.view(out.shape[0],-1)   # 펼친다. out=out.view(out.size(0),-1)로 바꿔도 된다.\n",
    "        #print(out.shape)\n",
    "        out=self.layer3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "net=CNN().to(device)\n",
    "test_input=(torch.Tensor(3,3,64,128)).to(device)\n",
    "test_out=net(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer & criterion\n",
    "optimizer=optim.Adam(net.parameters(), lr=0.00001)\n",
    "loss_func=nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] cost=0.6785112619400024\n",
      "[Epoch: 2] cost=0.6540599465370178\n",
      "[Epoch: 3] cost=0.6283811330795288\n",
      "[Epoch: 4] cost=0.5918824672698975\n",
      "[Epoch: 5] cost=0.5401192307472229\n",
      "learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch=len(data_loader)\n",
    "\n",
    "epochs=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_cost=0.0\n",
    "    for num, data in enumerate(data_loader):\n",
    "        imgs,labels=data\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out=net(imgs)\n",
    "        loss=loss_func(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost+=loss/total_batch\n",
    "\n",
    "    print('[Epoch: {}] cost={}'.format(epoch+1,avg_cost))\n",
    "print('learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model의 save에서 다시 불러오는 방법을 간단하게 넣어두었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'./model/model.pth')    #학습시킨 모델을 항상 쓸 때마다 다시 학습을 시켜서 사용할 수는 없으므로\n",
    "                                                    #torch.save를 써서 그 network의 state_dict 값을 저장하게 된다.\n",
    "                                                    #state_dict()는 torch.nn.Module에서 모델로 학습할 때 각 layer마다 텐서로 매핑되는 매개변수(예를들어, 가중치, 편향 등)\n",
    "                                                    #를 python dictionary 타입으로 저장한 객체이다. 학습 가능한 매개변수를 갖는 계층만이 모델의 state_dict에 항목을 가진다.\n",
    "                                                    #torch.optim 또한 옵티마이저의 상태 뿐만 아니라 사용된 하이퍼 매개변수 정보가 포함된 state_dict를 갖는다.\n",
    "                                                    #\n",
    "                                                    # 문법은 torch.save(모델명.state_dict(),'저장경로.pth')\n",
    "                                                    # 참고로 .pth는 pytorch 모델 파일을 저장할 때 사용되는 확장자. .pth파일은 모델의 state_dict를 저장한 파일이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러오려면 그 네트워크의 모형은 똑같아야 한다.\n",
    "# 그래서 net을 선언할 때 했던 것처럼 똑같이 선언해 주는데, 이름은 new_net이라 하고 새로운 네트워크를 선언해주자.\n",
    "new_net=CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net.load_state_dict(torch.load('./model/model.pth'))    #모델을 불러올 때는 새로운_모델명.load_state_dict()를 사용.\n",
    "                                                            #torch.load를 이용해서 아까 저장한 값을 가져온다. \n",
    "                                                            #'./model/model.pth' 이 값이 아까 저장한 load_state_dict이니 load해서 new_net에 담아라는 의미다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "tensor([-0.0087, -0.1160, -0.0399,  0.0729, -0.0699], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0087, -0.1160, -0.0399,  0.0729, -0.0699], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net에서의 값과 new_net에서의 값이 일치하는 것을 관찰할 수 있다.\n",
    "\n",
    "print(net.layer1[0])            # net의 layer1의 첫번째\n",
    "print(new_net.layer1[0])        # new_net의 layer1의 첫번째\n",
    "\n",
    "print(net.layer1[0].weight[0][0][0])    #net의 layer1의 첫번째의 weight값의 첫번째 index에 해당하는 값을 뽑아라. net의 layer1의 첫번째는 convolution layer다.\n",
    "print(new_net.layer1[0].weight[0][0][0])\n",
    "\n",
    "net.layer1[0].weight[0]==new_net.layer1[0].weight[0]        #일치."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킨 모델들을 test해보자.\n",
    "trans=torchvision.transforms.Compose([\n",
    "    transforms.Resize((64,128)),                    # 64x128의 사이즈로 resize하고 \n",
    "    transforms.ToTensor()                           # ToTensor로 바꿔서 사용.\n",
    "])                                                  #혹시라도 trans=torchvision.transforms.Compose([transforms.ToTensor(64,128)])을 생각했다면 이건 유효한 코드가 아니다.\n",
    "\n",
    "test_data=torchvision.datasets.ImageFolder(root='./custom_data/test_data',transform=trans)          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7199999690055847\n"
     ]
    }
   ],
   "source": [
    "test_set=DataLoader(dataset=test_data, batch_size=len(test_data))       # testset은 DataLoader로 해서 한번에 쓸 수 있게 test_data set의 길이만큼 batch_size로 한번에 받음.\n",
    "                                                                        # 참고로 채널크기가 맞아야 하는거지 batch_size는 얼마가 들어가든 상관이 없다.\n",
    "with torch.no_grad():\n",
    "    for num, data in enumerate(test_set):\n",
    "        imgs, label=data\n",
    "        imgs=imgs.to(device)\n",
    "        label=label.to(device)\n",
    "\n",
    "        prediction=net(imgs)\n",
    "\n",
    "        correct_prediction=torch.argmax(prediction,1)==label\n",
    "\n",
    "        accuracy=correct_prediction.float().mean()\n",
    "        print('Accuracy:',accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 모델과 데이터를 삭제\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m net\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m new_net\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 가비지 컬렉션을 강제로 호출하여 메모리 정리\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "# GPU 메모리 캐시 비우기\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 모델과 데이터를 삭제\n",
    "del net\n",
    "del new_net\n",
    "\n",
    "# 가비지 컬렉션을 강제로 호출하여 메모리 정리\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# Python 세션 종료\n",
    "exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "trans=torchvision.transforms.Compose([transforms.ToTensor()])\n",
    "train_data=torchvision.datasets.ImageFolder(root='./custom_data/train_data',transform=trans)\n",
    "\n",
    "data_loader=torch.utils.data.DataLoader(dataset=train_data,batch_size=8, shuffle=True,num_workers=2)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(3,6,5),           # input_channel, output_channel, kernel_size순. stride는 기본값이 1임. padding 도 기본값이 0임.\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),            # MaxPool2d는 stride 설정을 안하면 kernel_size와 같다.\n",
    "        )\n",
    "\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(6,16,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.layer3=nn.Sequential(      # fully connected이다.\n",
    "            nn.Linear(16*13*29, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        #print(out.shape)                #크기가 헷갈리면 print로 출력을 해보는 것도 방법이다.\n",
    "        out=self.layer2(out)\n",
    "        #print(out.shape)\n",
    "        out=out.view(out.shape[0],-1)   # 펼친다. out=out.view(out.size(0),-1)로 바꿔도 된다.\n",
    "        #print(out.shape)\n",
    "        out=self.layer3(out)\n",
    "        return out\n",
    "\n",
    "net=CNN().to(device)\n",
    "\n",
    "# optimizer & criterion\n",
    "optimizer=optim.Adam(net.parameters(), lr=0.00001)\n",
    "loss_func=nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "total_batch=len(data_loader)\n",
    "\n",
    "epochs=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_cost=0.0\n",
    "    for num,data in enumerate(data_loader):\n",
    "        img,label=data\n",
    "        img=img.to(device)\n",
    "        label=label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis=net(img)\n",
    "        cost=loss_func(hypothesis,label)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=loss/total_batch\n",
    "\n",
    "    print('[Epoch: {}] cost={}'.format(epoch+1,avg_cost))\n",
    "print('learning finished')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for num, data in enumerate(test_set):\n",
    "        img, label=data\n",
    "        img=img.to(device)\n",
    "        label=label.to(device)\n",
    "        predictions=net(img)\n",
    "        correct=torch.argmax(predictions,1)==label\n",
    "\n",
    "        accuracy=correct.float().mean()\n",
    "\n",
    "        print(accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_kernel",
   "language": "python",
   "name": "notebook_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
