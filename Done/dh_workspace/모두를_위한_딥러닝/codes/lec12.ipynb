{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer1, layer2같은 모델과 X, Y와 같은 데이터들을 device로 옮겨야한다. 손실함수도 device로 옮긴다. 다만, optimizer는 device에서 연산을 하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 정답을 주고\n",
    "layer를 만들고, 활성화 함수를 만든다.<br>\n",
    "Sequential을 통해 모델을 만들고<br>\n",
    "손실함수와 최적화 함수를 만든 후<br>\n",
    "optimizer.zero_grad()<br>\n",
    "hypothesis=model(X)              #이게 중요. model에 X를 넣음<br>\n",
    "cost함수를 통해 back propagation을 한 후<br>\n",
    "optimizer를 통해 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6959517002105713\n",
      "100 0.6927783489227295\n",
      "200 0.6903095245361328\n",
      "300 0.6676894426345825\n",
      "400 0.5709620714187622\n",
      "500 0.5047262907028198\n",
      "600 0.3756834864616394\n",
      "700 0.13354578614234924\n",
      "800 0.06363264471292496\n",
      "900 0.04019070789217949\n",
      "1000 0.029036937281489372\n",
      "1100 0.022613516077399254\n",
      "1200 0.018465783447027206\n",
      "1300 0.015577229671180248\n",
      "1400 0.013454966247081757\n",
      "1500 0.0118322242051363\n",
      "1600 0.010552708059549332\n",
      "1700 0.009518757462501526\n",
      "1800 0.008666414767503738\n",
      "1900 0.007952000945806503\n",
      "2000 0.007344826124608517\n",
      "2100 0.006822541356086731\n",
      "2200 0.006368688307702541\n",
      "2300 0.005970681551843882\n",
      "2400 0.005618912633508444\n",
      "2500 0.005305774975568056\n",
      "2600 0.00502531323581934\n",
      "2700 0.004772701300680637\n",
      "2800 0.004543973598629236\n",
      "2900 0.0043359119445085526\n",
      "3000 0.004145908169448376\n",
      "3100 0.003971632104367018\n",
      "3200 0.0038113072514533997\n",
      "3300 0.003663311479613185\n",
      "3400 0.0035262280143797398\n",
      "3500 0.00339897396042943\n",
      "3600 0.0032804703805595636\n",
      "3700 0.003169882344081998\n",
      "3800 0.00306645012460649\n",
      "3900 0.002969477092847228\n",
      "4000 0.0028784098103642464\n",
      "4100 0.00279267062433064\n",
      "4200 0.0027119109872728586\n",
      "4300 0.002635619370266795\n",
      "4400 0.0025634802877902985\n",
      "4500 0.002495161257684231\n",
      "4600 0.00243029510602355\n",
      "4700 0.002368756802752614\n",
      "4800 0.0023102345876395702\n",
      "4900 0.0022544730454683304\n",
      "5000 0.0022013592533767223\n",
      "5100 0.0021506324410438538\n",
      "5200 0.0021021561697125435\n",
      "5300 0.002055868273600936\n",
      "5400 0.0020115231163799763\n",
      "5500 0.001969004748389125\n",
      "5600 0.0019283238798379898\n",
      "5700 0.0018892213702201843\n",
      "5800 0.0018516250420361757\n",
      "5900 0.0018155216239392757\n",
      "6000 0.001780819147825241\n",
      "6100 0.0017473881598562002\n",
      "6200 0.001715170918032527\n",
      "6300 0.001684072078205645\n",
      "6400 0.0016541287768632174\n",
      "6500 0.0016252242494374514\n",
      "6600 0.0015972715336829424\n",
      "6700 0.0015702820383012295\n",
      "6800 0.0015442005824297667\n",
      "6900 0.001518925535492599\n",
      "7000 0.0014945217408239841\n",
      "7100 0.0014707930386066437\n",
      "7200 0.0014478755183517933\n",
      "7300 0.0014256633585318923\n",
      "7400 0.0014040509704500437\n",
      "7500 0.0013831165852025151\n",
      "7600 0.001362816197797656\n",
      "7700 0.0013430503895506263\n",
      "7800 0.0013238949468359351\n",
      "7900 0.0013052504509687424\n",
      "8000 0.001287106773816049\n",
      "8100 0.001269487664103508\n",
      "8200 0.0012523188488557935\n",
      "8300 0.0012356245424598455\n",
      "8400 0.0012193676084280014\n",
      "8500 0.0012035391991958022\n",
      "8600 0.0011880425736308098\n",
      "8700 0.0011729903053492308\n",
      "8800 0.001158344093710184\n",
      "8900 0.0011440124362707138\n",
      "9000 0.001130049116909504\n",
      "9100 0.0011164112947881222\n",
      "9200 0.001103070331737399\n",
      "9300 0.001090110745280981\n",
      "9400 0.0010773752583190799\n",
      "9500 0.0010649831965565681\n",
      "9600 0.0010528330458328128\n",
      "9700 0.0010410175891593099\n",
      "9800 0.001029408653266728\n",
      "9900 0.001018061302602291\n",
      "10000 0.0010069803101941943\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda')\n",
    "\n",
    "\n",
    "X=torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y=torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "\n",
    "#nn layers\n",
    "layer1=torch.nn.Linear(2,2, bias=True)\n",
    "layer2=torch.nn.Linear(2,1, bias=True)\n",
    "sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "model=torch.nn.Sequential(layer1,sigmoid,layer2,sigmoid).to(device)\n",
    "#cost and optimizer\n",
    "criterion=torch.nn.BCELoss().to(device)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis=model(X)                         #forward를 수행함.\n",
    "    cost=criterion(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step%100 == 0:\n",
    "        print(step, cost.item())\n",
    "\n",
    "del model  # 모델 객체를 삭제하여 GPU 메모리 해제\n",
    "torch.cuda.empty_cache()  # GPU 메모리 캐시를 비움\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7196991443634033\n",
      "100 0.6931585073471069\n",
      "200 0.6931577920913696\n",
      "300 0.6931571960449219\n",
      "400 0.6931566596031189\n",
      "500 0.6931560635566711\n",
      "600 0.6931554675102234\n",
      "700 0.6931549906730652\n",
      "800 0.6931544542312622\n",
      "900 0.693153977394104\n",
      "1000 0.693153440952301\n",
      "1100 0.6931529641151428\n",
      "1200 0.6931525468826294\n",
      "1300 0.6931520700454712\n",
      "1400 0.6931517124176025\n",
      "1500 0.6931512355804443\n",
      "1600 0.6931508183479309\n",
      "1700 0.6931504011154175\n",
      "1800 0.693149983882904\n",
      "1900 0.6931496262550354\n",
      "2000 0.693149209022522\n",
      "2100 0.6931488513946533\n",
      "2200 0.6931484341621399\n",
      "2300 0.6931480169296265\n",
      "2400 0.6931476593017578\n",
      "2500 0.6931472420692444\n",
      "2600 0.693146824836731\n",
      "2700 0.6931464076042175\n",
      "2800 0.6931460499763489\n",
      "2900 0.6931456327438354\n",
      "3000 0.693145215511322\n",
      "3100 0.6931447982788086\n",
      "3200 0.6931443810462952\n",
      "3300 0.6931438446044922\n",
      "3400 0.6931434869766235\n",
      "3500 0.6931430101394653\n",
      "3600 0.6931424736976624\n",
      "3700 0.6931420564651489\n",
      "3800 0.6931414604187012\n",
      "3900 0.693140983581543\n",
      "4000 0.6931403875350952\n",
      "4100 0.6931398510932922\n",
      "4200 0.6931391954421997\n",
      "4300 0.693138599395752\n",
      "4400 0.6931380033493042\n",
      "4500 0.6931372880935669\n",
      "4600 0.6931365728378296\n",
      "4700 0.6931357383728027\n",
      "4800 0.6931349635124207\n",
      "4900 0.693134069442749\n",
      "5000 0.6931331157684326\n",
      "5100 0.6931321620941162\n",
      "5200 0.6931310296058655\n",
      "5300 0.6931298971176147\n",
      "5400 0.6931286454200745\n",
      "5500 0.6931272745132446\n",
      "5600 0.69312584400177\n",
      "5700 0.6931242942810059\n",
      "5800 0.6931225061416626\n",
      "5900 0.693120539188385\n",
      "6000 0.6931183338165283\n",
      "6100 0.6931160092353821\n",
      "6200 0.6931133270263672\n",
      "6300 0.6931103467941284\n",
      "6400 0.6931069493293762\n",
      "6500 0.6931030750274658\n",
      "6600 0.6930987238883972\n",
      "6700 0.6930936574935913\n",
      "6800 0.6930876970291138\n",
      "6900 0.6930808424949646\n",
      "7000 0.6930726766586304\n",
      "7100 0.6930629014968872\n",
      "7200 0.6930510997772217\n",
      "7300 0.6930364966392517\n",
      "7400 0.6930183172225952\n",
      "7500 0.6929952502250671\n",
      "7600 0.6929653286933899\n",
      "7700 0.6929255127906799\n",
      "7800 0.69287109375\n",
      "7900 0.6927937865257263\n",
      "8000 0.6926794052124023\n",
      "8100 0.692500114440918\n",
      "8200 0.6921982765197754\n",
      "8300 0.6916365623474121\n",
      "8400 0.6904252767562866\n",
      "8500 0.6870994567871094\n",
      "8600 0.6726589202880859\n",
      "8700 0.5682210326194763\n",
      "8800 0.5222015380859375\n",
      "8900 0.018140841275453568\n",
      "9000 0.00747209507972002\n",
      "9100 0.004491235129535198\n",
      "9200 0.003150378819555044\n",
      "9300 0.002402101643383503\n",
      "9400 0.0019294542726129293\n",
      "9500 0.0016058051260188222\n",
      "9600 0.0013713010121136904\n",
      "9700 0.0011940787080675364\n",
      "9800 0.00105574750341475\n",
      "9900 0.0009449523058719933\n",
      "10000 0.0008543680305592716\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')  # GPU가 아니라 CPU에서 실행\n",
    "\n",
    "X=torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y=torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "linear1=torch.nn.Linear(2,10,bias=True)\n",
    "linear2=torch.nn.Linear(10,10,bias=True)\n",
    "linear3=torch.nn.Linear(10,10,bias=True)\n",
    "linear4=torch.nn.Linear(10,1,bias=True)\n",
    "sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "model=torch.nn.Sequential(linear1,sigmoid,linear2,sigmoid,linear3,sigmoid,linear4,sigmoid).to(device)\n",
    "\n",
    "criterion=torch.nn.BCELoss().to(device)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis=model(X)\n",
    "    cost=criterion(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100==0:\n",
    "        print(epoch, cost.item())\n",
    "del model  # 모델 객체를 삭제하여 GPU 메모리 해제\n",
    "torch.cuda.empty_cache()  # GPU 메모리 캐시를 비움\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_kernel",
   "language": "python",
   "name": "notebook_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
