{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train=[[1,2,1,1],\n",
    "         [2,1,3,2],\n",
    "         [3,1,3,4],\n",
    "         [4,1,5,5],\n",
    "         [1,7,5,5],\n",
    "         [1,2,5,6],\n",
    "         [1,6,6,6],\n",
    "         [1,7,7,7]]\n",
    "\n",
    "y_train=[2,2,2,1,1,1,0,0]\n",
    "x_train=torch.FloatTensor(x_train)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "\n",
    "\n",
    "\n",
    "W=torch.zeros((4,3),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "\n",
    "optimizer=optim.SGD([W,b],lr=0.1)\n",
    "\n",
    "nb_epochs=1000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis=F.softmax(x_train.matmul(W)+b,dim=1)\n",
    "    y_one_hot=torch.zeros_like(hypothesis)\n",
    "    y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n",
    "    cost=(y_one_hot*-torch.log(hypothesis)).sum(1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100==0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost=(y_one_hot*-torch.log(x_train.matmul(W)+b)).sum(1).mean()\n",
    "#대신에\n",
    "\n",
    "#cost=F.nll_loss(F.log_softmax(x_train.matmul(W)+b,dim=1),y_train)\n",
    "\n",
    "#또는\n",
    "cost=F.cross_entropy(x_train.matmul(W)+b,y_train)                   #log_softmax와 nll_loss를 합침."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.210765\n",
      "Epoch  100/1000 Cost: 0.644807\n",
      "Epoch  200/1000 Cost: 0.560825\n",
      "Epoch  300/1000 Cost: 0.506951\n",
      "Epoch  400/1000 Cost: 0.463074\n",
      "Epoch  500/1000 Cost: 0.424023\n",
      "Epoch  600/1000 Cost: 0.387494\n",
      "Epoch  700/1000 Cost: 0.352007\n",
      "Epoch  800/1000 Cost: 0.316410\n",
      "Epoch  900/1000 Cost: 0.280068\n",
      "Epoch 1000/1000 Cost: 0.247024\n"
     ]
    }
   ],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(4,3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)   \n",
    "\n",
    "\n",
    "x_train=[[1,2,1,1],\n",
    "         [2,1,3,2],\n",
    "         [3,1,3,4],\n",
    "         [4,1,5,5],\n",
    "         [1,7,5,5],\n",
    "         [1,2,5,6],\n",
    "         [1,6,6,6],\n",
    "         [1,7,7,7]]\n",
    "y_train=[2,2,2,1,1,1,0,0]\n",
    "x_train=torch.FloatTensor(x_train)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "\n",
    "model=SoftmaxClassifierModel()\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "nb_epochs=1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    prediction=model.linear(x_train)\n",
    "    cost=F.cross_entropy(prediction,y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100==0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_kernel",
   "language": "python",
   "name": "notebook_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
