{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "inputs=torch.Tensor(1,1,28,28)                      # batch_size, channel, height, width    (batch_size: 한 번에 모델에 입력되는 데이터 샘플의 수)\n",
    "conv1=nn.Conv2d(1,32,3,padding=1)                   # input_channel수, output_channel수, filter_size(filter의 height*width)\n",
    "pool=nn.MaxPool2d(2)                                # stride값은 입력이 None일 경우 kernel_size를 따라간다.\n",
    "print(pool)                                     \n",
    "\n",
    "    # 참고: Conv2d의 필터(커널) 값들은 학습을 통해 자동으로 조정됩니다. Conv2d의 필터 값들은 신경망 학습 초기화 단계에서 무작위로 설정됩니다. \n",
    "    # 이러한 초기 값들은 임의의 작은 값으로 설정되며, 학습을 통해 점차 최적화됩니다. \n",
    "    # 초기화 방법은 여러 가지가 있을 수 있는데, 가장 많이 사용되는 방법은 He 초기화나 Xavier 초기화입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "tensor([[[[ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          ...,\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611]],\n",
      "\n",
      "         [[ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          ...,\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163]],\n",
      "\n",
      "         [[ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          ...,\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          ...,\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776]],\n",
      "\n",
      "         [[ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          ...,\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550]],\n",
      "\n",
      "         [[-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          ...,\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "conv2=nn.Conv2d(32,64,3,padding=1)                      \n",
    "print(conv1)\n",
    "print(conv2)\n",
    "\n",
    "out=conv1(inputs)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          ...,\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611],\n",
      "          [ 0.1611,  0.1611,  0.1611,  ...,  0.1611,  0.1611,  0.1611]],\n",
      "\n",
      "         [[ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          ...,\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163],\n",
      "          [ 0.3163,  0.3163,  0.3163,  ...,  0.3163,  0.3163,  0.3163]],\n",
      "\n",
      "         [[ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          ...,\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755],\n",
      "          [ 0.2755,  0.2755,  0.2755,  ...,  0.2755,  0.2755,  0.2755]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          ...,\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776],\n",
      "          [-0.0776, -0.0776, -0.0776,  ..., -0.0776, -0.0776, -0.0776]],\n",
      "\n",
      "         [[ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          ...,\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550],\n",
      "          [ 0.0550,  0.0550,  0.0550,  ...,  0.0550,  0.0550,  0.0550]],\n",
      "\n",
      "         [[-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          ...,\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555],\n",
      "          [-0.1555, -0.1555, -0.1555,  ..., -0.1555, -0.1555, -0.1555]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out=pool(out)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0910,  0.1073,  0.1073,  ...,  0.1073,  0.1073,  0.0559],\n",
      "          [ 0.0807,  0.0987,  0.0987,  ...,  0.0987,  0.0987,  0.0243],\n",
      "          [ 0.0807,  0.0987,  0.0987,  ...,  0.0696,  0.0987,  0.0243],\n",
      "          ...,\n",
      "          [ 0.0807,  0.0987,  0.0987,  ...,  0.0987,  0.0987,  0.0243],\n",
      "          [ 0.0807,  0.0987,  0.0987,  ...,  0.0987,  0.0987,  0.0243],\n",
      "          [ 0.0623,  0.0467,  0.0467,  ...,  0.0467,  0.0467,  0.0028]],\n",
      "\n",
      "         [[-0.0717, -0.0736, -0.0736,  ..., -0.0736, -0.0736,  0.0101],\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.1484, -0.1484, -0.0358],\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.1282, -0.1484, -0.0358],\n",
      "          ...,\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.1484, -0.1484, -0.0358],\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.1484, -0.1484, -0.0358],\n",
      "          [-0.0085, -0.0357, -0.0357,  ..., -0.0357, -0.0357, -0.0083]],\n",
      "\n",
      "         [[-0.0167, -0.0222, -0.0222,  ..., -0.0222, -0.0222,  0.0027],\n",
      "          [-0.0334, -0.0101, -0.0101,  ..., -0.0101, -0.0101,  0.0094],\n",
      "          [-0.0334, -0.0101, -0.0101,  ..., -0.0427, -0.0101,  0.0094],\n",
      "          ...,\n",
      "          [-0.0334, -0.0101, -0.0101,  ..., -0.0101, -0.0101,  0.0094],\n",
      "          [-0.0334, -0.0101, -0.0101,  ..., -0.0101, -0.0101,  0.0094],\n",
      "          [-0.0248,  0.0302,  0.0302,  ...,  0.0302,  0.0302,  0.0492]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2005, -0.1742, -0.1742,  ..., -0.1742, -0.1742, -0.1232],\n",
      "          [-0.1880, -0.1367, -0.1367,  ..., -0.1367, -0.1367, -0.0809],\n",
      "          [-0.1880, -0.1367, -0.1367,  ..., -0.1368, -0.1367, -0.0809],\n",
      "          ...,\n",
      "          [-0.1880, -0.1367, -0.1367,  ..., -0.1367, -0.1367, -0.0809],\n",
      "          [-0.1880, -0.1367, -0.1367,  ..., -0.1367, -0.1367, -0.0809],\n",
      "          [-0.0564, -0.0364, -0.0364,  ..., -0.0364, -0.0364, -0.0217]],\n",
      "\n",
      "         [[-0.0310, -0.1291, -0.1291,  ..., -0.1291, -0.1291, -0.1085],\n",
      "          [-0.0250, -0.1370, -0.1370,  ..., -0.1370, -0.1370, -0.1241],\n",
      "          [-0.0250, -0.1370, -0.1370,  ..., -0.1281, -0.1370, -0.1241],\n",
      "          ...,\n",
      "          [-0.0250, -0.1370, -0.1370,  ..., -0.1370, -0.1370, -0.1241],\n",
      "          [-0.0250, -0.1370, -0.1370,  ..., -0.1370, -0.1370, -0.1241],\n",
      "          [-0.0862, -0.1731, -0.1731,  ..., -0.1731, -0.1731, -0.1383]],\n",
      "\n",
      "         [[ 0.1304,  0.0998,  0.0998,  ...,  0.0998,  0.0998,  0.0684],\n",
      "          [ 0.1984,  0.1523,  0.1523,  ...,  0.1523,  0.1523,  0.1419],\n",
      "          [ 0.1984,  0.1523,  0.1523,  ...,  0.1325,  0.1523,  0.1419],\n",
      "          ...,\n",
      "          [ 0.1984,  0.1523,  0.1523,  ...,  0.1523,  0.1523,  0.1419],\n",
      "          [ 0.1984,  0.1523,  0.1523,  ...,  0.1523,  0.1523,  0.1419],\n",
      "          [ 0.1358,  0.1390,  0.1390,  ...,  0.1390,  0.1390,  0.1660]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out=conv2(out)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1073,  0.1073,  0.1073,  ...,  0.1073,  0.1073,  0.1073],\n",
      "          [ 0.0987,  0.0987,  0.1426,  ..., -0.0710,  0.0696,  0.0987],\n",
      "          [ 0.0987,  0.0987,  0.1893,  ...,  0.1570, -0.0113,  0.0987],\n",
      "          ...,\n",
      "          [ 0.2099,  0.2897,  0.2071,  ...,  0.2023,  0.1698,  0.0724],\n",
      "          [ 0.1391,  0.1011,  0.0987,  ...,  0.0987,  0.0987,  0.0987],\n",
      "          [ 0.0987,  0.0987,  0.0987,  ...,  0.0987,  0.0987,  0.0987]],\n",
      "\n",
      "         [[-0.0717, -0.0736, -0.0736,  ..., -0.0736, -0.0736,  0.0101],\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.0885,  0.0210, -0.0358],\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.1921, -0.0481, -0.0358],\n",
      "          ...,\n",
      "          [-0.1155, -0.3443, -0.2349,  ..., -0.2211, -0.1538, -0.0194],\n",
      "          [-0.1155, -0.1484, -0.1484,  ..., -0.1476, -0.1421, -0.0358],\n",
      "          [-0.0085, -0.0357, -0.0357,  ..., -0.0357, -0.0357, -0.0083]],\n",
      "\n",
      "         [[-0.0101, -0.0101, -0.0101,  ..., -0.0101, -0.0101,  0.0094],\n",
      "          [-0.0101, -0.0101,  0.0254,  ..., -0.0988, -0.0427,  0.0094],\n",
      "          [-0.0101, -0.0101,  0.0351,  ...,  0.3550,  0.0931,  0.0094],\n",
      "          ...,\n",
      "          [ 0.0229,  0.3539,  0.4355,  ...,  0.2795,  0.3128,  0.2698],\n",
      "          [ 0.0678,  0.1056,  0.0834,  ..., -0.0096, -0.0042,  0.0094],\n",
      "          [ 0.0302,  0.0302,  0.0302,  ...,  0.0302,  0.0302,  0.0492]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1367, -0.1367, -0.1367,  ..., -0.1367, -0.1367, -0.0809],\n",
      "          [-0.1367, -0.1367, -0.1367,  ..., -0.1256, -0.1368, -0.0809],\n",
      "          [-0.1367, -0.1367, -0.1353,  ..., -0.0163, -0.0053, -0.0809],\n",
      "          ...,\n",
      "          [-0.1880,  0.0400,  0.0107,  ...,  0.0269, -0.0133,  0.0290],\n",
      "          [-0.1264, -0.0980, -0.0675,  ..., -0.1363, -0.1367, -0.0659],\n",
      "          [-0.0364, -0.0364, -0.0364,  ..., -0.0364, -0.0364, -0.0217]],\n",
      "\n",
      "         [[-0.0250, -0.1291, -0.1291,  ..., -0.1291, -0.1291, -0.1085],\n",
      "          [-0.0250, -0.1370, -0.1370,  ...,  0.0516,  0.0837, -0.1241],\n",
      "          [-0.0250, -0.1370, -0.0627,  ..., -0.0125,  0.0711, -0.1241],\n",
      "          ...,\n",
      "          [-0.0250,  0.0457,  0.1066,  ..., -0.0261, -0.0574, -0.0659],\n",
      "          [-0.0250,  0.0281, -0.1370,  ..., -0.1364, -0.1259, -0.1241],\n",
      "          [-0.0250, -0.1370, -0.1370,  ..., -0.1370, -0.1370, -0.1241]],\n",
      "\n",
      "         [[ 0.1984,  0.1523,  0.1523,  ...,  0.1523,  0.1523,  0.1523],\n",
      "          [ 0.1984,  0.1523,  0.1523,  ...,  0.0017,  0.1325,  0.1523],\n",
      "          [ 0.1984,  0.1523,  0.2437,  ..., -0.0347,  0.2056,  0.1523],\n",
      "          ...,\n",
      "          [ 0.2342,  0.1265,  0.0662,  ...,  0.1569,  0.1808,  0.2214],\n",
      "          [ 0.2274,  0.1523,  0.1523,  ...,  0.1530,  0.1594,  0.1530],\n",
      "          [ 0.1984,  0.1523,  0.1523,  ...,  0.1523,  0.1523,  0.1660]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out=pool(out)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "64\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(out.size(0))\n",
    "print(out.size(1))\n",
    "print(out.size(2))\n",
    "print(out.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "out=out.view(out.size(0),-1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1138, -0.0751,  0.2452, -0.1299, -0.0403, -0.0850, -0.0217,  0.0626,\n",
      "         -0.1243, -0.1138]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc=nn.Linear(3136,10)\n",
    "out=fc(out)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본격적으로 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "import torch.nn.init                                # 텐서 초기화(initialization) 함수들을 제공하는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# parameters\n",
    "learning_rate=0.001\n",
    "training_epochs=15\n",
    "batch_size=100\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_train=dsets.MNIST(root='C:/git_experiment/RWL_Intern/dh_workspace/모두를 위한 딥러닝/MNIST',\n",
    "                        train=True,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)      #transform은 input data를 어떻게 변환해줄 거냐를 의미함. \n",
    "                                            #그냥 받아오면 Tensor value가 아니므로받아온 mnist data를 tensor value로 바꿔준다.\n",
    "                                            #이미지를 ToTensor로 하면 예를들어 픽셀 값이 0-255의 값일 때 정규화를 적용해서 0-1의 값으로 바꾼다.\n",
    "mnist_test=dsets.MNIST(root='C:/git_experiment/RWL_Intern/dh_workspace/모두를 위한 딥러닝/MNIST',\n",
    "                       train=False,\n",
    "                       transform=transforms.ToTensor(),\n",
    "                       download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()                  #  CNN,self는 현재 클래스(여기서는 CNN)와 현재 객체(여기서는 self)를 명시적으로 지정하는 \n",
    "        self.layer1=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1,32,kernel_size=3,stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                         # MaxPool2d를 거쳐도 채널의 개수는 변하지 않는다.\n",
    "        )\n",
    "\n",
    "        self.layer2=torch.nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc=nn.Linear(7*7*64, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "\n",
    "        out=out.view(out.size(0),-1)        # out.size(0)은 batch_size -->out.view(out.size(0),-1): (batch_size ,14*7*7)\n",
    "        out=self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN().to(device)              # model을 device로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss().to(device)              # loss_function을 device로\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 cost: 0.22577328979969025\n",
      "epoch: 2 cost: 0.06306502223014832\n",
      "epoch: 3 cost: 0.04632473364472389\n",
      "epoch: 4 cost: 0.03743469715118408\n",
      "epoch: 5 cost: 0.03137858211994171\n",
      "epoch: 6 cost: 0.026164093986153603\n",
      "epoch: 7 cost: 0.021853219717741013\n",
      "epoch: 8 cost: 0.018350539728999138\n",
      "epoch: 9 cost: 0.016098221763968468\n",
      "epoch: 10 cost: 0.013577586971223354\n",
      "epoch: 11 cost: 0.010142168030142784\n",
      "epoch: 12 cost: 0.01027227658778429\n",
      "epoch: 13 cost: 0.008242693729698658\n",
      "epoch: 14 cost: 0.006388708483427763\n",
      "epoch: 15 cost: 0.006578456610441208\n",
      "learning finished\n"
     ]
    }
   ],
   "source": [
    "#training 하는 코드\n",
    "total_batch=len(data_loader)                # 전체 배치 수가 나온다.\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "\n",
    "    for X,Y in data_loader:\n",
    "        X=X.to(device)                      # cuda 연산을 진행하려면 해야한다. 이미지를 device로\n",
    "        Y=Y.to(device)                      # cuda 연산을 진행하려면 해야한다.  label을 device로\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis=model(X)\n",
    "        cost=criterion(hypothesis,Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost+=cost/total_batch\n",
    "\n",
    "    print('epoch: {} cost: {}'.format(epoch+1,avg_cost))\n",
    "\n",
    "print('learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9857999682426453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhlee\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\Users\\dhlee\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:71: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "with torch.no_grad():\n",
    "    X_test=mnist_test.test_data.view(len(mnist_test),1,28,28).float().to(device)        #test 이미지 추출. 원래는 (10000,28,28)인데 view를 통해 (10000,1,28,28)\n",
    "    Y_test=mnist_test.test_labels.to(device)                                            #test 라벨 추출.   shape은 (10000,)\n",
    "\n",
    "    prediction=model(X_test)\n",
    "    correct_prediction=torch.argmax(prediction,1)==Y_test                               #torch.argmax는 인수로 (예측값을 가진 텐서, dim)을 받는다.\n",
    "    accuracy=correct_prediction.float().mean()                                          # 이 값은 단일 Tensor값이다.\n",
    "    print('Accuracy:',accuracy.item())                                                  # 따라서 우리가 원하는 Python float값으로 출력하려면 .item()을 해줘야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer를 늘려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 cost: 0.15979771316051483\n",
      "epoch: 2 cost: 0.04317035526037216\n",
      "epoch: 3 cost: 0.029908541589975357\n",
      "epoch: 4 cost: 0.02232998237013817\n",
      "epoch: 5 cost: 0.018295282498002052\n",
      "epoch: 6 cost: 0.01512010209262371\n",
      "epoch: 7 cost: 0.012980270199477673\n",
      "epoch: 8 cost: 0.01045115664601326\n",
      "epoch: 9 cost: 0.009223178029060364\n",
      "epoch: 10 cost: 0.009032508358359337\n",
      "epoch: 11 cost: 0.007143223658204079\n",
      "epoch: 12 cost: 0.008653398603200912\n",
      "epoch: 13 cost: 0.005579840857535601\n",
      "epoch: 14 cost: 0.006424498278647661\n",
      "epoch: 15 cost: 0.005773204378783703\n",
      "learning finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "import torch.nn.init\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device=='cuda':                          # 만약 device가 cuda일 때\n",
    "    torch.cuda.manual_seed_all(777)         # 모든 cuda에 대해 난수를 생성해라(manual_seed_all)\n",
    "\n",
    "# parameters\n",
    "learning_rate=0.001\n",
    "training_epochs=15\n",
    "batch_size=100\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_train=dsets.MNIST(root='C:/git_experiment/RWL_Intern/dh_workspace/모두를 위한 딥러닝/MNIST',\n",
    "                        train=True,\n",
    "                        transform=transforms.ToTensor(),        #흑백 이미지일 때는 channel수가 1, 컬러 이미지면 channel 수가 3\n",
    "                        download=True)      #transform은 input data를 어떻게 변환해줄 거냐를 의미함. \n",
    "                                            #그냥 받아오면 Tensor value가 아니므로받아온 mnist data를 tensor value로 바꿔준다.\n",
    "mnist_test=dsets.MNIST(root='C:/git_experiment/RWL_Intern/dh_workspace/모두를 위한 딥러닝/MNIST',\n",
    "                       train=False,\n",
    "                       transform=transforms.ToTensor(),\n",
    "                       download=True)\n",
    "\n",
    "data_loader=torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        drop_last=True)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1,32,kernel_size=3,stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2=torch.nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc1=nn.Linear(3*3*128, 625)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "\n",
    "        out=out.view(out.size(0),-1)            # 이걸 하는 이유: convolution layer를 지난 결과들을 fully connected layer에 넣어야 하기 때문에 입력 개수만큼 바꿔주기 위해서.\n",
    "        out=self.fc1(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model=CNN().to(device)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#training 하는 코드\n",
    "total_batch=len(data_loader)                # 전체 배치 수가 나온다.\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "\n",
    "    for X,Y in data_loader:\n",
    "        X=X.to(device)                      # cuda 연산을 진행하려면 해야한다.\n",
    "        Y=Y.to(device)                      # cuda 연산을 진행하려면 해야한다.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis=model(X)\n",
    "        cost=criterion(hypothesis,Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost+=cost/total_batch\n",
    "\n",
    "    print('epoch: {} cost: {}'.format(epoch+1,avg_cost))\n",
    "\n",
    "print('learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cost: 0.2992653250694275\n",
      "epoch: 2, cost: 0.11726064234972\n",
      "epoch: 3, cost: 0.10683590918779373\n",
      "epoch: 4, cost: 0.10272818058729172\n",
      "epoch: 5, cost: 0.10507979989051819\n",
      "epoch: 6, cost: 0.10775179415941238\n",
      "epoch: 7, cost: 0.10779769718647003\n",
      "epoch: 8, cost: 0.10426343232393265\n",
      "epoch: 9, cost: 0.10197030752897263\n",
      "epoch: 10, cost: 0.09687957167625427\n",
      "epoch: 11, cost: 0.09840089082717896\n",
      "epoch: 12, cost: 0.0968899354338646\n",
      "epoch: 13, cost: 0.10430961102247238\n",
      "epoch: 14, cost: 0.10163317620754242\n",
      "epoch: 15, cost: 0.09393569082021713\n",
      "finished learning\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.init\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(777)\n",
    "\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# 파라미터 설정\n",
    "learning_rate=0.015\n",
    "training_epochs=15\n",
    "batch_size=100\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "mnist_train=dsets.MNIST(root='C:/git_experiment/RWL_Intern/dh_workspace/모두를 위한 딥러닝/MNIST',train=True,transform=transforms.ToTensor(),download=True)\n",
    "mnist_test=dsets.MNIST(root='C:/git_experiment/RWL_Intern/dh_workspace/모두를 위한 딥러닝/MNIST',train=False,transform=transforms.ToTensor(),download=True)\n",
    "data_loader=torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "# class 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(32,64,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Conv2d(64,128,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc1=nn.Linear(3*3*128,625)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(625,10,bias=True)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight)             # he 초기화는 kaiming_uniform 을 사용\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "\n",
    "        out=out.view(out.size(0),-1)\n",
    "        \n",
    "        out=self.fc1(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# model 정의\n",
    "model=CNN().to(device)\n",
    "\n",
    "# optimizer와 loss function 정의\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion=nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "total_batch=len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "\n",
    "    for X,Y in data_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis=model(X)\n",
    "        cost=criterion(hypothesis,Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost+=cost/total_batch\n",
    "\n",
    "    print('epoch: {}, cost: {}'.format(epoch+1,avg_cost))\n",
    "\n",
    "print('finished learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_kernel",
   "language": "python",
   "name": "notebook_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
