{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고](https://velog.io/@jadenkim5179/%EB%B0%91%EB%B0%94%EB%8B%A5-%EB%94%A5%EB%9F%AC%EB%8B%9D-im2col-%EA%B5%AC%ED%98%84-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0)\n",
    "\n",
    "[참고2](https://velog.io/@clayryu328/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-17-max-pooling-im2col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터 (이미지 수, 채널 수, 높이, 너비)\n",
    "                 (N, C, H, W) 형상으로, N은 이미지의 수, C는 채널 수, H는 높이, W는 너비\n",
    "    filter_h : 필터의 높이 (세로 크기)\n",
    "    filter_w : 필터의 너비 (가로 크기)\n",
    "    stride : 스트라이드 (기본값 1), 필터가 슬라이딩 할 때의 간격\n",
    "    pad : 패딩 (기본값 0), 입력 이미지에 추가할 픽셀 수\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "        변환된 2차원 배열. 각 윈도우가 1개의 행(row)으로 평탄화됨.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 입력 데이터의 크기 (이미지 수, 채널 수, 높이, 너비) 받아오기\n",
    "    N, C, H, W = input_data.shape\n",
    "\n",
    "    # 출력 크기 계산\n",
    "    out_h = (H + 2 * pad - filter_h) // stride + 1  # 출력 높이\n",
    "    out_w = (W + 2 * pad - filter_w) // stride + 1  # 출력 너비\n",
    "\n",
    "    # 패딩 적용된 입력 이미지 생성 (배치와 채널에 대해서는 패딩을 적용하지 않음)\n",
    "    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], 'constant')\n",
    "\n",
    "    # 필터의 높이와 너비에 맞게 출력 배열 크기 초기화\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    #col의 출력 크기(out_h, out_w)는 필터가 이미지 위를 슬라이딩할 수 있는 횟수를 나타냅니다. 즉, 출력 이미지의 크기와 대응\n",
    "    #col 배열은 입력 이미지에서 필터가 슬라이딩하면서 각 영역을 잘라내고, 이를 2차원 배열로 평탄화합니다.\n",
    "\n",
    "    # y 방향으로 필터의 크기만큼 슬라이딩하며 윈도우의 값을 가져오기\n",
    "    for y in range(filter_h):  # 필터의 높이만큼 반복\n",
    "        y_max = y + stride * out_h  # 필터가 세로로 이동할 최대 끝 위치(입력이미지의 height, width를 7,7이라 하고, stride를 1, padding을 0, 필터 h,w를 5,5로 두고 숫자놀이 ㄱㄱ)\n",
    "        for x in range(filter_w):  # 필터의 너비만큼 반복\n",
    "            x_max = x + stride * out_w  # 필터가 가로로 이동할 최대 끝 위치\n",
    "\n",
    "            # 이미지를 슬라이딩하면서 윈도우의 영역을 col 배열에 저장\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]       #행을 우선으로 읽는다. 그다음에 열을 살펴봄.(ex: x1,x2,x3,x4)\n",
    "\n",
    "    # col 배열을 2차원 배열로 변환 (배치, 출력 크기, 채널, 필터 크기 순으로 차원을 재배열) \n",
    "    # 그니까 transpose(0, 4, 5, 1, 2, 3)는 (N, out_h, out_w, C, filter_h, filter_w)로 재배열 한다는 소리. transpose는 배열의 차원 순서를 변경하는 연산.\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)    #재배열을 하고, N*out_h*out_w 만큼 행을 배열하고 열은 자동으로 배열한다.(열을 C*f_h*f_w)\n",
    "    \n",
    "    return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.stride=stride\n",
    "        self.pad=pad\n",
    "\n",
    "    def forward(self,x):\n",
    "        FN,C,FH,FW=self.W.shape\n",
    "        N,C,H,W=x.shape\n",
    "        out_h=int(1+(H+2*self.pad-FH)/self.stride)\n",
    "        out_w=int(1+(W+2*self.pad-FW)/self.stride)\n",
    "\n",
    "        col=im2col(x,FH,FW,self.stride,self.pad)\n",
    "        col_w=self.W.reshape(FN,-1).T\n",
    "        out=np.dot(col,col_w)+self.b                    #행렬곱 사용함.\n",
    "\n",
    "        out=out.reshape(N,out_h,out_w,-1).transpose(0,3,1,2)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : 2차원 배열(입력 데이터)\n",
    "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : 변환된 이미지들\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))         \n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![사진](convolution_for_back.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[강의링크](https://www.youtube.com/watch?v=OHCaMC0hMtI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 중간 데이터（backward 시 사용）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):                   \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) #forward에서 reshape해 준것을 backward에서 다시 원상복귀해준다.\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)                  #forward에서 reshape해 준것을 backward에서 다시 원상복귀해준다.\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)                              # col은 (N*OH*OW, C*FH*FW)이고, dout은 (N*OH*OW,FN)임-->self.dW는 (C*FH*FW,FN)이다.\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)        # forward에서의 입력되었던 W 상태로 바꿔준다. (FN,C,FH,FW 형태로)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)                               #\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h=pool_h\n",
    "        self.pool_w=pool_w\n",
    "        self.stride=stride\n",
    "        self.pad=pad\n",
    "    \n",
    "    def forward(self,x):\n",
    "        N,C,H,W=x.shape\n",
    "        out_h=int(1+(H-self.pool_h)/self.stride)\n",
    "        out_w=int(1+(W-self.pool_w)/self.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):        #이 convolution에서는 은닉층이 단일이다.\n",
    "        # 합성곱 층의 파라미터 설정\n",
    "        filter_num = conv_param['filter_num']  # 필터의 수 (출력 채널)\n",
    "        filter_size = conv_param['filter_size']  # 필터 크기\n",
    "        filter_pad = conv_param['pad']  # 패딩 크기\n",
    "        filter_stride = conv_param['stride']  # 스트라이드 크기\n",
    "        input_size = input_dim[1]  # 입력 크기 (MNIST의 경우 28)\n",
    "        \n",
    "        # 합성곱 출력 크기 계산\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        # 풀링 출력 크기 계산 (2x2 풀링을 사용하므로 크기를 반으로 줄임)\n",
    "        pool_output_size = int(filter_num * (conv_output_size / 2) * (conv_output_size / 2))   #아래의 self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "                                                                                               #때문에 이걸 쓴다.\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)   # input_dim[0]은 입력 이미지의 채널 수\n",
    "                                                                                                                    #그리고 가로세로 길이가 동일해서 filter_size가 두개 들어감.\n",
    "        self.params['b1'] = np.zeros(filter_num)                        #편향은 필터의 개수에 의존(각 필터에 하나씩 존재, 입력값에는 의존 안함.)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        # 합성곱 계층\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n",
    "        # ReLU 활성화 계층\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        # 풀링 계층 (2x2 크기, 스트라이드 2)\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        # Affine(fully connected) 계층\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        # 두 번째 ReLU 활성화 계층\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        # 두 번째 Affine 계층\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        # 마지막 소프트맥스와 손실 계층\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"입력 x에 대한 예측을 수행한다.\"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"입력 x와 정답 t에 대한 손실을 계산한다.\"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):       #참고로 gradient에서는 배치처리를 안하고 전체적으로 계산을 했지만, accuracy에서는 배치처리로 분할해서 계산함.\n",
    "        \"\"\"정확도를 계산한다.\"\"\"\n",
    "        if t.ndim != 1:     #원핫 인코딩(예를 들어 [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])일 때 \n",
    "            t = np.argmax(t, axis=1)  # 정답 레이블을 원핫 벡터에서 정수로 변환     (위의 예시의 경우 3으로...)\n",
    "        \n",
    "        acc = 0.0\n",
    "        for i in range(int(x.shape[0] / batch_size)):    #x.shape[0]은 입력 데이터 x의 전체 샘플 수\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]  # 배치 단위로 데이터 분할\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)  # 예측값\n",
    "            y = np.argmax(y, axis=1)  # 예측값을 1D 배열로 변환\n",
    "            acc += np.sum(y == tt)  # 예측이 맞은 갯수 카운트\n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):                     #아래의 gradient가 따로 있으니 주의.\n",
    "        \"\"\"기울기를 수치미분으로 계산한다.\"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)  # 손실 함수를 람다 함수로 정의\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            # 각 층의 가중치에 대해 수치미분 계산\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 오차역전파법으로 계산한다.\"\"\"\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 역전파\n",
    "        dout = 1  # 손실 함수의 기울기는 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        # 계층 역순으로 역전파 수행\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()                        #순서를 바꿔줌.\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        \"\"\"모델의 파라미터를 파일에 저장한다.\"\"\"\n",
    "        params = {}                                 #  새로운 딕셔너리 params 생성성\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val                       # 새로운 딕셔너리 params에 저장\n",
    "        with open(file_name, 'wb') as f:            # 'wb' 모드는 바이너리 쓰기(pickle은 객체를 이진형식으로 저장한다.)\n",
    "            pickle.dump(params, f)                  # pickle.dump()는 파이썬 객체를 파일에 저장하는 함수(파일 객체 f에 params를 dump(저장)함.)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        \"\"\"파일에서 모델의 파라미터를 로드한다.\"\"\"\n",
    "        with open(os.path.dirname(__file__) + '/' + file_name, 'rb') as f:          #'rb'는 read binary\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):       #enumerate는 파이썬에서 반복 가능한 객체(iterable)를 순회하면서 인덱스와 값을 동시에 반환하는 함수\n",
    "            # 각 계층에 파라미터 로드\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]            #각각의 class의 self.W와 self.b에 값들을 저장.\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300736457643319\n",
      "=== epoch:1, train acc:0.208, test acc:0.221 ===\n",
      "train loss:2.2988907334886863\n",
      "train loss:2.2969536370495387\n",
      "train loss:2.291843462075748\n",
      "train loss:2.285538358223709\n",
      "train loss:2.2801845415063\n",
      "train loss:2.2610518039330127\n",
      "train loss:2.251178439710075\n",
      "train loss:2.2461938442011338\n",
      "train loss:2.2081397650394923\n",
      "train loss:2.200117829696899\n",
      "train loss:2.168128890651122\n",
      "train loss:2.115663750909967\n",
      "train loss:2.0977460078378893\n",
      "train loss:2.033019918681853\n",
      "train loss:1.9885904710757134\n",
      "train loss:1.888799455717433\n",
      "train loss:1.7912619459917116\n",
      "train loss:1.7369246225169275\n",
      "train loss:1.7705761833190174\n",
      "train loss:1.687212086843517\n",
      "train loss:1.4972112809730813\n",
      "train loss:1.4557660370266763\n",
      "train loss:1.2930956146542862\n",
      "train loss:1.2356554749300086\n",
      "train loss:1.195330866602896\n",
      "train loss:1.105907764717787\n",
      "train loss:1.0617013318386128\n",
      "train loss:0.9339049786455577\n",
      "train loss:0.9693797380817587\n",
      "train loss:0.8236253132897633\n",
      "train loss:0.8976454250140651\n",
      "train loss:0.7726679948552134\n",
      "train loss:0.7686210503270031\n",
      "train loss:0.6491030395707642\n",
      "train loss:0.8086767819603456\n",
      "train loss:0.6877304570757987\n",
      "train loss:0.745306552702541\n",
      "train loss:0.6702259941142849\n",
      "train loss:0.6552389469933515\n",
      "train loss:0.6665724465040966\n",
      "train loss:0.590604993080935\n",
      "train loss:0.71344349120542\n",
      "train loss:0.58182831531202\n",
      "train loss:0.7225047606905709\n",
      "train loss:0.5162704426041446\n",
      "train loss:0.6887246775027304\n",
      "train loss:0.5115760831363032\n",
      "train loss:0.6354725666509625\n",
      "train loss:0.5221318372298388\n",
      "train loss:0.558279717584829\n",
      "train loss:0.579467621414983\n",
      "train loss:0.6162983032107937\n",
      "train loss:0.518872276531179\n",
      "train loss:0.6912538359431969\n",
      "train loss:0.5457111747656487\n",
      "train loss:0.367543157024699\n",
      "train loss:0.4715876537554104\n",
      "train loss:0.6022163696232609\n",
      "train loss:0.5466590515105637\n",
      "train loss:0.5272775399758399\n",
      "train loss:0.3065007899079498\n",
      "train loss:0.44212605318117504\n",
      "train loss:0.4168538030378572\n",
      "train loss:0.48760793950352477\n",
      "train loss:0.4073025909510062\n",
      "train loss:0.3363602657865443\n",
      "train loss:0.4121020509276211\n",
      "train loss:0.4626941383555739\n",
      "train loss:0.3017842417100922\n",
      "train loss:0.3052790714222517\n",
      "train loss:0.4429316646523641\n",
      "train loss:0.3916248449568504\n",
      "train loss:0.2881994514194801\n",
      "train loss:0.5359336907590583\n",
      "train loss:0.3923725250913798\n",
      "train loss:0.4811093546784452\n",
      "train loss:0.5321822051994182\n",
      "train loss:0.4614576580243687\n",
      "train loss:0.48568066212692335\n",
      "train loss:0.33816029000915165\n",
      "train loss:0.42188955906448194\n",
      "train loss:0.3517971053434356\n",
      "train loss:0.4230648202219644\n",
      "train loss:0.5953151186178712\n",
      "train loss:0.3540626875218303\n",
      "train loss:0.2850202574879366\n",
      "train loss:0.4879263760661573\n",
      "train loss:0.2991931681739031\n",
      "train loss:0.34688572394549305\n",
      "train loss:0.4407007249699072\n",
      "train loss:0.3250171628938231\n",
      "train loss:0.3476375452924103\n",
      "train loss:0.1537418177352175\n",
      "train loss:0.3731152618660471\n",
      "train loss:0.4385422528740168\n",
      "train loss:0.29907480004169407\n",
      "train loss:0.4280115368891673\n",
      "train loss:0.3073372526496722\n",
      "train loss:0.26814211409678645\n",
      "train loss:0.36107979328090783\n",
      "train loss:0.3840461222582373\n",
      "train loss:0.2944655496744546\n",
      "train loss:0.4349616076899576\n",
      "train loss:0.33971470260141323\n",
      "train loss:0.2889811742368222\n",
      "train loss:0.1986007668762131\n",
      "train loss:0.5793897962533981\n",
      "train loss:0.2939551510314855\n",
      "train loss:0.25438987838154503\n",
      "train loss:0.29701703753629605\n",
      "train loss:0.27886949562067953\n",
      "train loss:0.2873275516723037\n",
      "train loss:0.39017565134661936\n",
      "train loss:0.2744372723243258\n",
      "train loss:0.3996102850013197\n",
      "train loss:0.2658793616303287\n",
      "train loss:0.35555046054150274\n",
      "train loss:0.34944150635749804\n",
      "train loss:0.3484336234873656\n",
      "train loss:0.2515138881807177\n",
      "train loss:0.43795061206429226\n",
      "train loss:0.5852918955059402\n",
      "train loss:0.30136518525820466\n",
      "train loss:0.4692005418675657\n",
      "train loss:0.23199326805541598\n",
      "train loss:0.19545842549307435\n",
      "train loss:0.30660433000931425\n",
      "train loss:0.30930816948612483\n",
      "train loss:0.2658316691479977\n",
      "train loss:0.3791137791978278\n",
      "train loss:0.2982508059955563\n",
      "train loss:0.3626584369361845\n",
      "train loss:0.4174217803248574\n",
      "train loss:0.4895316673750759\n",
      "train loss:0.3344341431567138\n",
      "train loss:0.2992955360698012\n",
      "train loss:0.30798932677803587\n",
      "train loss:0.2815505255276879\n",
      "train loss:0.2437210094391643\n",
      "train loss:0.35208054801234895\n",
      "train loss:0.2022686247318202\n",
      "train loss:0.23313624185996723\n",
      "train loss:0.2305655455526317\n",
      "train loss:0.33637774110710195\n",
      "train loss:0.19499688199366966\n",
      "train loss:0.3365672209405222\n",
      "train loss:0.2764988121847523\n",
      "train loss:0.2999402896582742\n",
      "train loss:0.46916515916032464\n",
      "train loss:0.21836301650955722\n",
      "train loss:0.3083085713388992\n",
      "train loss:0.17238901862492123\n",
      "train loss:0.19320916619787745\n",
      "train loss:0.3755251736605311\n",
      "train loss:0.258131360249526\n",
      "train loss:0.407663114622556\n",
      "train loss:0.34450548249824076\n",
      "train loss:0.3267362494375962\n",
      "train loss:0.3782985957515803\n",
      "train loss:0.4936909830787306\n",
      "train loss:0.2632759846844942\n",
      "train loss:0.49310259480135893\n",
      "train loss:0.3874046204364744\n",
      "train loss:0.3222530534327943\n",
      "train loss:0.39837037656540586\n",
      "train loss:0.30313042914170885\n",
      "train loss:0.5256696959978803\n",
      "train loss:0.33839509889496777\n",
      "train loss:0.24891931819517044\n",
      "train loss:0.3505219097551031\n",
      "train loss:0.2303585869259523\n",
      "train loss:0.4055720815030194\n",
      "train loss:0.2407407432645701\n",
      "train loss:0.2949665518858241\n",
      "train loss:0.4706081005449858\n",
      "train loss:0.3608148008523525\n",
      "train loss:0.319178668168548\n",
      "train loss:0.39969658226976873\n",
      "train loss:0.43281027677797845\n",
      "train loss:0.29161286704540235\n",
      "train loss:0.2341353415086303\n",
      "train loss:0.31622868099638296\n",
      "train loss:0.2714438624954717\n",
      "train loss:0.15630110539425218\n",
      "train loss:0.21462760044030793\n",
      "train loss:0.29117831601838257\n",
      "train loss:0.32092834227559586\n",
      "train loss:0.18543337141050564\n",
      "train loss:0.47097927170109183\n",
      "train loss:0.3419612112310165\n",
      "train loss:0.17855210199667237\n",
      "train loss:0.32317991352574565\n",
      "train loss:0.27411828127965204\n",
      "train loss:0.3933981313890126\n",
      "train loss:0.24847950829650664\n",
      "train loss:0.2663890506197749\n",
      "train loss:0.2602639604641494\n",
      "train loss:0.4021379155992272\n",
      "train loss:0.22053861083069426\n",
      "train loss:0.5509251699056085\n",
      "train loss:0.2973574643861466\n",
      "train loss:0.3221017562514963\n",
      "train loss:0.2374406100435541\n",
      "train loss:0.1918736284985324\n",
      "train loss:0.24369815469308498\n",
      "train loss:0.3909219747816146\n",
      "train loss:0.3293094001301677\n",
      "train loss:0.24338222734207207\n",
      "train loss:0.37784663839989496\n",
      "train loss:0.32581713384063316\n",
      "train loss:0.3466370691729287\n",
      "train loss:0.2021668594760985\n",
      "train loss:0.38480470996540594\n",
      "train loss:0.14319340325721652\n",
      "train loss:0.33560036374123065\n",
      "train loss:0.3306898184517575\n",
      "train loss:0.1873762664889086\n",
      "train loss:0.2451238334344065\n",
      "train loss:0.2980753581546083\n",
      "train loss:0.32740622136562914\n",
      "train loss:0.26918458724552\n",
      "train loss:0.2755146125083589\n",
      "train loss:0.30528752729314235\n",
      "train loss:0.29223160430459993\n",
      "train loss:0.38454033771412405\n",
      "train loss:0.30356189202091566\n",
      "train loss:0.22171828825231898\n",
      "train loss:0.2606542085669354\n",
      "train loss:0.4130343019447118\n",
      "train loss:0.2242559642605131\n",
      "train loss:0.3000254463606256\n",
      "train loss:0.3033038875652879\n",
      "train loss:0.3205116482360053\n",
      "train loss:0.30043701085416297\n",
      "train loss:0.2689356755642696\n",
      "train loss:0.20221632596558098\n",
      "train loss:0.3480488023771555\n",
      "train loss:0.2630248760416207\n",
      "train loss:0.18076218796953328\n",
      "train loss:0.37515369321969855\n",
      "train loss:0.32307734805450294\n",
      "train loss:0.20720054705266644\n",
      "train loss:0.1785986388241413\n",
      "train loss:0.19640794345164145\n",
      "train loss:0.18450807792666807\n",
      "train loss:0.16602036630250422\n",
      "train loss:0.3156860645255019\n",
      "train loss:0.19455086700381816\n",
      "train loss:0.28506983830284177\n",
      "train loss:0.34090888802559627\n",
      "train loss:0.22421078174365935\n",
      "train loss:0.18783521021679664\n",
      "train loss:0.22718970222915846\n",
      "train loss:0.19637475822106942\n",
      "train loss:0.41290370387881004\n",
      "train loss:0.2546333132281515\n",
      "train loss:0.2730970530865736\n",
      "train loss:0.31166309872409786\n",
      "train loss:0.2252026846621476\n",
      "train loss:0.23958872194118158\n",
      "train loss:0.30369388212956994\n",
      "train loss:0.33332623134182593\n",
      "train loss:0.23191281028983124\n",
      "train loss:0.3046965077112434\n",
      "train loss:0.315420514781263\n",
      "train loss:0.17888772543403292\n",
      "train loss:0.15812694499514227\n",
      "train loss:0.28777165491016443\n",
      "train loss:0.16118403724201444\n",
      "train loss:0.18533102050144903\n",
      "train loss:0.1933634391935336\n",
      "train loss:0.20045638854647269\n",
      "train loss:0.2584974300653514\n",
      "train loss:0.15910141003468456\n",
      "train loss:0.11966931389942831\n",
      "train loss:0.2674887685993923\n",
      "train loss:0.23454767461906606\n",
      "train loss:0.23000463863079929\n",
      "train loss:0.2973312038566156\n",
      "train loss:0.28390241493291624\n",
      "train loss:0.3546571109070618\n",
      "train loss:0.28115742263996013\n",
      "train loss:0.2039350369395349\n",
      "train loss:0.2487256480166262\n",
      "train loss:0.14495874571408485\n",
      "train loss:0.2084092002070348\n",
      "train loss:0.4300269044848211\n",
      "train loss:0.1669035257511477\n",
      "train loss:0.31335270384371466\n",
      "train loss:0.2678758443023818\n",
      "train loss:0.1821184615831657\n",
      "train loss:0.39367193807820305\n",
      "train loss:0.18076746807048644\n",
      "train loss:0.10712989162766898\n",
      "train loss:0.21328659067974695\n",
      "train loss:0.2540843479201321\n",
      "train loss:0.23791672290945642\n",
      "train loss:0.23559385404618122\n",
      "train loss:0.33096316361381367\n",
      "train loss:0.24655009671129183\n",
      "train loss:0.3567646627879204\n",
      "train loss:0.18008965346312736\n",
      "train loss:0.20709662276959104\n",
      "train loss:0.1672733425610082\n",
      "train loss:0.1780249361912097\n",
      "train loss:0.21812484820194045\n",
      "train loss:0.16215799885410243\n",
      "train loss:0.14716766176835358\n",
      "train loss:0.2799204515981513\n",
      "train loss:0.18677766608041663\n",
      "train loss:0.289033163025358\n",
      "train loss:0.2403373183290202\n",
      "train loss:0.12953762990559678\n",
      "train loss:0.41658289148023475\n",
      "train loss:0.11470968529941467\n",
      "train loss:0.18955973470296986\n",
      "train loss:0.1280531092520981\n",
      "train loss:0.11245133491511171\n",
      "train loss:0.24042340731192674\n",
      "train loss:0.3302097622134697\n",
      "train loss:0.24464361413031738\n",
      "train loss:0.16886696833642453\n",
      "train loss:0.17564838200350455\n",
      "train loss:0.1336831971557132\n",
      "train loss:0.3022614076663846\n",
      "train loss:0.19011825605909116\n",
      "train loss:0.15322549953946\n",
      "train loss:0.1850111935968558\n",
      "train loss:0.31162754005591814\n",
      "train loss:0.16335380955873335\n",
      "train loss:0.24932493481853593\n",
      "train loss:0.18059088026078804\n",
      "train loss:0.20179354419482354\n",
      "train loss:0.12739338852810073\n",
      "train loss:0.22781358034953902\n",
      "train loss:0.1747748381505193\n",
      "train loss:0.2586386720094811\n",
      "train loss:0.22340652967563035\n",
      "train loss:0.1690394176933431\n",
      "train loss:0.2463094380989865\n",
      "train loss:0.3519566106117445\n",
      "train loss:0.2241151721208676\n",
      "train loss:0.23138648026778683\n",
      "train loss:0.19092459020089222\n",
      "train loss:0.11447015268179926\n",
      "train loss:0.22838216091303706\n",
      "train loss:0.16987952220118147\n",
      "train loss:0.17850881173413655\n",
      "train loss:0.3132326322828975\n",
      "train loss:0.23199218335284286\n",
      "train loss:0.19285617999270255\n",
      "train loss:0.16315776926761674\n",
      "train loss:0.2126694903559844\n",
      "train loss:0.2598081840545119\n",
      "train loss:0.3236678846813802\n",
      "train loss:0.23242884973213798\n",
      "train loss:0.13175443698256642\n",
      "train loss:0.15454174117484146\n",
      "train loss:0.1861620609152344\n",
      "train loss:0.1480195267449449\n",
      "train loss:0.15550527438927916\n",
      "train loss:0.24027154227614517\n",
      "train loss:0.25687460786405597\n",
      "train loss:0.17433460385585364\n",
      "train loss:0.22317071087997506\n",
      "train loss:0.21851478681933578\n",
      "train loss:0.0827674368071341\n",
      "train loss:0.23216401762381753\n",
      "train loss:0.15483953675921075\n",
      "train loss:0.16208738583597118\n",
      "train loss:0.19807148558842222\n",
      "train loss:0.16951122879361594\n",
      "train loss:0.12485973321053156\n",
      "train loss:0.12197902670180233\n",
      "train loss:0.18754176149055585\n",
      "train loss:0.1403183497108403\n",
      "train loss:0.22302758728591315\n",
      "train loss:0.12269082741635402\n",
      "train loss:0.21595031081731644\n",
      "train loss:0.12924122100778124\n",
      "train loss:0.13569975412463822\n",
      "train loss:0.22118612743186247\n",
      "train loss:0.29980138852433663\n",
      "train loss:0.24976820043995854\n",
      "train loss:0.18887912247287075\n",
      "train loss:0.21175377039526455\n",
      "train loss:0.13187164542738525\n",
      "train loss:0.25779813277210983\n",
      "train loss:0.205778301004027\n",
      "train loss:0.16032036026037383\n",
      "train loss:0.17666741664991936\n",
      "train loss:0.2162136170737241\n",
      "train loss:0.22565393361783073\n",
      "train loss:0.1379550222458114\n",
      "train loss:0.13908628584770147\n",
      "train loss:0.1314803670578421\n",
      "train loss:0.3261394968196453\n",
      "train loss:0.2523495350586229\n",
      "train loss:0.340009098820381\n",
      "train loss:0.14371992381608426\n",
      "train loss:0.1872910325336628\n",
      "train loss:0.23355576680683648\n",
      "train loss:0.25012638020102723\n",
      "train loss:0.1615833164901682\n",
      "train loss:0.24933352377272025\n",
      "train loss:0.1278430732326614\n",
      "train loss:0.35132207072828\n",
      "train loss:0.12505419691171646\n",
      "train loss:0.1621142883520654\n",
      "train loss:0.1422561035102386\n",
      "train loss:0.15064307422461223\n",
      "train loss:0.22736196262382002\n",
      "train loss:0.1430931968893832\n",
      "train loss:0.17566154823096472\n",
      "train loss:0.12356741462385848\n",
      "train loss:0.24001137802596845\n",
      "train loss:0.1765415891779263\n",
      "train loss:0.2926097120205064\n",
      "train loss:0.11390330004213416\n",
      "train loss:0.16276540280719032\n",
      "train loss:0.11345470217730108\n",
      "train loss:0.1303050347976434\n",
      "train loss:0.2390514387255033\n",
      "train loss:0.1543705344370932\n",
      "train loss:0.143249355693737\n",
      "train loss:0.13233150154970258\n",
      "train loss:0.18104718372340145\n",
      "train loss:0.1430010961488617\n",
      "train loss:0.2640047217601678\n",
      "train loss:0.1622021140697429\n",
      "train loss:0.10209727827427616\n",
      "train loss:0.13478828592639866\n",
      "train loss:0.15505630004077578\n",
      "train loss:0.11577587091775715\n",
      "train loss:0.1598091832538697\n",
      "train loss:0.10442680514691202\n",
      "train loss:0.15256225206095686\n",
      "train loss:0.17288488427235574\n",
      "train loss:0.2074909909509673\n",
      "train loss:0.12462047380709616\n",
      "train loss:0.23188946240996716\n",
      "train loss:0.15888310342341286\n",
      "train loss:0.12708895098460815\n",
      "train loss:0.12312911448306509\n",
      "train loss:0.1574799077945205\n",
      "train loss:0.08609687770285022\n",
      "train loss:0.12183579680282655\n",
      "train loss:0.08562355841795041\n",
      "train loss:0.15615315078176165\n",
      "train loss:0.10531264534169464\n",
      "train loss:0.24769938266330754\n",
      "train loss:0.1748521051146312\n",
      "train loss:0.1382938493071256\n",
      "train loss:0.12960941752838148\n",
      "train loss:0.14941008751303791\n",
      "train loss:0.2086410142100068\n",
      "train loss:0.08705126181562459\n",
      "train loss:0.17453852049136542\n",
      "train loss:0.06456327465931849\n",
      "train loss:0.13595992450797753\n",
      "train loss:0.13027910855572097\n",
      "train loss:0.19102447923095994\n",
      "train loss:0.11171614800154162\n",
      "train loss:0.12484647609118675\n",
      "train loss:0.21486265320602005\n",
      "train loss:0.16588229373341046\n",
      "train loss:0.2182573771517795\n",
      "train loss:0.11207259197313114\n",
      "train loss:0.12101640614795578\n",
      "train loss:0.20171656679609104\n",
      "train loss:0.10354662663812744\n",
      "train loss:0.11558461150670016\n",
      "train loss:0.13307025116550192\n",
      "train loss:0.16135453361673882\n",
      "train loss:0.10051098522804992\n",
      "train loss:0.1330428176859034\n",
      "train loss:0.25112570658317557\n",
      "train loss:0.13033814347504122\n",
      "train loss:0.14875374386197968\n",
      "train loss:0.0749934970737672\n",
      "train loss:0.11956222636769805\n",
      "train loss:0.22364800520227562\n",
      "train loss:0.10323484981051045\n",
      "train loss:0.1265554398507818\n",
      "train loss:0.15827687774697338\n",
      "train loss:0.16760786068206993\n",
      "train loss:0.10385845569522306\n",
      "train loss:0.1836484766866225\n",
      "train loss:0.23676549684746065\n",
      "train loss:0.13329680220009668\n",
      "train loss:0.10032794361564017\n",
      "train loss:0.13612243136379562\n",
      "train loss:0.12255805472901443\n",
      "train loss:0.09261667627409284\n",
      "train loss:0.23844693672702644\n",
      "train loss:0.11696891564546022\n",
      "train loss:0.15360306092768758\n",
      "train loss:0.1457425304321373\n",
      "train loss:0.1091840271732212\n",
      "train loss:0.2641268193577051\n",
      "train loss:0.059283838804302595\n",
      "train loss:0.17704881377612294\n",
      "train loss:0.13447923443018808\n",
      "train loss:0.12518314288979954\n",
      "train loss:0.13543336755162833\n",
      "train loss:0.05521304750022548\n",
      "train loss:0.20643041975610452\n",
      "train loss:0.1363230748346642\n",
      "train loss:0.08265419481938391\n",
      "train loss:0.15598450513575934\n",
      "train loss:0.15821649004292707\n",
      "train loss:0.15519011385115683\n",
      "train loss:0.04834163606704117\n",
      "train loss:0.15946227653524025\n",
      "train loss:0.13004141143844147\n",
      "train loss:0.18416799475953166\n",
      "train loss:0.11941133736842029\n",
      "train loss:0.13101549471613944\n",
      "train loss:0.172951492793959\n",
      "train loss:0.051031982139912724\n",
      "train loss:0.07903674546129709\n",
      "train loss:0.15925597704131658\n",
      "train loss:0.13800987833118536\n",
      "train loss:0.1706524223295153\n",
      "train loss:0.08112304122228993\n",
      "train loss:0.11629561805048151\n",
      "train loss:0.1050553962959445\n",
      "train loss:0.11422287937472751\n",
      "train loss:0.07115559504999211\n",
      "train loss:0.15346619051377555\n",
      "train loss:0.12036249958610754\n",
      "train loss:0.14697185503235047\n",
      "train loss:0.16072523368851385\n",
      "train loss:0.1414273315023783\n",
      "train loss:0.1978159376474692\n",
      "train loss:0.14361800076016787\n",
      "train loss:0.1330222976437034\n",
      "train loss:0.2092902142340417\n",
      "train loss:0.07335563433049648\n",
      "train loss:0.08471563373318963\n",
      "train loss:0.12038750550292124\n",
      "train loss:0.11596367784146847\n",
      "train loss:0.1186059422058503\n",
      "train loss:0.1284308255230327\n",
      "train loss:0.08877388566873262\n",
      "train loss:0.19040642118559845\n",
      "train loss:0.07823109895299132\n",
      "train loss:0.16647596538093445\n",
      "train loss:0.09568592673485558\n",
      "train loss:0.1444124116423048\n",
      "train loss:0.13193326977221248\n",
      "train loss:0.12371200400482167\n",
      "train loss:0.19651519846566448\n",
      "train loss:0.18221901887158815\n",
      "train loss:0.09737534072195694\n",
      "train loss:0.1281723656905913\n",
      "train loss:0.1312786546580921\n",
      "train loss:0.15516765407241792\n",
      "train loss:0.14568842597226359\n",
      "train loss:0.06956410427504095\n",
      "train loss:0.13244645303149857\n",
      "train loss:0.12635284991976925\n",
      "train loss:0.060178977028844595\n",
      "train loss:0.04636650516652216\n",
      "train loss:0.2186276023841365\n",
      "train loss:0.13379839392494086\n",
      "train loss:0.0951809725228296\n",
      "train loss:0.10054185845235551\n",
      "train loss:0.14020080299894744\n",
      "train loss:0.11879741476412171\n",
      "train loss:0.10616550489685281\n",
      "train loss:0.20323662186187771\n",
      "train loss:0.2824613481849253\n",
      "train loss:0.1199044740849307\n",
      "train loss:0.07155119299778166\n",
      "train loss:0.041975337991908376\n",
      "train loss:0.08673919686037732\n",
      "train loss:0.21891544746033836\n",
      "train loss:0.11149358262985803\n",
      "train loss:0.11527630740240888\n",
      "train loss:0.11487871447737044\n",
      "train loss:0.06340763868252756\n",
      "train loss:0.0868351106715222\n",
      "train loss:0.10622321164963333\n",
      "train loss:0.052062957723908905\n",
      "train loss:0.1292225200532852\n",
      "train loss:0.15751554630835207\n",
      "train loss:0.17669270835754958\n",
      "train loss:0.0571244594434301\n",
      "train loss:0.05810199919189234\n",
      "train loss:0.11770367011122113\n",
      "train loss:0.1775173305481819\n",
      "train loss:0.0886477613306712\n",
      "train loss:0.056056396379127627\n",
      "train loss:0.11375832661940427\n",
      "train loss:0.21486089415022566\n",
      "train loss:0.048630112794805856\n",
      "train loss:0.07617153726765304\n",
      "train loss:0.07287917127688794\n",
      "train loss:0.06930566155855897\n",
      "=== epoch:2, train acc:0.958, test acc:0.965 ===\n",
      "train loss:0.08316291038269874\n",
      "train loss:0.049253990272913446\n",
      "train loss:0.10965915829898114\n",
      "train loss:0.12162418116004092\n",
      "train loss:0.07671716422857759\n",
      "train loss:0.05378738220430709\n",
      "train loss:0.0642393604548533\n",
      "train loss:0.0420870593151324\n",
      "train loss:0.09221338142731456\n",
      "train loss:0.13106639248548724\n",
      "train loss:0.16612816354617368\n",
      "train loss:0.045657749161370866\n",
      "train loss:0.2247842996999972\n",
      "train loss:0.09877940748130942\n",
      "train loss:0.09499248625234345\n",
      "train loss:0.15707019994573018\n",
      "train loss:0.11737023154252434\n",
      "train loss:0.10510020375199083\n",
      "train loss:0.10873030272698646\n",
      "train loss:0.09291488775751432\n",
      "train loss:0.10930614824256395\n",
      "train loss:0.09423588743759428\n",
      "train loss:0.15069849239811706\n",
      "train loss:0.1665881637140183\n",
      "train loss:0.05855973527086986\n",
      "train loss:0.14610189499443552\n",
      "train loss:0.04280854488079368\n",
      "train loss:0.0677691041083211\n",
      "train loss:0.09297351809608115\n",
      "train loss:0.21087226383983282\n",
      "train loss:0.10322942716162524\n",
      "train loss:0.10614916902396491\n",
      "train loss:0.06319971839310265\n",
      "train loss:0.16171018518946906\n",
      "train loss:0.14810169712558255\n",
      "train loss:0.05362798955322532\n",
      "train loss:0.1165997663814451\n",
      "train loss:0.06533441631807904\n",
      "train loss:0.13025638865795514\n",
      "train loss:0.04788156649744035\n",
      "train loss:0.13893091138902716\n",
      "train loss:0.09837382669157974\n",
      "train loss:0.12227506035492773\n",
      "train loss:0.1539649730550385\n",
      "train loss:0.08442483925195318\n",
      "train loss:0.10981927571309137\n",
      "train loss:0.0808680977806353\n",
      "train loss:0.06968143426225469\n",
      "train loss:0.09689823292987729\n",
      "train loss:0.14315693814478164\n",
      "train loss:0.10732475698657212\n",
      "train loss:0.059343171332641734\n",
      "train loss:0.1399169123997605\n",
      "train loss:0.1212691276687462\n",
      "train loss:0.12307898363529118\n",
      "train loss:0.15715727793028025\n",
      "train loss:0.13001306289637227\n",
      "train loss:0.09251464872993856\n",
      "train loss:0.09154867574070889\n",
      "train loss:0.07847885333571689\n",
      "train loss:0.08960913413299573\n",
      "train loss:0.060368628131524445\n",
      "train loss:0.08187987502339905\n",
      "train loss:0.138048017868866\n",
      "train loss:0.07675154349927697\n",
      "train loss:0.08694278612609142\n",
      "train loss:0.13032794155736774\n",
      "train loss:0.13183970886041688\n",
      "train loss:0.15703558362794953\n",
      "train loss:0.14932792276536797\n",
      "train loss:0.1003895793961419\n",
      "train loss:0.24338175724576722\n",
      "train loss:0.09282340811326371\n",
      "train loss:0.17253231460972096\n",
      "train loss:0.15709242546181262\n",
      "train loss:0.22531252939130872\n",
      "train loss:0.13932990684613183\n",
      "train loss:0.08745631646470282\n",
      "train loss:0.19140271610842943\n",
      "train loss:0.06058595016527166\n",
      "train loss:0.04119223025449223\n",
      "train loss:0.06238391043459709\n",
      "train loss:0.031149453626333493\n",
      "train loss:0.09720775111385932\n",
      "train loss:0.12415000150061113\n",
      "train loss:0.11618117779595863\n",
      "train loss:0.06682990862880306\n",
      "train loss:0.12023254826005955\n",
      "train loss:0.07236023609286844\n",
      "train loss:0.069772134866541\n",
      "train loss:0.1091521298887777\n",
      "train loss:0.09056226936207395\n",
      "train loss:0.14395575642563385\n",
      "train loss:0.11469929048874156\n",
      "train loss:0.04823418169347876\n",
      "train loss:0.12099818999883862\n",
      "train loss:0.06025015157122821\n",
      "train loss:0.0779657078983442\n",
      "train loss:0.21103153484624051\n",
      "train loss:0.09344713957240376\n",
      "train loss:0.1059901380406905\n",
      "train loss:0.06366450829908997\n",
      "train loss:0.06448844349907315\n",
      "train loss:0.06308191472184149\n",
      "train loss:0.10432620525237098\n",
      "train loss:0.04583118000881054\n",
      "train loss:0.09012234440730134\n",
      "train loss:0.08902040301210498\n",
      "train loss:0.1659867569468838\n",
      "train loss:0.0785138254953338\n",
      "train loss:0.06625614753703664\n",
      "train loss:0.07389120378423548\n",
      "train loss:0.035661350231907266\n",
      "train loss:0.09189698525181134\n",
      "train loss:0.10212856502550142\n",
      "train loss:0.07295851983657807\n",
      "train loss:0.06854519071303712\n",
      "train loss:0.11274339660998602\n",
      "train loss:0.04985962276635186\n",
      "train loss:0.11030288443873561\n",
      "train loss:0.13377946503105778\n",
      "train loss:0.06118316282113853\n",
      "train loss:0.045579485580789995\n",
      "train loss:0.15161285807267175\n",
      "train loss:0.23379493307714003\n",
      "train loss:0.028796111323581758\n",
      "train loss:0.017062282328328113\n",
      "train loss:0.1612666639940537\n",
      "train loss:0.11211089156106892\n",
      "train loss:0.09293190586340255\n",
      "train loss:0.07101015620761819\n",
      "train loss:0.06084133496563832\n",
      "train loss:0.16130426291544134\n",
      "train loss:0.11984326986414542\n",
      "train loss:0.0870115026835685\n",
      "train loss:0.08466549154156572\n",
      "train loss:0.06477334638272125\n",
      "train loss:0.10220446382259013\n",
      "train loss:0.11476874681609474\n",
      "train loss:0.07340336319218062\n",
      "train loss:0.15810321606864902\n",
      "train loss:0.07912068056276056\n",
      "train loss:0.050276246612836945\n",
      "train loss:0.2388611496526764\n",
      "train loss:0.10779283370094142\n",
      "train loss:0.06719002029952488\n",
      "train loss:0.0429732166439675\n",
      "train loss:0.1092211838926478\n",
      "train loss:0.0329107584264755\n",
      "train loss:0.08710147775601552\n",
      "train loss:0.10013019778407588\n",
      "train loss:0.07816725440152247\n",
      "train loss:0.08089923119880896\n",
      "train loss:0.2111365224809616\n",
      "train loss:0.056649909582402805\n",
      "train loss:0.20881506069382777\n",
      "train loss:0.17393630322475417\n",
      "train loss:0.08325369745834257\n",
      "train loss:0.11427295149054671\n",
      "train loss:0.10669189034978947\n",
      "train loss:0.07776083959986199\n",
      "train loss:0.07095977491118083\n",
      "train loss:0.05145780436750612\n",
      "train loss:0.259518643345538\n",
      "train loss:0.08552309283779547\n",
      "train loss:0.05616299308126295\n",
      "train loss:0.025605011510662624\n",
      "train loss:0.08766461104503698\n",
      "train loss:0.05255710306087342\n",
      "train loss:0.09264444757951934\n",
      "train loss:0.09990622480340283\n",
      "train loss:0.08818137953768751\n",
      "train loss:0.2642708707696409\n",
      "train loss:0.087909708257618\n",
      "train loss:0.0679429580918367\n",
      "train loss:0.11117100313322174\n",
      "train loss:0.06468328570487267\n",
      "train loss:0.1241967280213486\n",
      "train loss:0.033750874907176036\n",
      "train loss:0.0886278025046854\n",
      "train loss:0.11316860148038249\n",
      "train loss:0.09501099628729082\n",
      "train loss:0.10634951925331552\n",
      "train loss:0.10841049632996355\n",
      "train loss:0.04587069585692153\n",
      "train loss:0.09300211333252964\n",
      "train loss:0.14858143977887997\n",
      "train loss:0.12135860403969544\n",
      "train loss:0.0415399499181422\n",
      "train loss:0.05400384048101448\n",
      "train loss:0.08306782137657491\n",
      "train loss:0.05358478394545821\n",
      "train loss:0.04213216305190492\n",
      "train loss:0.040681131239872846\n",
      "train loss:0.0768549179992657\n",
      "train loss:0.07525232977547859\n",
      "train loss:0.06440362472235464\n",
      "train loss:0.09094562370598747\n",
      "train loss:0.12307638419101709\n",
      "train loss:0.08304313048275247\n",
      "train loss:0.07666487084409691\n",
      "train loss:0.10254387722583966\n",
      "train loss:0.08235462999015014\n",
      "train loss:0.1081654177712667\n",
      "train loss:0.06439541010998562\n",
      "train loss:0.10609719009291446\n",
      "train loss:0.07328543420697263\n",
      "train loss:0.16554523729341064\n",
      "train loss:0.049790441795434515\n",
      "train loss:0.016020982814198788\n",
      "train loss:0.11566407500878416\n",
      "train loss:0.09450312420037306\n",
      "train loss:0.11862848828298764\n",
      "train loss:0.13299443067415936\n",
      "train loss:0.06438645165255469\n",
      "train loss:0.058344983131274605\n",
      "train loss:0.09570637614474546\n",
      "train loss:0.10158303339301225\n",
      "train loss:0.03886773261575907\n",
      "train loss:0.09355249200677608\n",
      "train loss:0.04037013535007834\n",
      "train loss:0.07793959027961843\n",
      "train loss:0.18030818167813278\n",
      "train loss:0.14747087596349384\n",
      "train loss:0.13242334968495928\n",
      "train loss:0.07955109154679675\n",
      "train loss:0.0968693556373794\n",
      "train loss:0.05362895595875192\n",
      "train loss:0.11263384859508703\n",
      "train loss:0.06645757480435013\n",
      "train loss:0.20880723741731186\n",
      "train loss:0.09004382421739276\n",
      "train loss:0.06162588623324287\n",
      "train loss:0.11098950505720014\n",
      "train loss:0.036336863755648985\n",
      "train loss:0.10790753746597005\n",
      "train loss:0.08263454810160456\n",
      "train loss:0.06455480013044687\n",
      "train loss:0.03470091415601452\n",
      "train loss:0.051231340527767316\n",
      "train loss:0.052563418792999084\n",
      "train loss:0.036143572295836486\n",
      "train loss:0.02073037673905482\n",
      "train loss:0.11182676223904656\n",
      "train loss:0.20515334403103533\n",
      "train loss:0.1283982654735519\n",
      "train loss:0.06890870793389339\n",
      "train loss:0.10931183182665205\n",
      "train loss:0.2212144706341591\n",
      "train loss:0.060570197809403675\n",
      "train loss:0.15274283452418577\n",
      "train loss:0.18125343847445882\n",
      "train loss:0.080365336733671\n",
      "train loss:0.055540330660368245\n",
      "train loss:0.05900929601407689\n",
      "train loss:0.11234901727194778\n",
      "train loss:0.05552451962275124\n",
      "train loss:0.06927483340747073\n",
      "train loss:0.10504511340622519\n",
      "train loss:0.11874071306447133\n",
      "train loss:0.1525301199868439\n",
      "train loss:0.18732891636161036\n",
      "train loss:0.12440788074246655\n",
      "train loss:0.03865221350963079\n",
      "train loss:0.050145232395806906\n",
      "train loss:0.05623716262864423\n",
      "train loss:0.12809177883243522\n",
      "train loss:0.057004221250796336\n",
      "train loss:0.0785837519166103\n",
      "train loss:0.1088723613627738\n",
      "train loss:0.06186662599229497\n",
      "train loss:0.02619275269103724\n",
      "train loss:0.11069058754996135\n",
      "train loss:0.038082277901095675\n",
      "train loss:0.11628176057041718\n",
      "train loss:0.04934073017245616\n",
      "train loss:0.04902515391009707\n",
      "train loss:0.04651322679950032\n",
      "train loss:0.05416364615796351\n",
      "train loss:0.04938449787877715\n",
      "train loss:0.0798161479693247\n",
      "train loss:0.03970002206674629\n",
      "train loss:0.05598000855990151\n",
      "train loss:0.11336275941382067\n",
      "train loss:0.04021359399720471\n",
      "train loss:0.07410856525579473\n",
      "train loss:0.057797269416288086\n",
      "train loss:0.11752499560457012\n",
      "train loss:0.0497384793244428\n",
      "train loss:0.05570064499123333\n",
      "train loss:0.04526241598420702\n",
      "train loss:0.1947535704519348\n",
      "train loss:0.05396881785482692\n",
      "train loss:0.12861918014122428\n",
      "train loss:0.10622469462708123\n",
      "train loss:0.028530852737919492\n",
      "train loss:0.09277449961137235\n",
      "train loss:0.06810320982478162\n",
      "train loss:0.0351775233681709\n",
      "train loss:0.074564884649363\n",
      "train loss:0.20618749823870477\n",
      "train loss:0.0981210036263545\n",
      "train loss:0.05505952254586866\n",
      "train loss:0.10316266984071382\n",
      "train loss:0.10469700261632495\n",
      "train loss:0.0503123876497206\n",
      "train loss:0.10557823463277201\n",
      "train loss:0.11399513759666453\n",
      "train loss:0.059337996221763376\n",
      "train loss:0.03925280018725407\n",
      "train loss:0.15657855639960305\n",
      "train loss:0.07559652726124076\n",
      "train loss:0.15826441985526055\n",
      "train loss:0.07477098303865953\n",
      "train loss:0.019211515154967537\n",
      "train loss:0.09094071255601432\n",
      "train loss:0.03220549358058274\n",
      "train loss:0.06239942525647699\n",
      "train loss:0.05480591755869571\n",
      "train loss:0.044505497288250116\n",
      "train loss:0.07201971154113006\n",
      "train loss:0.07524804937960233\n",
      "train loss:0.0429164296020188\n",
      "train loss:0.051820488012800335\n",
      "train loss:0.10163464726272757\n",
      "train loss:0.2896075768167495\n",
      "train loss:0.026738768301329346\n",
      "train loss:0.07794433350050575\n",
      "train loss:0.053114098824896094\n",
      "train loss:0.0952253232352938\n",
      "train loss:0.07769491297605068\n",
      "train loss:0.046745172677257266\n",
      "train loss:0.08010863150604396\n",
      "train loss:0.13065137561068563\n",
      "train loss:0.08616016602454472\n",
      "train loss:0.03337568445101904\n",
      "train loss:0.051802805895688336\n",
      "train loss:0.021073975949515353\n",
      "train loss:0.08331219681185659\n",
      "train loss:0.08348351232495649\n",
      "train loss:0.030946248591714128\n",
      "train loss:0.09941185042666095\n",
      "train loss:0.14312843841077805\n",
      "train loss:0.08343956587340744\n",
      "train loss:0.04015136586617277\n",
      "train loss:0.037192184820441995\n",
      "train loss:0.0441527895208416\n",
      "train loss:0.049193181238095275\n",
      "train loss:0.03831974037896258\n",
      "train loss:0.05119868757229124\n",
      "train loss:0.15349237638305693\n",
      "train loss:0.06937835803379182\n",
      "train loss:0.03177694399912109\n",
      "train loss:0.06745768504251083\n",
      "train loss:0.115514115665747\n",
      "train loss:0.1357831420163344\n",
      "train loss:0.12797724310133818\n",
      "train loss:0.1315754906101867\n",
      "train loss:0.02623649682783878\n",
      "train loss:0.0635318285320415\n",
      "train loss:0.020215905497774883\n",
      "train loss:0.0507523010800266\n",
      "train loss:0.0627401524020173\n",
      "train loss:0.08443539289098269\n",
      "train loss:0.06085245216821988\n",
      "train loss:0.13137651316699717\n",
      "train loss:0.07715899146648167\n",
      "train loss:0.017066444780951606\n",
      "train loss:0.06479616570446538\n",
      "train loss:0.0756842010996805\n",
      "train loss:0.021731468292767585\n",
      "train loss:0.10402325204550067\n",
      "train loss:0.07253057364784934\n",
      "train loss:0.04826854992044742\n",
      "train loss:0.04754734908945093\n",
      "train loss:0.2699300812329495\n",
      "train loss:0.06468231721865106\n",
      "train loss:0.05762157388903944\n",
      "train loss:0.08577696745494881\n",
      "train loss:0.09023752528908728\n",
      "train loss:0.1105838591718846\n",
      "train loss:0.03469138274595523\n",
      "train loss:0.10426414964168716\n",
      "train loss:0.022033584617213345\n",
      "train loss:0.04046261862328649\n",
      "train loss:0.055152663465724366\n",
      "train loss:0.06239136080686701\n",
      "train loss:0.04078794295627241\n",
      "train loss:0.033478625887239016\n",
      "train loss:0.07149511725717893\n",
      "train loss:0.051800731370328215\n",
      "train loss:0.04778070987380186\n",
      "train loss:0.05698335746040307\n",
      "train loss:0.06421699795389954\n",
      "train loss:0.07744136724676175\n",
      "train loss:0.053410470573251725\n",
      "train loss:0.05328770325380744\n",
      "train loss:0.08457892800752025\n",
      "train loss:0.08540277126676923\n",
      "train loss:0.06502639656629382\n",
      "train loss:0.042595446375092355\n",
      "train loss:0.11341001251461241\n",
      "train loss:0.03692327724160293\n",
      "train loss:0.07126289663232481\n",
      "train loss:0.05905203763980931\n",
      "train loss:0.03946290321972204\n",
      "train loss:0.05378340138624147\n",
      "train loss:0.07669465155352333\n",
      "train loss:0.03943724431072608\n",
      "train loss:0.10737931661484183\n",
      "train loss:0.011865508056614491\n",
      "train loss:0.05526845480587003\n",
      "train loss:0.03559701833970402\n",
      "train loss:0.04808672296602456\n",
      "train loss:0.08032624378820931\n",
      "train loss:0.029712451347348286\n",
      "train loss:0.09385112495242165\n",
      "train loss:0.0623045818963192\n",
      "train loss:0.038800866308284575\n",
      "train loss:0.043079257548121724\n",
      "train loss:0.1219446306466934\n",
      "train loss:0.12854301972875243\n",
      "train loss:0.09743546719249119\n",
      "train loss:0.19407442708789469\n",
      "train loss:0.06909744735561642\n",
      "train loss:0.09156000702139083\n",
      "train loss:0.05394283503158542\n",
      "train loss:0.10597312402388845\n",
      "train loss:0.08304491710052357\n",
      "train loss:0.08488896979368736\n",
      "train loss:0.07607335862260321\n",
      "train loss:0.254612673658942\n",
      "train loss:0.02103000512088354\n",
      "train loss:0.06646011099530315\n",
      "train loss:0.1111521009706695\n",
      "train loss:0.023209905303367178\n",
      "train loss:0.035466923778199384\n",
      "train loss:0.06481799674324155\n",
      "train loss:0.10303943129517057\n",
      "train loss:0.09905220468790374\n",
      "train loss:0.10601226113724009\n",
      "train loss:0.04309195245418837\n",
      "train loss:0.08754007306156916\n",
      "train loss:0.04546305455359214\n",
      "train loss:0.09157547514996515\n",
      "train loss:0.06633879185342363\n",
      "train loss:0.0977663624264355\n",
      "train loss:0.03446876237062553\n",
      "train loss:0.06670800031632057\n",
      "train loss:0.09771909297647582\n",
      "train loss:0.05685903852242585\n",
      "train loss:0.07149869030300199\n",
      "train loss:0.030928456160695474\n",
      "train loss:0.08290362120096142\n",
      "train loss:0.031536135597255696\n",
      "train loss:0.057031459050157614\n",
      "train loss:0.12701838827367518\n",
      "train loss:0.07650668481907687\n",
      "train loss:0.03807217605796948\n",
      "train loss:0.043309190431008365\n",
      "train loss:0.07091116551522983\n",
      "train loss:0.03212069757004999\n",
      "train loss:0.02280487761039975\n",
      "train loss:0.05425541384346871\n",
      "train loss:0.07971633884703969\n",
      "train loss:0.1180463099752957\n",
      "train loss:0.07219145654091161\n",
      "train loss:0.1268756132715673\n",
      "train loss:0.05773602154345843\n",
      "train loss:0.08054960951194445\n",
      "train loss:0.0425050767755268\n",
      "train loss:0.03590306312683655\n",
      "train loss:0.04690950598941436\n",
      "train loss:0.13760673341703922\n",
      "train loss:0.058749608124479276\n",
      "train loss:0.10327160878323458\n",
      "train loss:0.05736674029945342\n",
      "train loss:0.08398583216085806\n",
      "train loss:0.0355597102166271\n",
      "train loss:0.03492116050498754\n",
      "train loss:0.040810777916584454\n",
      "train loss:0.1446695438664988\n",
      "train loss:0.021500668750551254\n",
      "train loss:0.09804382014459145\n",
      "train loss:0.03058480640322542\n",
      "train loss:0.09022552863054079\n",
      "train loss:0.06891659442068099\n",
      "train loss:0.07418867265692831\n",
      "train loss:0.04635188153804244\n",
      "train loss:0.0577037591059802\n",
      "train loss:0.03872946712201829\n",
      "train loss:0.03194404714051673\n",
      "train loss:0.027532468989104223\n",
      "train loss:0.04832675557945097\n",
      "train loss:0.03714886519876545\n",
      "train loss:0.023633022011092117\n",
      "train loss:0.09808505733476379\n",
      "train loss:0.060369226039133236\n",
      "train loss:0.01967394221597106\n",
      "train loss:0.03007695321323882\n",
      "train loss:0.02892320225754681\n",
      "train loss:0.03422901749944538\n",
      "train loss:0.03023593587483083\n",
      "train loss:0.035623795401638125\n",
      "train loss:0.16989128864440026\n",
      "train loss:0.029990327035719397\n",
      "train loss:0.08847209396265714\n",
      "train loss:0.06570579119483949\n",
      "train loss:0.057602883240636046\n",
      "train loss:0.11761189097930837\n",
      "train loss:0.04235347902722056\n",
      "train loss:0.03166868142484292\n",
      "train loss:0.1318791097125397\n",
      "train loss:0.04204049383067556\n",
      "train loss:0.03396931833881015\n",
      "train loss:0.0808618744926305\n",
      "train loss:0.11592944429165732\n",
      "train loss:0.05653969880601977\n",
      "train loss:0.043904998054874265\n",
      "train loss:0.06231728150105162\n",
      "train loss:0.0989846391913629\n",
      "train loss:0.02304125195919255\n",
      "train loss:0.11545450691328804\n",
      "train loss:0.06067401511165483\n",
      "train loss:0.13456951044404675\n",
      "train loss:0.08993577187307217\n",
      "train loss:0.07953891841127655\n",
      "train loss:0.12124657762409197\n",
      "train loss:0.13693930649174774\n",
      "train loss:0.05486420280689331\n",
      "train loss:0.04915428440911101\n",
      "train loss:0.03815041993261346\n",
      "train loss:0.0924040476105103\n",
      "train loss:0.024667260967299095\n",
      "train loss:0.02897237805158028\n",
      "train loss:0.040172772391400366\n",
      "train loss:0.08431279481154925\n",
      "train loss:0.04231097102676476\n",
      "train loss:0.04197677619101711\n",
      "train loss:0.06989353385933907\n",
      "train loss:0.030136754659662247\n",
      "train loss:0.0612919582082939\n",
      "train loss:0.029256269412280447\n",
      "train loss:0.027916854896454422\n",
      "train loss:0.09151577496855076\n",
      "train loss:0.042170176067657446\n",
      "train loss:0.05345836861317371\n",
      "train loss:0.07877812288903242\n",
      "train loss:0.04815834390743829\n",
      "train loss:0.05222745727112665\n",
      "train loss:0.058179561934992366\n",
      "train loss:0.0806424585400011\n",
      "train loss:0.09708132930329388\n",
      "train loss:0.10780764528253309\n",
      "train loss:0.038645680715066744\n",
      "train loss:0.13058590472832765\n",
      "train loss:0.08443000566931079\n",
      "train loss:0.04743230256285505\n",
      "train loss:0.033710561742851856\n",
      "train loss:0.05931255917556781\n",
      "train loss:0.05697441780011428\n",
      "train loss:0.07350595848935063\n",
      "train loss:0.03278740306606162\n",
      "train loss:0.08335921089447398\n",
      "train loss:0.02445932183839882\n",
      "train loss:0.06497839704443308\n",
      "train loss:0.025190513770920343\n",
      "train loss:0.15919950077019318\n",
      "train loss:0.07977341681452256\n",
      "train loss:0.04430406447532611\n",
      "train loss:0.11629785260872703\n",
      "train loss:0.10282400826175014\n",
      "train loss:0.042776758775555715\n",
      "train loss:0.021443065135697895\n",
      "train loss:0.07643729865546443\n",
      "train loss:0.080218213862795\n",
      "train loss:0.021819916787078602\n",
      "train loss:0.040026856066216754\n",
      "train loss:0.039359516264718925\n",
      "train loss:0.012941328865317382\n",
      "train loss:0.04176795676160122\n",
      "train loss:0.01890925788936192\n",
      "train loss:0.01871276540506823\n",
      "train loss:0.03431299087442699\n",
      "train loss:0.0525949844773354\n",
      "train loss:0.06997708581614033\n",
      "train loss:0.048161877710140404\n",
      "train loss:0.09449831865213396\n",
      "train loss:0.029866818683512677\n",
      "train loss:0.014158068026672061\n",
      "train loss:0.015006623620313622\n",
      "train loss:0.09398932744189988\n",
      "train loss:0.033154630326510726\n",
      "train loss:0.028555123483785437\n",
      "train loss:0.040601440897598255\n",
      "train loss:0.02360406999644736\n",
      "train loss:0.05760304220612634\n",
      "train loss:0.02665601968338513\n",
      "train loss:0.14080565146744228\n",
      "train loss:0.024008084984249067\n",
      "=== epoch:3, train acc:0.975, test acc:0.977 ===\n",
      "train loss:0.060859795984799465\n",
      "train loss:0.024621264567558036\n",
      "train loss:0.05895232720823271\n",
      "train loss:0.014744460347202995\n",
      "train loss:0.016568630925252213\n",
      "train loss:0.03034145304485068\n",
      "train loss:0.09710149951179486\n",
      "train loss:0.029108521394200854\n",
      "train loss:0.05963794454442616\n",
      "train loss:0.02830753499201831\n",
      "train loss:0.049523838159291456\n",
      "train loss:0.04211258453044947\n",
      "train loss:0.15117456465200696\n",
      "train loss:0.05878948798984304\n",
      "train loss:0.1486962601889901\n",
      "train loss:0.07625695016063597\n",
      "train loss:0.040336009883860366\n",
      "train loss:0.03185106574454807\n",
      "train loss:0.04774749200767559\n",
      "train loss:0.07316986161431871\n",
      "train loss:0.10656517441019213\n",
      "train loss:0.06254496959144584\n",
      "train loss:0.04935503392779099\n",
      "train loss:0.05119473410684604\n",
      "train loss:0.08310331798585766\n",
      "train loss:0.05834746216786368\n",
      "train loss:0.07582270729503918\n",
      "train loss:0.07138841344964043\n",
      "train loss:0.03428250253763377\n",
      "train loss:0.086858726466245\n",
      "train loss:0.05681686262715505\n",
      "train loss:0.09806020061629518\n",
      "train loss:0.09593797742832139\n",
      "train loss:0.02588253004348029\n",
      "train loss:0.03341163894023457\n",
      "train loss:0.04648053167481765\n",
      "train loss:0.06970852619656971\n",
      "train loss:0.031067029693077473\n",
      "train loss:0.04205738515029307\n",
      "train loss:0.03640917628741615\n",
      "train loss:0.09856158107521665\n",
      "train loss:0.050390852967863727\n",
      "train loss:0.0258739786503306\n",
      "train loss:0.027287583583896956\n",
      "train loss:0.10840580078771231\n",
      "train loss:0.10526475216509144\n",
      "train loss:0.07655710676761321\n",
      "train loss:0.0804622455856052\n",
      "train loss:0.07456641615843297\n",
      "train loss:0.13431353144451177\n",
      "train loss:0.04041617765507821\n",
      "train loss:0.11405589756489144\n",
      "train loss:0.033350583115037954\n",
      "train loss:0.021934052178744997\n",
      "train loss:0.04374408243836461\n",
      "train loss:0.04847311140916487\n",
      "train loss:0.14089277416626955\n",
      "train loss:0.03219137521762428\n",
      "train loss:0.10423216284711835\n",
      "train loss:0.06783425324760949\n",
      "train loss:0.037312601398199335\n",
      "train loss:0.12168387955101957\n",
      "train loss:0.03195362700869229\n",
      "train loss:0.01701205752179944\n",
      "train loss:0.026149464780577173\n",
      "train loss:0.03222814816856987\n",
      "train loss:0.09299973663402639\n",
      "train loss:0.014398750956226081\n",
      "train loss:0.12070287884468696\n",
      "train loss:0.13280151299348555\n",
      "train loss:0.08039312312408697\n",
      "train loss:0.07842296780063421\n",
      "train loss:0.08954578352571131\n",
      "train loss:0.160254729459397\n",
      "train loss:0.15648232730250178\n",
      "train loss:0.05855879279500047\n",
      "train loss:0.026626302097704415\n",
      "train loss:0.059201633688553565\n",
      "train loss:0.06656761193312195\n",
      "train loss:0.050031433861532165\n",
      "train loss:0.14698432657957478\n",
      "train loss:0.04862903320513486\n",
      "train loss:0.08168224032561663\n",
      "train loss:0.03703195124140953\n",
      "train loss:0.0764108258581367\n",
      "train loss:0.02484193657035276\n",
      "train loss:0.03562047060295192\n",
      "train loss:0.045737000119891666\n",
      "train loss:0.020828893878811865\n",
      "train loss:0.05590773081243517\n",
      "train loss:0.08273137694225104\n",
      "train loss:0.03392643700994706\n",
      "train loss:0.038491884866670635\n",
      "train loss:0.04336871546687362\n",
      "train loss:0.0736173653625141\n",
      "train loss:0.08440991396220865\n",
      "train loss:0.0775620144324151\n",
      "train loss:0.07157935210486248\n",
      "train loss:0.01827559641612459\n",
      "train loss:0.025153096977752466\n",
      "train loss:0.04365797336964533\n",
      "train loss:0.014965075493906426\n",
      "train loss:0.02694644793089505\n",
      "train loss:0.03931488488601153\n",
      "train loss:0.11864493950306229\n",
      "train loss:0.060003016566919504\n",
      "train loss:0.1011201892166159\n",
      "train loss:0.18711818316144208\n",
      "train loss:0.08479960376409483\n",
      "train loss:0.01885207020518139\n",
      "train loss:0.06366141266543232\n",
      "train loss:0.030670618418416992\n",
      "train loss:0.09420844083434222\n",
      "train loss:0.02805323061962531\n",
      "train loss:0.07051121009160502\n",
      "train loss:0.05805647798400868\n",
      "train loss:0.12330589894006709\n",
      "train loss:0.023519161029779367\n",
      "train loss:0.04687601199393199\n",
      "train loss:0.06584858407054839\n",
      "train loss:0.06426410623574987\n",
      "train loss:0.03811881887448422\n",
      "train loss:0.049629661715486\n",
      "train loss:0.04988369230983191\n",
      "train loss:0.05585802719769757\n",
      "train loss:0.10735161543622568\n",
      "train loss:0.02615017091376236\n",
      "train loss:0.05138042501529958\n",
      "train loss:0.11648590945726493\n",
      "train loss:0.06201360341834132\n",
      "train loss:0.09405687418527958\n",
      "train loss:0.019734633725661622\n",
      "train loss:0.04642019031110733\n",
      "train loss:0.024345246666395384\n",
      "train loss:0.1101217399829271\n",
      "train loss:0.07838161366296074\n",
      "train loss:0.03637265873731326\n",
      "train loss:0.04446407837011202\n",
      "train loss:0.07036582638956385\n",
      "train loss:0.0902794745381668\n",
      "train loss:0.03086990134321429\n",
      "train loss:0.022324343919860525\n",
      "train loss:0.11793636550227012\n",
      "train loss:0.026875440352255593\n",
      "train loss:0.04775072262704176\n",
      "train loss:0.06824905104941092\n",
      "train loss:0.059039584047831974\n",
      "train loss:0.06226394972986852\n",
      "train loss:0.036730610034600444\n",
      "train loss:0.044039474237169154\n",
      "train loss:0.05484811600435438\n",
      "train loss:0.09824400568250756\n",
      "train loss:0.05732906485290832\n",
      "train loss:0.05712033943790379\n",
      "train loss:0.045932776468875156\n",
      "train loss:0.04916821275025666\n",
      "train loss:0.03238126032199282\n",
      "train loss:0.039724091026420015\n",
      "train loss:0.030357279707930417\n",
      "train loss:0.033338829851747784\n",
      "train loss:0.042431007429516214\n",
      "train loss:0.08734942184291088\n",
      "train loss:0.025309718108108142\n",
      "train loss:0.15821507483482394\n",
      "train loss:0.04313155098651951\n",
      "train loss:0.027420081509472723\n",
      "train loss:0.12324589089901657\n",
      "train loss:0.05751153473059951\n",
      "train loss:0.027284657227839505\n",
      "train loss:0.0318962491837702\n",
      "train loss:0.02464076303291516\n",
      "train loss:0.020283962359727584\n",
      "train loss:0.06689713530360158\n",
      "train loss:0.01636238197911256\n",
      "train loss:0.04521303761591114\n",
      "train loss:0.013231877625243629\n",
      "train loss:0.007401648320372126\n",
      "train loss:0.05202297788497769\n",
      "train loss:0.07957717251563187\n",
      "train loss:0.0390983977148998\n",
      "train loss:0.022954685293316787\n",
      "train loss:0.012114663551665586\n",
      "train loss:0.06584236065357706\n",
      "train loss:0.04568877941075354\n",
      "train loss:0.0340551700248115\n",
      "train loss:0.09044746441613359\n",
      "train loss:0.01020806193099416\n",
      "train loss:0.01742649432001935\n",
      "train loss:0.016846416196362478\n",
      "train loss:0.04463564269088404\n",
      "train loss:0.03811204302802011\n",
      "train loss:0.07760107007278423\n",
      "train loss:0.02267953896575863\n",
      "train loss:0.06299835650050677\n",
      "train loss:0.05193866621858418\n",
      "train loss:0.09280697331144026\n",
      "train loss:0.03364496385315054\n",
      "train loss:0.016441514625893387\n",
      "train loss:0.036990270317598724\n",
      "train loss:0.007534743309477299\n",
      "train loss:0.03483971611961512\n",
      "train loss:0.025995014919788645\n",
      "train loss:0.04911897539662891\n",
      "train loss:0.07376351083259822\n",
      "train loss:0.023504092502288042\n",
      "train loss:0.05160885878662816\n",
      "train loss:0.025982952051991314\n",
      "train loss:0.022772549651106602\n",
      "train loss:0.015338964889243332\n",
      "train loss:0.03219194848436245\n",
      "train loss:0.0882048860653322\n",
      "train loss:0.02507546058130508\n",
      "train loss:0.016845918274413646\n",
      "train loss:0.0700911718963953\n",
      "train loss:0.044069614435351186\n",
      "train loss:0.06493060788453107\n",
      "train loss:0.0704029053214385\n",
      "train loss:0.01659402676453142\n",
      "train loss:0.02113492507282363\n",
      "train loss:0.03413309492912914\n",
      "train loss:0.04070132531841319\n",
      "train loss:0.05162182788186834\n",
      "train loss:0.03097587723820574\n",
      "train loss:0.0204018111042829\n",
      "train loss:0.026495961237888638\n",
      "train loss:0.061495136312901356\n",
      "train loss:0.01003834609087204\n",
      "train loss:0.01761420697706552\n",
      "train loss:0.0692957313899881\n",
      "train loss:0.05222993693331577\n",
      "train loss:0.06166971211375081\n",
      "train loss:0.023890623095923363\n",
      "train loss:0.008956148568673194\n",
      "train loss:0.07286156746451695\n",
      "train loss:0.049463942699893175\n",
      "train loss:0.03729775694814529\n",
      "train loss:0.13047714850415762\n",
      "train loss:0.04040039623820183\n",
      "train loss:0.07543174680648408\n",
      "train loss:0.03509249609089326\n",
      "train loss:0.023960990617347497\n",
      "train loss:0.06535916676708908\n",
      "train loss:0.03516109948670407\n",
      "train loss:0.012759555520052873\n",
      "train loss:0.13523841119318022\n",
      "train loss:0.03167493460749104\n",
      "train loss:0.10724046311073691\n",
      "train loss:0.06452739459910826\n",
      "train loss:0.03864221749642359\n",
      "train loss:0.0209547184847209\n",
      "train loss:0.050871629420592715\n",
      "train loss:0.02040411119671413\n",
      "train loss:0.027432008628556184\n",
      "train loss:0.012915901205463041\n",
      "train loss:0.11386561878506639\n",
      "train loss:0.02967956159452137\n",
      "train loss:0.024593565303081655\n",
      "train loss:0.011265647981351908\n",
      "train loss:0.030999088232437865\n",
      "train loss:0.05147053414444577\n",
      "train loss:0.05203708665827672\n",
      "train loss:0.015556715228466252\n",
      "train loss:0.04216206701088617\n",
      "train loss:0.014591981330600518\n",
      "train loss:0.06715984362131486\n",
      "train loss:0.020712042762379906\n",
      "train loss:0.021845674362972353\n",
      "train loss:0.03767223367604863\n",
      "train loss:0.022218636655670622\n",
      "train loss:0.049492185247353396\n",
      "train loss:0.07228698676534914\n",
      "train loss:0.006973488917355505\n",
      "train loss:0.035452461300054396\n",
      "train loss:0.029536190356831065\n",
      "train loss:0.026632005507807838\n",
      "train loss:0.019420143384353522\n",
      "train loss:0.03507988451657637\n",
      "train loss:0.017237592073728242\n",
      "train loss:0.07483406851545457\n",
      "train loss:0.10266181785175593\n",
      "train loss:0.06289913393683413\n",
      "train loss:0.06655280578737029\n",
      "train loss:0.02417919997790417\n",
      "train loss:0.026955925494376417\n",
      "train loss:0.05106518300843963\n",
      "train loss:0.02853372863215747\n",
      "train loss:0.05778454492718341\n",
      "train loss:0.06059295533230782\n",
      "train loss:0.06680218966130719\n",
      "train loss:0.050256157652733516\n",
      "train loss:0.09650265860448547\n",
      "train loss:0.04412149463620488\n",
      "train loss:0.03585333021195175\n",
      "train loss:0.08917707386295443\n",
      "train loss:0.011762105143038083\n",
      "train loss:0.025964983927583504\n",
      "train loss:0.10896739233884116\n",
      "train loss:0.015590768598399545\n",
      "train loss:0.04847258810085209\n",
      "train loss:0.04678788283828668\n",
      "train loss:0.027083768527652215\n",
      "train loss:0.046386342212579285\n",
      "train loss:0.04446819170709841\n",
      "train loss:0.039654226531223906\n",
      "train loss:0.03695622269627069\n",
      "train loss:0.10165653760495916\n",
      "train loss:0.06142374756754573\n",
      "train loss:0.06351517933472062\n",
      "train loss:0.01631199956723413\n",
      "train loss:0.04002842666606171\n",
      "train loss:0.0503726321752332\n",
      "train loss:0.044004788659337185\n",
      "train loss:0.1629788808368488\n",
      "train loss:0.07484707729276534\n",
      "train loss:0.03070244362636372\n",
      "train loss:0.03289395198554221\n",
      "train loss:0.05583726989652428\n",
      "train loss:0.00788307418727261\n",
      "train loss:0.02891754586925223\n",
      "train loss:0.08744285336639318\n",
      "train loss:0.02284629901158715\n",
      "train loss:0.06741899052170759\n",
      "train loss:0.01276104980772218\n",
      "train loss:0.08540536210473387\n",
      "train loss:0.027763845432180956\n",
      "train loss:0.020206629545404073\n",
      "train loss:0.016562383550589185\n",
      "train loss:0.038879685387466806\n",
      "train loss:0.05285970783533155\n",
      "train loss:0.013369404088519747\n",
      "train loss:0.012002403965574051\n",
      "train loss:0.02093844238183074\n",
      "train loss:0.08151655872986906\n",
      "train loss:0.044588286385844784\n",
      "train loss:0.03255054792284739\n",
      "train loss:0.02494157553200017\n",
      "train loss:0.09010596676985465\n",
      "train loss:0.01668955712812253\n",
      "train loss:0.009470970810845141\n",
      "train loss:0.03515660608289856\n",
      "train loss:0.027764248006475607\n",
      "train loss:0.08537358341881736\n",
      "train loss:0.07063588478713598\n",
      "train loss:0.009895946045013433\n",
      "train loss:0.04989782197563801\n",
      "train loss:0.057208573678046035\n",
      "train loss:0.03429098654097425\n",
      "train loss:0.031834196819928676\n",
      "train loss:0.04482947436970494\n",
      "train loss:0.06137449255323842\n",
      "train loss:0.05131741190587746\n",
      "train loss:0.028141291988778804\n",
      "train loss:0.04228859539669212\n",
      "train loss:0.043976598490000844\n",
      "train loss:0.014549704684559905\n",
      "train loss:0.027785852518980504\n",
      "train loss:0.05129636926804957\n",
      "train loss:0.011248269949930452\n",
      "train loss:0.0813326935235572\n",
      "train loss:0.009130280488971038\n",
      "train loss:0.06399823399285087\n",
      "train loss:0.03718239181618301\n",
      "train loss:0.05924534232117015\n",
      "train loss:0.03715666985026989\n",
      "train loss:0.10991468094403568\n",
      "train loss:0.09061150810294119\n",
      "train loss:0.039859499845138785\n",
      "train loss:0.023731103407541743\n",
      "train loss:0.037068790380982965\n",
      "train loss:0.09321348181292466\n",
      "train loss:0.04430637113204537\n",
      "train loss:0.03843074478697238\n",
      "train loss:0.03559831752614328\n",
      "train loss:0.07797635671504835\n",
      "train loss:0.03281851387501014\n",
      "train loss:0.08246395194154232\n",
      "train loss:0.04052937811201501\n",
      "train loss:0.04728159020430401\n",
      "train loss:0.11519840523547879\n",
      "train loss:0.09485411742412225\n",
      "train loss:0.02962072744892616\n",
      "train loss:0.020240568278349014\n",
      "train loss:0.021591324001028527\n",
      "train loss:0.05179463188475083\n",
      "train loss:0.03485034997960514\n",
      "train loss:0.047367992083205454\n",
      "train loss:0.05535598088342569\n",
      "train loss:0.01219337310724155\n",
      "train loss:0.016169031619952118\n",
      "train loss:0.020238120834619306\n",
      "train loss:0.04391933366229099\n",
      "train loss:0.0487261593898401\n",
      "train loss:0.03472531499835281\n",
      "train loss:0.048759073457682385\n",
      "train loss:0.010121805806927075\n",
      "train loss:0.007387372755849295\n",
      "train loss:0.038401863456068386\n",
      "train loss:0.02250766594249925\n",
      "train loss:0.03302372559990438\n",
      "train loss:0.029983479452518735\n",
      "train loss:0.0299162640083102\n",
      "train loss:0.07390172745198999\n",
      "train loss:0.021446837873096286\n",
      "train loss:0.11877792878775136\n",
      "train loss:0.08836227652934191\n",
      "train loss:0.04926474013545122\n",
      "train loss:0.022831974104420793\n",
      "train loss:0.016668621089835033\n",
      "train loss:0.04365747480728362\n",
      "train loss:0.08718267763013587\n",
      "train loss:0.056514352138416865\n",
      "train loss:0.05908893332428424\n",
      "train loss:0.03381566661102844\n",
      "train loss:0.049047308633553034\n",
      "train loss:0.040028561621863405\n",
      "train loss:0.06760773946263873\n",
      "train loss:0.031376158405276945\n",
      "train loss:0.04309947011910018\n",
      "train loss:0.01342056153969719\n",
      "train loss:0.025732777404914087\n",
      "train loss:0.0935167915729041\n",
      "train loss:0.02004732862059508\n",
      "train loss:0.045523706912489824\n",
      "train loss:0.04905525628474934\n",
      "train loss:0.020389204802196585\n",
      "train loss:0.036251055046057246\n",
      "train loss:0.053799992663070346\n",
      "train loss:0.037531077281275575\n",
      "train loss:0.027816918214056595\n",
      "train loss:0.023286175531644776\n",
      "train loss:0.04162826484120216\n",
      "train loss:0.026081911395714204\n",
      "train loss:0.02296269311430997\n",
      "train loss:0.06934937257346106\n",
      "train loss:0.11786705969175014\n",
      "train loss:0.07440775245864358\n",
      "train loss:0.01699189306165622\n",
      "train loss:0.06298167625603748\n",
      "train loss:0.08064222833069247\n",
      "train loss:0.04546401034939127\n",
      "train loss:0.04627170897249445\n",
      "train loss:0.025506777662817292\n",
      "train loss:0.08019895193833566\n",
      "train loss:0.01922328770984121\n",
      "train loss:0.057422633755818124\n",
      "train loss:0.08708949126406446\n",
      "train loss:0.07278753717485296\n",
      "train loss:0.11476961462598231\n",
      "train loss:0.01485998689639334\n",
      "train loss:0.04926756982772193\n",
      "train loss:0.07376580897170962\n",
      "train loss:0.037220074486724826\n",
      "train loss:0.05908291755662828\n",
      "train loss:0.10043870882286246\n",
      "train loss:0.06089090134655268\n",
      "train loss:0.02690733064363586\n",
      "train loss:0.07249088066458477\n",
      "train loss:0.012998842591024452\n",
      "train loss:0.008302893981643418\n",
      "train loss:0.021604844318969568\n",
      "train loss:0.05246435095352207\n",
      "train loss:0.10190342884515757\n",
      "train loss:0.021797101839284266\n",
      "train loss:0.047833509899168264\n",
      "train loss:0.023834257112926256\n",
      "train loss:0.06330548927398333\n",
      "train loss:0.03336918899386901\n",
      "train loss:0.045601195037875006\n",
      "train loss:0.02837744891049387\n",
      "train loss:0.01492168042982344\n",
      "train loss:0.019417259585348835\n",
      "train loss:0.025746257325341474\n",
      "train loss:0.023955056241737577\n",
      "train loss:0.027995642357920455\n",
      "train loss:0.06359207313025342\n",
      "train loss:0.08706698448131531\n",
      "train loss:0.018866611054530958\n",
      "train loss:0.02122475245952749\n",
      "train loss:0.07826865202532993\n",
      "train loss:0.06562730681011693\n",
      "train loss:0.07598677472261467\n",
      "train loss:0.07645646861884033\n",
      "train loss:0.01950538364593133\n",
      "train loss:0.02862619300488929\n",
      "train loss:0.01613567286961849\n",
      "train loss:0.01834106193271332\n",
      "train loss:0.06986862551713902\n",
      "train loss:0.030913810720769503\n",
      "train loss:0.029006040857071674\n",
      "train loss:0.021540520155012177\n",
      "train loss:0.039850822589630776\n",
      "train loss:0.03669344329945334\n",
      "train loss:0.0463615594995039\n",
      "train loss:0.0811732483776338\n",
      "train loss:0.1067045795995582\n",
      "train loss:0.02549701670744404\n",
      "train loss:0.07564562076858157\n",
      "train loss:0.01914575314823322\n",
      "train loss:0.01743540684756285\n",
      "train loss:0.01973688055879868\n",
      "train loss:0.08244175436803453\n",
      "train loss:0.019131510500878267\n",
      "train loss:0.02074585115054788\n",
      "train loss:0.021995675292843207\n",
      "train loss:0.030225101210847365\n",
      "train loss:0.01044779511250038\n",
      "train loss:0.023569295092334786\n",
      "train loss:0.05772094208006977\n",
      "train loss:0.08117572851117125\n",
      "train loss:0.0355169760987286\n",
      "train loss:0.01341180601640886\n",
      "train loss:0.025211225245020574\n",
      "train loss:0.004860093032939095\n",
      "train loss:0.01470801782044786\n",
      "train loss:0.053470189154194214\n",
      "train loss:0.03941051637670758\n",
      "train loss:0.023607297898364542\n",
      "train loss:0.02896108362278002\n",
      "train loss:0.015224112374352174\n",
      "train loss:0.024618090532125478\n",
      "train loss:0.033279930526936785\n",
      "train loss:0.07575987889822444\n",
      "train loss:0.023058879310614473\n",
      "train loss:0.054179793199281526\n",
      "train loss:0.03351622974093665\n",
      "train loss:0.08048991695109235\n",
      "train loss:0.014931414778059135\n",
      "train loss:0.061724929921071314\n",
      "train loss:0.07344812482509658\n",
      "train loss:0.05026872196594254\n",
      "train loss:0.07374413027752101\n",
      "train loss:0.04321205656683975\n",
      "train loss:0.011107537939328666\n",
      "train loss:0.0388344286319914\n",
      "train loss:0.04640567153705717\n",
      "train loss:0.08023338566988338\n",
      "train loss:0.022111027224312\n",
      "train loss:0.06774195557231195\n",
      "train loss:0.012745858014431963\n",
      "train loss:0.059858581451945614\n",
      "train loss:0.03383179538245496\n",
      "train loss:0.04163601874459737\n",
      "train loss:0.020441474534882372\n",
      "train loss:0.03467259030241902\n",
      "train loss:0.018488035342615543\n",
      "train loss:0.04161810959689119\n",
      "train loss:0.06394483217948231\n",
      "train loss:0.017798265352713925\n",
      "train loss:0.04099649032019488\n",
      "train loss:0.03321488256514756\n",
      "train loss:0.03541617233598272\n",
      "train loss:0.05063513652635268\n",
      "train loss:0.04188110551299515\n",
      "train loss:0.046752320587970894\n",
      "train loss:0.0505734659920293\n",
      "train loss:0.020573677043506086\n",
      "train loss:0.04165785670284148\n",
      "train loss:0.022839994309084077\n",
      "train loss:0.08667839700332532\n",
      "train loss:0.055596182444889154\n",
      "train loss:0.051886467241868246\n",
      "train loss:0.04824637834707523\n",
      "train loss:0.02518379903195818\n",
      "train loss:0.022713160371471686\n",
      "train loss:0.02629620504410172\n",
      "train loss:0.019910801562526306\n",
      "train loss:0.01943163088254007\n",
      "train loss:0.03707302692792778\n",
      "train loss:0.04132656271575743\n",
      "train loss:0.022441557573571465\n",
      "train loss:0.07205588779330717\n",
      "train loss:0.011255026561743202\n",
      "train loss:0.07386268657874465\n",
      "train loss:0.06458864654219339\n",
      "train loss:0.021716659133955072\n",
      "train loss:0.01200376011526095\n",
      "train loss:0.03801540288080618\n",
      "train loss:0.038097567222903944\n",
      "train loss:0.007051283044318307\n",
      "train loss:0.04330887816995495\n",
      "train loss:0.02906237275754558\n",
      "train loss:0.02788181679682213\n",
      "train loss:0.040105715028046135\n",
      "train loss:0.03433720704587636\n",
      "train loss:0.02591130809227281\n",
      "train loss:0.017745191206903984\n",
      "train loss:0.049997912149616595\n",
      "train loss:0.029324851107172315\n",
      "train loss:0.04222562586705575\n",
      "train loss:0.01752249217419774\n",
      "train loss:0.02985634560233252\n",
      "train loss:0.1143658802354434\n",
      "train loss:0.051251725910620716\n",
      "train loss:0.044834526070931406\n",
      "train loss:0.022928922280740102\n",
      "train loss:0.14680199816585535\n",
      "train loss:0.038514238683169215\n",
      "train loss:0.020473436437436113\n",
      "train loss:0.029018569604320223\n",
      "train loss:0.06236525326355093\n",
      "=== epoch:4, train acc:0.983, test acc:0.974 ===\n",
      "train loss:0.050072274079737376\n",
      "train loss:0.018114493497781544\n",
      "train loss:0.018848812686296953\n",
      "train loss:0.0582893550656619\n",
      "train loss:0.06956135372249714\n",
      "train loss:0.014004839412129808\n",
      "train loss:0.037119296065235\n",
      "train loss:0.01918176762327777\n",
      "train loss:0.00953538321212221\n",
      "train loss:0.028456900358433845\n",
      "train loss:0.06669742679912163\n",
      "train loss:0.05008509428177552\n",
      "train loss:0.07386786755744584\n",
      "train loss:0.02816122171757295\n",
      "train loss:0.011096604418612965\n",
      "train loss:0.028835445671569294\n",
      "train loss:0.043507642766760134\n",
      "train loss:0.054447892152335885\n",
      "train loss:0.01129473372112845\n",
      "train loss:0.010425826404035776\n",
      "train loss:0.024660261621654113\n",
      "train loss:0.10731156096142486\n",
      "train loss:0.02643544662992868\n",
      "train loss:0.031744339440571624\n",
      "train loss:0.02451051266851458\n",
      "train loss:0.04480469281447551\n",
      "train loss:0.016194739729008766\n",
      "train loss:0.056919259114622915\n",
      "train loss:0.03354809526369742\n",
      "train loss:0.017515250843196672\n",
      "train loss:0.027205416965310158\n",
      "train loss:0.0791118841500974\n",
      "train loss:0.08775793985040412\n",
      "train loss:0.030546064713441456\n",
      "train loss:0.11391508479526022\n",
      "train loss:0.03678049286001731\n",
      "train loss:0.031630785399650384\n",
      "train loss:0.022930752386936443\n",
      "train loss:0.08791743466771948\n",
      "train loss:0.043675553841528714\n",
      "train loss:0.03147466549706202\n",
      "train loss:0.02850235598216733\n",
      "train loss:0.056960411244572226\n",
      "train loss:0.051998794818818105\n",
      "train loss:0.0498149657575292\n",
      "train loss:0.02297422252221971\n",
      "train loss:0.022400808658653397\n",
      "train loss:0.0417038410106407\n",
      "train loss:0.015713437936759854\n",
      "train loss:0.04526049257554114\n",
      "train loss:0.021055674345573795\n",
      "train loss:0.034388971265543654\n",
      "train loss:0.102321293846387\n",
      "train loss:0.036116696266357454\n",
      "train loss:0.01697073575316709\n",
      "train loss:0.039910672346211595\n",
      "train loss:0.03731140759760751\n",
      "train loss:0.051899339827666126\n",
      "train loss:0.015326560799531047\n",
      "train loss:0.08173341706180123\n",
      "train loss:0.03355991273482402\n",
      "train loss:0.033233156928461204\n",
      "train loss:0.013750407654517273\n",
      "train loss:0.017265894260660226\n",
      "train loss:0.02617719581453356\n",
      "train loss:0.02519504683901359\n",
      "train loss:0.054967330508522316\n",
      "train loss:0.11552832430072245\n",
      "train loss:0.010737990113369185\n",
      "train loss:0.14417632167813862\n",
      "train loss:0.020335526510322666\n",
      "train loss:0.023851697695377122\n",
      "train loss:0.01386091235407546\n",
      "train loss:0.06446148975864745\n",
      "train loss:0.04482558490913495\n",
      "train loss:0.11868601023406684\n",
      "train loss:0.09342784915866958\n",
      "train loss:0.0645572639127285\n",
      "train loss:0.05254210142658097\n",
      "train loss:0.024995513813773195\n",
      "train loss:0.022592633357701973\n",
      "train loss:0.06075702434921885\n",
      "train loss:0.026060151157196107\n",
      "train loss:0.051351781750841374\n",
      "train loss:0.028579534108148844\n",
      "train loss:0.03046969596527183\n",
      "train loss:0.10054655454556205\n",
      "train loss:0.054178520806636626\n",
      "train loss:0.08284355021284737\n",
      "train loss:0.05104643957257329\n",
      "train loss:0.019141537563372918\n",
      "train loss:0.033439053523343115\n",
      "train loss:0.020441360928238134\n",
      "train loss:0.02769021439313326\n",
      "train loss:0.06331164599040293\n",
      "train loss:0.030662546535575975\n",
      "train loss:0.04545375922112167\n",
      "train loss:0.021823474577091346\n",
      "train loss:0.026404559402689452\n",
      "train loss:0.01900353793109453\n",
      "train loss:0.039022448868484855\n",
      "train loss:0.017157500952243318\n",
      "train loss:0.04072122868131934\n",
      "train loss:0.03421037960574711\n",
      "train loss:0.009607295526295663\n",
      "train loss:0.008451494008718276\n",
      "train loss:0.03803159038198228\n",
      "train loss:0.03237826586595533\n",
      "train loss:0.029708479835269395\n",
      "train loss:0.04786892540183537\n",
      "train loss:0.06763319902364265\n",
      "train loss:0.1202133576186009\n",
      "train loss:0.04564884760331054\n",
      "train loss:0.01946407668264388\n",
      "train loss:0.012365070458567645\n",
      "train loss:0.031641168640562566\n",
      "train loss:0.0350696908115594\n",
      "train loss:0.025438602910408368\n",
      "train loss:0.03361695436295503\n",
      "train loss:0.01797205142210359\n",
      "train loss:0.0674523509121192\n",
      "train loss:0.009140623581987582\n",
      "train loss:0.09722500233772972\n",
      "train loss:0.01763266040209631\n",
      "train loss:0.029103764709982924\n",
      "train loss:0.006997050733253078\n",
      "train loss:0.025673770758023004\n",
      "train loss:0.10121707036946911\n",
      "train loss:0.04907334993472445\n",
      "train loss:0.010156911580081758\n",
      "train loss:0.016017695611088265\n",
      "train loss:0.02633818395536298\n",
      "train loss:0.03320705321386619\n",
      "train loss:0.027968208463651792\n",
      "train loss:0.022348814918274246\n",
      "train loss:0.05911355767392107\n",
      "train loss:0.024597690393732437\n",
      "train loss:0.04297753433007812\n",
      "train loss:0.024010106478185907\n",
      "train loss:0.06598530325083705\n",
      "train loss:0.012179770270361902\n",
      "train loss:0.051825043344737545\n",
      "train loss:0.03948201662983006\n",
      "train loss:0.0959009538941882\n",
      "train loss:0.07590423442019059\n",
      "train loss:0.01673388506884612\n",
      "train loss:0.04211292155861834\n",
      "train loss:0.02805246083447712\n",
      "train loss:0.02179034916617617\n",
      "train loss:0.030903905329911295\n",
      "train loss:0.0371573002516675\n",
      "train loss:0.01688674435013833\n",
      "train loss:0.022993783469746943\n",
      "train loss:0.008953744944038944\n",
      "train loss:0.10172000693609334\n",
      "train loss:0.04668903478242854\n",
      "train loss:0.019113253456345812\n",
      "train loss:0.01765786620858797\n",
      "train loss:0.0035860927883697097\n",
      "train loss:0.01674718630902657\n",
      "train loss:0.09407929558850114\n",
      "train loss:0.06916952579831791\n",
      "train loss:0.03125794498725826\n",
      "train loss:0.053156863127906934\n",
      "train loss:0.012669151285657038\n",
      "train loss:0.008408148382074274\n",
      "train loss:0.010400341243316156\n",
      "train loss:0.022258576291841293\n",
      "train loss:0.02714859812702296\n",
      "train loss:0.012814870964333884\n",
      "train loss:0.0339051697630563\n",
      "train loss:0.03655190076542827\n",
      "train loss:0.035177878549432766\n",
      "train loss:0.08068789761132601\n",
      "train loss:0.00768502538232219\n",
      "train loss:0.04457434983759584\n",
      "train loss:0.015898502074889402\n",
      "train loss:0.043068284392804655\n",
      "train loss:0.05287830474832621\n",
      "train loss:0.04647261978838975\n",
      "train loss:0.12387921920112634\n",
      "train loss:0.020688551578659536\n",
      "train loss:0.010724153312393354\n",
      "train loss:0.040403670622665144\n",
      "train loss:0.020327740130338605\n",
      "train loss:0.03634060223237942\n",
      "train loss:0.04435482378664761\n",
      "train loss:0.01614626844720589\n",
      "train loss:0.12183426359633769\n",
      "train loss:0.01055157706507234\n",
      "train loss:0.009111108197498167\n",
      "train loss:0.006373751089770241\n",
      "train loss:0.117671074817941\n",
      "train loss:0.019529777175992035\n",
      "train loss:0.046712760776408783\n",
      "train loss:0.04403668006974442\n",
      "train loss:0.010065008681377266\n",
      "train loss:0.052609805918822944\n",
      "train loss:0.04434399792721418\n",
      "train loss:0.013630184881967813\n",
      "train loss:0.05140376991745236\n",
      "train loss:0.02612390437823164\n",
      "train loss:0.060991215217190115\n",
      "train loss:0.041527910912218635\n",
      "train loss:0.03604311651834858\n",
      "train loss:0.010735999961151243\n",
      "train loss:0.047034185563987904\n",
      "train loss:0.036998995822469787\n",
      "train loss:0.019206775372603947\n",
      "train loss:0.014458393158823793\n",
      "train loss:0.010668289397722628\n",
      "train loss:0.07060250839626311\n",
      "train loss:0.1571139675510834\n",
      "train loss:0.02962097493784114\n",
      "train loss:0.08492633253928364\n",
      "train loss:0.033946900095630395\n",
      "train loss:0.04000013135145606\n",
      "train loss:0.06603035833723242\n",
      "train loss:0.032527156748763185\n",
      "train loss:0.09828143058254865\n",
      "train loss:0.048600453400045235\n",
      "train loss:0.01693272859387047\n",
      "train loss:0.013224346583932303\n",
      "train loss:0.0132764400561105\n",
      "train loss:0.046555399041668624\n",
      "train loss:0.03996260069846007\n",
      "train loss:0.022925567616971218\n",
      "train loss:0.05530683220350256\n",
      "train loss:0.007071891151125079\n",
      "train loss:0.0549408856259605\n",
      "train loss:0.04338246935570239\n",
      "train loss:0.009106062664164034\n",
      "train loss:0.004569801740096185\n",
      "train loss:0.035296058339373555\n",
      "train loss:0.028499421097730213\n",
      "train loss:0.08212678376201668\n",
      "train loss:0.023973337326436653\n",
      "train loss:0.01808322431249256\n",
      "train loss:0.06709475857698624\n",
      "train loss:0.014542544952449318\n",
      "train loss:0.08817688240956269\n",
      "train loss:0.02340926153255842\n",
      "train loss:0.03235883429271456\n",
      "train loss:0.047839096075326805\n",
      "train loss:0.024835910703089225\n",
      "train loss:0.03529775898293081\n",
      "train loss:0.00779878715252131\n",
      "train loss:0.008703119499413617\n",
      "train loss:0.04369673141625792\n",
      "train loss:0.02095677534107582\n",
      "train loss:0.010415076222294938\n",
      "train loss:0.06712866024713744\n",
      "train loss:0.011249333920297082\n",
      "train loss:0.03925655757274464\n",
      "train loss:0.025905665230883793\n",
      "train loss:0.010239502416479132\n",
      "train loss:0.05351438803411077\n",
      "train loss:0.05894347500267713\n",
      "train loss:0.05124364917966766\n",
      "train loss:0.0087130418905008\n",
      "train loss:0.04855063129854782\n",
      "train loss:0.014516301390812307\n",
      "train loss:0.01308055530536141\n",
      "train loss:0.02727594640693722\n",
      "train loss:0.011996641974912086\n",
      "train loss:0.09041662120327379\n",
      "train loss:0.01655331896396888\n",
      "train loss:0.0633605012285388\n",
      "train loss:0.03170514522874325\n",
      "train loss:0.01598547092044161\n",
      "train loss:0.10749928590032314\n",
      "train loss:0.023019236729964594\n",
      "train loss:0.06775520138860905\n",
      "train loss:0.058419661532065036\n",
      "train loss:0.03460310831774772\n",
      "train loss:0.047044245970621165\n",
      "train loss:0.024399795221512487\n",
      "train loss:0.01198357564438801\n",
      "train loss:0.011735095143784463\n",
      "train loss:0.0254414163261735\n",
      "train loss:0.03488502325185534\n",
      "train loss:0.01580049940578711\n",
      "train loss:0.0661921137899671\n",
      "train loss:0.015364101636201182\n",
      "train loss:0.05318821055741551\n",
      "train loss:0.044982293955122155\n",
      "train loss:0.020321270010793424\n",
      "train loss:0.05961107404171137\n",
      "train loss:0.027904412320010893\n",
      "train loss:0.025197757929094983\n",
      "train loss:0.022410526801569436\n",
      "train loss:0.01762702144243532\n",
      "train loss:0.01660588113283611\n",
      "train loss:0.011096683761539288\n",
      "train loss:0.031478287941086314\n",
      "train loss:0.09569288833421619\n",
      "train loss:0.017143210841396507\n",
      "train loss:0.02043460360158613\n",
      "train loss:0.023745983903819715\n",
      "train loss:0.0608171466898554\n",
      "train loss:0.020687272336031865\n",
      "train loss:0.011034843472964278\n",
      "train loss:0.09088168401138647\n",
      "train loss:0.059580921325383604\n",
      "train loss:0.01872339538902274\n",
      "train loss:0.023145793566628957\n",
      "train loss:0.05328377601876652\n",
      "train loss:0.013075685526274718\n",
      "train loss:0.012629645925290856\n",
      "train loss:0.016761812595232316\n",
      "train loss:0.0125413433977595\n",
      "train loss:0.035076490091880075\n",
      "train loss:0.05009152412848903\n",
      "train loss:0.015632529326579724\n",
      "train loss:0.022607069402962907\n",
      "train loss:0.03194353932443656\n",
      "train loss:0.017556676406824633\n",
      "train loss:0.02264938104983108\n",
      "train loss:0.010895133376456154\n",
      "train loss:0.017209079984315513\n",
      "train loss:0.009233733550872434\n",
      "train loss:0.010148365699253535\n",
      "train loss:0.021961617487198097\n",
      "train loss:0.03346739547319056\n",
      "train loss:0.014905463000624262\n",
      "train loss:0.05565837015835966\n",
      "train loss:0.004261599593798796\n",
      "train loss:0.011252749041560966\n",
      "train loss:0.025949891183314623\n",
      "train loss:0.02576751824936978\n",
      "train loss:0.08932593207505082\n",
      "train loss:0.01748763139299374\n",
      "train loss:0.014438351796741031\n",
      "train loss:0.04234944794772121\n",
      "train loss:0.03867465133785167\n",
      "train loss:0.03463142933051255\n",
      "train loss:0.04723532794883855\n",
      "train loss:0.037001350233923216\n",
      "train loss:0.005939630583978858\n",
      "train loss:0.008468581037864588\n",
      "train loss:0.008220903038912203\n",
      "train loss:0.0457256130176006\n",
      "train loss:0.026576588245137648\n",
      "train loss:0.01159178196458556\n",
      "train loss:0.02350682778325061\n",
      "train loss:0.053485149475342685\n",
      "train loss:0.04993704378701627\n",
      "train loss:0.035357609629517735\n",
      "train loss:0.022751524353749417\n",
      "train loss:0.017048264392211722\n",
      "train loss:0.016718243546659576\n",
      "train loss:0.023423346732644984\n",
      "train loss:0.011562894034341709\n",
      "train loss:0.06420654083757946\n",
      "train loss:0.06424166799888327\n",
      "train loss:0.020717143926822515\n",
      "train loss:0.03537100308285539\n",
      "train loss:0.01427603092112801\n",
      "train loss:0.02954096009939338\n",
      "train loss:0.008919215846147972\n",
      "train loss:0.02521383837405749\n",
      "train loss:0.005037369738701713\n",
      "train loss:0.07495446305072304\n",
      "train loss:0.014092460117604406\n",
      "train loss:0.01233069499634655\n",
      "train loss:0.016468746709435073\n",
      "train loss:0.003943914182163088\n",
      "train loss:0.06194127420867874\n",
      "train loss:0.012824596093828496\n",
      "train loss:0.0927766219348008\n",
      "train loss:0.031053541948210323\n",
      "train loss:0.030317679236032617\n",
      "train loss:0.013313139460548186\n",
      "train loss:0.051828784367317304\n",
      "train loss:0.026108135032273935\n",
      "train loss:0.06513614999487885\n",
      "train loss:0.07926205504618374\n",
      "train loss:0.017199018749989522\n",
      "train loss:0.060988936906640506\n",
      "train loss:0.023865843888891916\n",
      "train loss:0.014898570771392112\n",
      "train loss:0.04830556746178463\n",
      "train loss:0.04717060891309693\n",
      "train loss:0.04287957855165643\n",
      "train loss:0.01077122025827679\n",
      "train loss:0.04540573249890325\n",
      "train loss:0.059662745038273915\n",
      "train loss:0.06721584794630207\n",
      "train loss:0.04415582494279976\n",
      "train loss:0.008054749337103234\n",
      "train loss:0.04454936216387306\n",
      "train loss:0.03227286008832141\n",
      "train loss:0.018760052833334824\n",
      "train loss:0.01260094383695446\n",
      "train loss:0.02965320333611301\n",
      "train loss:0.00847598548151907\n",
      "train loss:0.018476274656083428\n",
      "train loss:0.06569728720240751\n",
      "train loss:0.03649849553087344\n",
      "train loss:0.05677293044791165\n",
      "train loss:0.007087684600865304\n",
      "train loss:0.021900428903163655\n",
      "train loss:0.04237852648949199\n",
      "train loss:0.031792263401319694\n",
      "train loss:0.005480912723547643\n",
      "train loss:0.08904126931042004\n",
      "train loss:0.016631245099989648\n",
      "train loss:0.06471377470137607\n",
      "train loss:0.03977692896079495\n",
      "train loss:0.04531449818919552\n",
      "train loss:0.05645468664259909\n",
      "train loss:0.09593143711969114\n",
      "train loss:0.026582426814615475\n",
      "train loss:0.013199087183821028\n",
      "train loss:0.024994794502139994\n",
      "train loss:0.01907591399371298\n",
      "train loss:0.023441091231977032\n",
      "train loss:0.03545977898455673\n",
      "train loss:0.01917933453211178\n",
      "train loss:0.021848265376126764\n",
      "train loss:0.011649187911445256\n",
      "train loss:0.026463386241404322\n",
      "train loss:0.01097371103037179\n",
      "train loss:0.004988358171677569\n",
      "train loss:0.003146093586046197\n",
      "train loss:0.05085689836423736\n",
      "train loss:0.013686332490910669\n",
      "train loss:0.09951916320784145\n",
      "train loss:0.032835887824611686\n",
      "train loss:0.01637422617304394\n",
      "train loss:0.0034602586193274083\n",
      "train loss:0.01870584275004447\n",
      "train loss:0.011255881616437886\n",
      "train loss:0.023042394080483312\n",
      "train loss:0.0030120904397231874\n",
      "train loss:0.01854715004132887\n",
      "train loss:0.17101281387247955\n",
      "train loss:0.12311325984818909\n",
      "train loss:0.00836173649467351\n",
      "train loss:0.022111226693968443\n",
      "train loss:0.050669972725362965\n",
      "train loss:0.03265181654461696\n",
      "train loss:0.03684284056595138\n",
      "train loss:0.027490812981464142\n",
      "train loss:0.03993890707077807\n",
      "train loss:0.03479780831499697\n",
      "train loss:0.09638189855868534\n",
      "train loss:0.02699323777415212\n",
      "train loss:0.035549449888562096\n",
      "train loss:0.03335404902883672\n",
      "train loss:0.019387933449576702\n",
      "train loss:0.06441891295179557\n",
      "train loss:0.036823359747089335\n",
      "train loss:0.015210946049365221\n",
      "train loss:0.042541876326191705\n",
      "train loss:0.054544296726858246\n",
      "train loss:0.08855177810056945\n",
      "train loss:0.020443796604325173\n",
      "train loss:0.049456757910506965\n",
      "train loss:0.01065661399307199\n",
      "train loss:0.013974233506462277\n",
      "train loss:0.008933780569665858\n",
      "train loss:0.018756433783734667\n",
      "train loss:0.044155654573788485\n",
      "train loss:0.02305085737318918\n",
      "train loss:0.05929813686974054\n",
      "train loss:0.02233435594253153\n",
      "train loss:0.04177359152251408\n",
      "train loss:0.09042619354518756\n",
      "train loss:0.014975416638508026\n",
      "train loss:0.005189396013997821\n",
      "train loss:0.043197285958051265\n",
      "train loss:0.017119661426001593\n",
      "train loss:0.05738355843530262\n",
      "train loss:0.03818845665483452\n",
      "train loss:0.02953575344838078\n",
      "train loss:0.01681364053143289\n",
      "train loss:0.016760709084333733\n",
      "train loss:0.02977707958863529\n",
      "train loss:0.026070199656384956\n",
      "train loss:0.03527993963000909\n",
      "train loss:0.016914714004337927\n",
      "train loss:0.09853461750957812\n",
      "train loss:0.020251159202444607\n",
      "train loss:0.017203091687774726\n",
      "train loss:0.023075283546484814\n",
      "train loss:0.008274352611900305\n",
      "train loss:0.012364653217489498\n",
      "train loss:0.08193798940095925\n",
      "train loss:0.060897956710969384\n",
      "train loss:0.02694642430261106\n",
      "train loss:0.03972478396280636\n",
      "train loss:0.025056471374299578\n",
      "train loss:0.015944149597682426\n",
      "train loss:0.015685029815729598\n",
      "train loss:0.055378291858739874\n",
      "train loss:0.024532324124571465\n",
      "train loss:0.008316079192630516\n",
      "train loss:0.02590937633813141\n",
      "train loss:0.009098041010320877\n",
      "train loss:0.010616976251192824\n",
      "train loss:0.0126264929052103\n",
      "train loss:0.02480047404774494\n",
      "train loss:0.00717135794692621\n",
      "train loss:0.039935233945627785\n",
      "train loss:0.07082148525698048\n",
      "train loss:0.05696522278117324\n",
      "train loss:0.01407377866882562\n",
      "train loss:0.04926037703279202\n",
      "train loss:0.024762099403289793\n",
      "train loss:0.041083734267379865\n",
      "train loss:0.03180467178740684\n",
      "train loss:0.019064855771747612\n",
      "train loss:0.04624300067160182\n",
      "train loss:0.0308332384557334\n",
      "train loss:0.00981589146316293\n",
      "train loss:0.02115365675213503\n",
      "train loss:0.019397431273877\n",
      "train loss:0.026476238492328684\n",
      "train loss:0.01408306563400456\n",
      "train loss:0.01657282897514711\n",
      "train loss:0.06393326364712058\n",
      "train loss:0.0573306295186757\n",
      "train loss:0.011466242468234723\n",
      "train loss:0.01215480700001412\n",
      "train loss:0.055344872105342384\n",
      "train loss:0.041392736130095684\n",
      "train loss:0.027891128855822428\n",
      "train loss:0.04974357640091848\n",
      "train loss:0.0809963676616833\n",
      "train loss:0.07218823310381199\n",
      "train loss:0.030450715828439875\n",
      "train loss:0.045602649264476804\n",
      "train loss:0.055500658842289836\n",
      "train loss:0.022256385570944517\n",
      "train loss:0.017218155687468314\n",
      "train loss:0.05014580922490598\n",
      "train loss:0.06126697181302933\n",
      "train loss:0.0074492401459620135\n",
      "train loss:0.04778469169708651\n",
      "train loss:0.01315465648080224\n",
      "train loss:0.06583411057721374\n",
      "train loss:0.0218979710343677\n",
      "train loss:0.008223633625062178\n",
      "train loss:0.039397170080547245\n",
      "train loss:0.04044625838437568\n",
      "train loss:0.01706631736988423\n",
      "train loss:0.0819603116474039\n",
      "train loss:0.03403630562835267\n",
      "train loss:0.01764431709213696\n",
      "train loss:0.042395930045367056\n",
      "train loss:0.03134574374212884\n",
      "train loss:0.00916839362424556\n",
      "train loss:0.030018392301396895\n",
      "train loss:0.04432831510922786\n",
      "train loss:0.010065565169275432\n",
      "train loss:0.03237638478928626\n",
      "train loss:0.016584032731851425\n",
      "train loss:0.022872876131475747\n",
      "train loss:0.07649413525090824\n",
      "train loss:0.03388638646102979\n",
      "train loss:0.07124455626975648\n",
      "train loss:0.031954024632246524\n",
      "train loss:0.008712559168532481\n",
      "train loss:0.019417752396940657\n",
      "train loss:0.030868439405362186\n",
      "train loss:0.02357659713670118\n",
      "train loss:0.00991719643506471\n",
      "train loss:0.07866254878842419\n",
      "train loss:0.05518813494069011\n",
      "train loss:0.011343250900106008\n",
      "train loss:0.044652949563357074\n",
      "train loss:0.04541619343275864\n",
      "train loss:0.053778769628470634\n",
      "train loss:0.03315055317279575\n",
      "train loss:0.006138238464045484\n",
      "train loss:0.0241770608816827\n",
      "train loss:0.04415300789709947\n",
      "train loss:0.03344263365523315\n",
      "train loss:0.0169732557609143\n",
      "train loss:0.013537287233897865\n",
      "train loss:0.0153231879534109\n",
      "train loss:0.01093322625279175\n",
      "train loss:0.016245322280692066\n",
      "train loss:0.005883173709596357\n",
      "train loss:0.012903916001038643\n",
      "train loss:0.022204792139082618\n",
      "train loss:0.021891986776518116\n",
      "train loss:0.03544358951998695\n",
      "train loss:0.03171070790353683\n",
      "train loss:0.023470123431758628\n",
      "train loss:0.003977671619273189\n",
      "train loss:0.018611019987439633\n",
      "train loss:0.04482718435099385\n",
      "train loss:0.01949897765190342\n",
      "train loss:0.024478799400119725\n",
      "train loss:0.011084475793251508\n",
      "train loss:0.014894015707962512\n",
      "train loss:0.025932753443458245\n",
      "train loss:0.006423848765604617\n",
      "=== epoch:5, train acc:0.984, test acc:0.981 ===\n",
      "train loss:0.009765803294526837\n",
      "train loss:0.009730521894921535\n",
      "train loss:0.010441246759137393\n",
      "train loss:0.02367349777614115\n",
      "train loss:0.0096981186278856\n",
      "train loss:0.03299292471193092\n",
      "train loss:0.03976940180005505\n",
      "train loss:0.040855674268415305\n",
      "train loss:0.028947755150630125\n",
      "train loss:0.008701270531744985\n",
      "train loss:0.024097539572477934\n",
      "train loss:0.013639360068442057\n",
      "train loss:0.03144278377092444\n",
      "train loss:0.10500419100792337\n",
      "train loss:0.027045156238200568\n",
      "train loss:0.02047489135332058\n",
      "train loss:0.017070277431450426\n",
      "train loss:0.12576633746755608\n",
      "train loss:0.013436437449131297\n",
      "train loss:0.015541984312901984\n",
      "train loss:0.011323672422382615\n",
      "train loss:0.0036811393798932483\n",
      "train loss:0.016501913619664743\n",
      "train loss:0.03522298659043557\n",
      "train loss:0.013430613686518154\n",
      "train loss:0.10207655708918288\n",
      "train loss:0.038744891710002866\n",
      "train loss:0.025752869062976944\n",
      "train loss:0.021338761430292005\n",
      "train loss:0.04015615816180664\n",
      "train loss:0.008032174407372656\n",
      "train loss:0.007381057725658729\n",
      "train loss:0.01128620001744732\n",
      "train loss:0.005936885598912154\n",
      "train loss:0.021306999942599325\n",
      "train loss:0.07209893335539044\n",
      "train loss:0.0028473690071274538\n",
      "train loss:0.013922916919170391\n",
      "train loss:0.014339159969195098\n",
      "train loss:0.027769762362736018\n",
      "train loss:0.021366481612016264\n",
      "train loss:0.07574666350904655\n",
      "train loss:0.03722920648212583\n",
      "train loss:0.02243257732038378\n",
      "train loss:0.023767773045839373\n",
      "train loss:0.015366166043810922\n",
      "train loss:0.009399848977502913\n",
      "train loss:0.034502719599216164\n",
      "train loss:0.016103923954202033\n",
      "train loss:0.026572683738120786\n",
      "train loss:0.033527189118398755\n",
      "train loss:0.013728361190056064\n",
      "train loss:0.009291653283873373\n",
      "train loss:0.02882868566755119\n",
      "train loss:0.008693580697040675\n",
      "train loss:0.01083942561209941\n",
      "train loss:0.01499332692596618\n",
      "train loss:0.023581276725513037\n",
      "train loss:0.01904962683933101\n",
      "train loss:0.0036925905264078383\n",
      "train loss:0.03354336196201539\n",
      "train loss:0.009108123279243825\n",
      "train loss:0.0206834623603782\n",
      "train loss:0.012541625212870347\n",
      "train loss:0.007725448597559864\n",
      "train loss:0.009444943258112022\n",
      "train loss:0.010950831604234584\n",
      "train loss:0.02747240555033809\n",
      "train loss:0.007148486088260023\n",
      "train loss:0.009820936107954462\n",
      "train loss:0.07560663097516133\n",
      "train loss:0.007632156101441396\n",
      "train loss:0.04180614664124396\n",
      "train loss:0.011029856370653941\n",
      "train loss:0.008773876381156204\n",
      "train loss:0.06259277491442211\n",
      "train loss:0.01155301204712817\n",
      "train loss:0.004276886542357906\n",
      "train loss:0.07635657770471668\n",
      "train loss:0.01512192552981242\n",
      "train loss:0.010434964490170878\n",
      "train loss:0.010559211304551695\n",
      "train loss:0.006930209103995128\n",
      "train loss:0.009265587887687981\n",
      "train loss:0.013503742022254088\n",
      "train loss:0.007368919167863975\n",
      "train loss:0.030720943827859365\n",
      "train loss:0.03828050651577108\n",
      "train loss:0.0066452005730617695\n",
      "train loss:0.018282779027526185\n",
      "train loss:0.059066450078819985\n",
      "train loss:0.003605878173427417\n",
      "train loss:0.013733358100584013\n",
      "train loss:0.031106422852105374\n",
      "train loss:0.013646704234569415\n",
      "train loss:0.004565804851814841\n",
      "train loss:0.039384011017200266\n",
      "train loss:0.014557307085909934\n",
      "train loss:0.012671155043939201\n",
      "train loss:0.017751368187941343\n",
      "train loss:0.00939312925671561\n",
      "train loss:0.024303583724883462\n",
      "train loss:0.10542790935899568\n",
      "train loss:0.009571136748147873\n",
      "train loss:0.03878486545902365\n",
      "train loss:0.01103328174422004\n",
      "train loss:0.016012639096221026\n",
      "train loss:0.006845679155128492\n",
      "train loss:0.018575724312111498\n",
      "train loss:0.01457245697378748\n",
      "train loss:0.016190099418873248\n",
      "train loss:0.020827051618139743\n",
      "train loss:0.011579715824020705\n",
      "train loss:0.011030675071909319\n",
      "train loss:0.027982535414232807\n",
      "train loss:0.006282896894796137\n",
      "train loss:0.020997887360372766\n",
      "train loss:0.06110562657172418\n",
      "train loss:0.03668759104245641\n",
      "train loss:0.005609494866922217\n",
      "train loss:0.07474115755014778\n",
      "train loss:0.035863763069554994\n",
      "train loss:0.0740536317828222\n",
      "train loss:0.06741148165051752\n",
      "train loss:0.02330478645573587\n",
      "train loss:0.011971011479801135\n",
      "train loss:0.030126733572725786\n",
      "train loss:0.005399500406518454\n",
      "train loss:0.01796534458153031\n",
      "train loss:0.009323185510762388\n",
      "train loss:0.027341245577171526\n",
      "train loss:0.02381756329038727\n",
      "train loss:0.005683623406691049\n",
      "train loss:0.08391904489746596\n",
      "train loss:0.05527559712052969\n",
      "train loss:0.007681189089599474\n",
      "train loss:0.007601653695672327\n",
      "train loss:0.013590641373998784\n",
      "train loss:0.06717614470117644\n",
      "train loss:0.018447466174759588\n",
      "train loss:0.03762313200789034\n",
      "train loss:0.021678840299689663\n",
      "train loss:0.049853162396648\n",
      "train loss:0.026546948830617735\n",
      "train loss:0.02069189463363374\n",
      "train loss:0.019868538411081188\n",
      "train loss:0.024886087293107463\n",
      "train loss:0.03283959862013696\n",
      "train loss:0.009863822545698352\n",
      "train loss:0.05071647748651168\n",
      "train loss:0.04633413110178784\n",
      "train loss:0.016879934203386186\n",
      "train loss:0.010523286242551786\n",
      "train loss:0.10554474526673516\n",
      "train loss:0.04735667124832974\n",
      "train loss:0.017900210836898724\n",
      "train loss:0.05262966104473655\n",
      "train loss:0.03506647991350475\n",
      "train loss:0.016225529114250778\n",
      "train loss:0.017531946864661144\n",
      "train loss:0.011409212511924536\n",
      "train loss:0.012575179741264882\n",
      "train loss:0.029337914221140918\n",
      "train loss:0.10078839787923927\n",
      "train loss:0.003385820738484356\n",
      "train loss:0.02252131030986329\n",
      "train loss:0.06220378042651557\n",
      "train loss:0.03280082023068\n",
      "train loss:0.03338350399322747\n",
      "train loss:0.01865341760141215\n",
      "train loss:0.011401371224873755\n",
      "train loss:0.009316405529751094\n",
      "train loss:0.00832098266067781\n",
      "train loss:0.017481353582614278\n",
      "train loss:0.06441572940836957\n",
      "train loss:0.027465990479008155\n",
      "train loss:0.07067087343570569\n",
      "train loss:0.031691966535150246\n",
      "train loss:0.006421635037478653\n",
      "train loss:0.017902305768837615\n",
      "train loss:0.0319993480427702\n",
      "train loss:0.04424723696684715\n",
      "train loss:0.009963869854552667\n",
      "train loss:0.006285095672533671\n",
      "train loss:0.009012544324254248\n",
      "train loss:0.047608812461806975\n",
      "train loss:0.018822318189160324\n",
      "train loss:0.06806817714309445\n",
      "train loss:0.025330392648259835\n",
      "train loss:0.011245092676318832\n",
      "train loss:0.015392669611675885\n",
      "train loss:0.014500905906246133\n",
      "train loss:0.002616719017087146\n",
      "train loss:0.038206586125787236\n",
      "train loss:0.005950020222940717\n",
      "train loss:0.04157531138711863\n",
      "train loss:0.0800702146045338\n",
      "train loss:0.0216780210291113\n",
      "train loss:0.07114543858512287\n",
      "train loss:0.02134219152022252\n",
      "train loss:0.0102842579959995\n",
      "train loss:0.028879444529093676\n",
      "train loss:0.011572044781080048\n",
      "train loss:0.012876660483962611\n",
      "train loss:0.09963632308824837\n",
      "train loss:0.022905755810884398\n",
      "train loss:0.006582561481355376\n",
      "train loss:0.005478235510852243\n",
      "train loss:0.022843068408498653\n",
      "train loss:0.0063725161918787385\n",
      "train loss:0.01298265922266923\n",
      "train loss:0.0492634598195058\n",
      "train loss:0.005200843916811543\n",
      "train loss:0.05857365194982847\n",
      "train loss:0.051054206566466614\n",
      "train loss:0.018836873283687737\n",
      "train loss:0.04860516554129541\n",
      "train loss:0.033661395933658536\n",
      "train loss:0.031075151097296975\n",
      "train loss:0.008342142886260263\n",
      "train loss:0.01538328465705459\n",
      "train loss:0.02381441926115821\n",
      "train loss:0.01278779640979674\n",
      "train loss:0.03183400405028793\n",
      "train loss:0.05889475089746636\n",
      "train loss:0.10664176360830105\n",
      "train loss:0.036638505772028686\n",
      "train loss:0.07578748494401412\n",
      "train loss:0.02949758716498301\n",
      "train loss:0.020331238019167478\n",
      "train loss:0.08327904401921984\n",
      "train loss:0.06348890798300491\n",
      "train loss:0.016920509625859878\n",
      "train loss:0.010933476124030667\n",
      "train loss:0.13773522856233522\n",
      "train loss:0.015130872561033949\n",
      "train loss:0.02123241479313939\n",
      "train loss:0.006094907871028117\n",
      "train loss:0.01560173155826578\n",
      "train loss:0.01158276969292259\n",
      "train loss:0.016861297295327288\n",
      "train loss:0.038462208593122674\n",
      "train loss:0.02370153720728339\n",
      "train loss:0.016976214373379844\n",
      "train loss:0.004471501586767633\n",
      "train loss:0.0032771877090793274\n",
      "train loss:0.018215608475121596\n",
      "train loss:0.02659911561442125\n",
      "train loss:0.03787464759752292\n",
      "train loss:0.01744213522468046\n",
      "train loss:0.023780876940177963\n",
      "train loss:0.027478684316276772\n",
      "train loss:0.010933330614150282\n",
      "train loss:0.039310411158361785\n",
      "train loss:0.008793421035145584\n",
      "train loss:0.10731358640490686\n",
      "train loss:0.006124514984943371\n",
      "train loss:0.001971073083704194\n",
      "train loss:0.020504017188784366\n",
      "train loss:0.02595452912916616\n",
      "train loss:0.03064130052369501\n",
      "train loss:0.015304036904615119\n",
      "train loss:0.025932807965337878\n",
      "train loss:0.018687034657473248\n",
      "train loss:0.03632152141488191\n",
      "train loss:0.06940490662034368\n",
      "train loss:0.02051312210253625\n",
      "train loss:0.005854043211218773\n",
      "train loss:0.025990169993832617\n",
      "train loss:0.0067934611917915624\n",
      "train loss:0.022828946104362348\n",
      "train loss:0.01705130842884376\n",
      "train loss:0.02067209954232154\n",
      "train loss:0.06256252538215598\n",
      "train loss:0.01833518657930355\n",
      "train loss:0.035889515705532345\n",
      "train loss:0.016822921578133067\n",
      "train loss:0.009385489525777738\n",
      "train loss:0.0981213386855377\n",
      "train loss:0.019846099553586752\n",
      "train loss:0.017747098924267804\n",
      "train loss:0.018094603493403853\n",
      "train loss:0.029503120529409607\n",
      "train loss:0.01029396164157962\n",
      "train loss:0.008981037459593874\n",
      "train loss:0.023597145858321365\n",
      "train loss:0.011866576085774582\n",
      "train loss:0.01035057344390626\n",
      "train loss:0.016652231751996333\n",
      "train loss:0.02606280366025832\n",
      "train loss:0.16999939280775167\n",
      "train loss:0.0049725037147224345\n",
      "train loss:0.01645448766317971\n",
      "train loss:0.006376866033511766\n",
      "train loss:0.040384782359943826\n",
      "train loss:0.03360869978604684\n",
      "train loss:0.0024781010430093755\n",
      "train loss:0.019496254446349927\n",
      "train loss:0.071761172855095\n",
      "train loss:0.036354355319776176\n",
      "train loss:0.00441242046581482\n",
      "train loss:0.06614750863811344\n",
      "train loss:0.0058784538114810695\n",
      "train loss:0.04705087169738124\n",
      "train loss:0.022518477467335932\n",
      "train loss:0.006638385141320491\n",
      "train loss:0.03922238753997825\n",
      "train loss:0.02939352785982807\n",
      "train loss:0.010916526299015752\n",
      "train loss:0.015293243224547615\n",
      "train loss:0.0061530198480557845\n",
      "train loss:0.023937537908811778\n",
      "train loss:0.009726024926725817\n",
      "train loss:0.024752577861677155\n",
      "train loss:0.02958725118338791\n",
      "train loss:0.0799661800637235\n",
      "train loss:0.04875653744303175\n",
      "train loss:0.020508264771391907\n",
      "train loss:0.01337705372385647\n",
      "train loss:0.0023745786357151936\n",
      "train loss:0.015241731695963559\n",
      "train loss:0.041110764279774586\n",
      "train loss:0.013212590240646643\n",
      "train loss:0.05087347394417355\n",
      "train loss:0.019522850842352894\n",
      "train loss:0.03228361179916021\n",
      "train loss:0.03527112154743375\n",
      "train loss:0.021844635978704806\n",
      "train loss:0.046353930350120774\n",
      "train loss:0.07283940313600144\n",
      "train loss:0.0067080350780679985\n",
      "train loss:0.018727803762227817\n",
      "train loss:0.00951703956181595\n",
      "train loss:0.009304638497359734\n",
      "train loss:0.042449454775150934\n",
      "train loss:0.019468524989376516\n",
      "train loss:0.08809866176096326\n",
      "train loss:0.09148700597297457\n",
      "train loss:0.01402393768224865\n",
      "train loss:0.024816071689340368\n",
      "train loss:0.008657525034170596\n",
      "train loss:0.00727216376042655\n",
      "train loss:0.06976559545794742\n",
      "train loss:0.03457141516611941\n",
      "train loss:0.010802231300671235\n",
      "train loss:0.04650724591270368\n",
      "train loss:0.026397224707525254\n",
      "train loss:0.01072223249958438\n",
      "train loss:0.03220891631267408\n",
      "train loss:0.018044474522721357\n",
      "train loss:0.046789606549452536\n",
      "train loss:0.016388572848495885\n",
      "train loss:0.011763656553547391\n",
      "train loss:0.031003532623909334\n",
      "train loss:0.015272022537551555\n",
      "train loss:0.004758892897864696\n",
      "train loss:0.004547115394975537\n",
      "train loss:0.04315472530803877\n",
      "train loss:0.030468132987685845\n",
      "train loss:0.024314067144634167\n",
      "train loss:0.013201261153581912\n",
      "train loss:0.0729482787617584\n",
      "train loss:0.008070955980740811\n",
      "train loss:0.028980232307762435\n",
      "train loss:0.010558618009052773\n",
      "train loss:0.02802441424636525\n",
      "train loss:0.01521694625659982\n",
      "train loss:0.01689038890957341\n",
      "train loss:0.01490142002706891\n",
      "train loss:0.06275511769313376\n",
      "train loss:0.03630102908097624\n",
      "train loss:0.010074693683144016\n",
      "train loss:0.024556500905199743\n",
      "train loss:0.0036996356408694076\n",
      "train loss:0.022574886119431477\n",
      "train loss:0.023132003310479668\n",
      "train loss:0.0876955518554329\n",
      "train loss:0.0406159442184618\n",
      "train loss:0.0530096196125967\n",
      "train loss:0.008885721669180913\n",
      "train loss:0.028516670414451783\n",
      "train loss:0.008816308527747624\n",
      "train loss:0.009685209789507798\n",
      "train loss:0.07096928907932666\n",
      "train loss:0.0035998584214136983\n",
      "train loss:0.015859752281373037\n",
      "train loss:0.006043950921263284\n",
      "train loss:0.12416809989028907\n",
      "train loss:0.05093745936813979\n",
      "train loss:0.05476977361892391\n",
      "train loss:0.009205032480721192\n",
      "train loss:0.047459215718761154\n",
      "train loss:0.014770642200561348\n",
      "train loss:0.009701853626193807\n",
      "train loss:0.012385233494607803\n",
      "train loss:0.02171002914754795\n",
      "train loss:0.036984807762869824\n",
      "train loss:0.01774383909623294\n",
      "train loss:0.022156073814962523\n",
      "train loss:0.005410196864112916\n",
      "train loss:0.026236174053832287\n",
      "train loss:0.006848301011369284\n",
      "train loss:0.04867431233177304\n",
      "train loss:0.04948535817859498\n",
      "train loss:0.006498898836473945\n",
      "train loss:0.006807124629488702\n",
      "train loss:0.01929948876301661\n",
      "train loss:0.012462225020611345\n",
      "train loss:0.011228873961618518\n",
      "train loss:0.008618513456849773\n",
      "train loss:0.006964298529989138\n",
      "train loss:0.009299883029853916\n",
      "train loss:0.04240653622187739\n",
      "train loss:0.04072513968430646\n",
      "train loss:0.007429676604067499\n",
      "train loss:0.029392413859206264\n",
      "train loss:0.005654598827979735\n",
      "train loss:0.003395755793095856\n",
      "train loss:0.03781824933675945\n",
      "train loss:0.029437760971649865\n",
      "train loss:0.03056825161589218\n",
      "train loss:0.026245470404654067\n",
      "train loss:0.004810858817396606\n",
      "train loss:0.00892206179797544\n",
      "train loss:0.009097903460170715\n",
      "train loss:0.006271548293261406\n",
      "train loss:0.03491900919057833\n",
      "train loss:0.010298393529962382\n",
      "train loss:0.004272320471970989\n",
      "train loss:0.016005016608254385\n",
      "train loss:0.0035631837840904685\n",
      "train loss:0.014517261463812475\n",
      "train loss:0.04216948323538903\n",
      "train loss:0.006780413291050087\n",
      "train loss:0.007036270605502243\n",
      "train loss:0.0726315252767454\n",
      "train loss:0.008024909149891669\n",
      "train loss:0.05920973023325851\n",
      "train loss:0.0543614782284886\n",
      "train loss:0.011108350622213525\n",
      "train loss:0.020704458846822607\n",
      "train loss:0.03416357190156297\n",
      "train loss:0.012605926686792468\n",
      "train loss:0.021016664168268303\n",
      "train loss:0.0742157296849481\n",
      "train loss:0.009354360415885521\n",
      "train loss:0.018767714495870072\n",
      "train loss:0.03430750997407499\n",
      "train loss:0.040369369483609543\n",
      "train loss:0.045025346824473775\n",
      "train loss:0.04146567809187422\n",
      "train loss:0.04822978063133952\n",
      "train loss:0.002877560497341422\n",
      "train loss:0.03590859739142765\n",
      "train loss:0.024645117072354714\n",
      "train loss:0.0037107345981033106\n",
      "train loss:0.0340155921957994\n",
      "train loss:0.012902515361004653\n",
      "train loss:0.007770836936999958\n",
      "train loss:0.023173683550716292\n",
      "train loss:0.012451072009601409\n",
      "train loss:0.02278649099519256\n",
      "train loss:0.012142189252772058\n",
      "train loss:0.07296906409564481\n",
      "train loss:0.03366434566577623\n",
      "train loss:0.01786588221195636\n",
      "train loss:0.010040197773447725\n",
      "train loss:0.03850326964088412\n",
      "train loss:0.032051042395278534\n",
      "train loss:0.008346466727679752\n",
      "train loss:0.09799128923870386\n",
      "train loss:0.040038774571981815\n",
      "train loss:0.026417870192346603\n",
      "train loss:0.06365907983657788\n",
      "train loss:0.02982374243479259\n",
      "train loss:0.008021669871603476\n",
      "train loss:0.01679339505831304\n",
      "train loss:0.013857345207654964\n",
      "train loss:0.031174352061523036\n",
      "train loss:0.02357341733153652\n",
      "train loss:0.05254221082106633\n",
      "train loss:0.015320130327588395\n",
      "train loss:0.01486335279646182\n",
      "train loss:0.010181769722927472\n",
      "train loss:0.04304819585196842\n",
      "train loss:0.0366609649446338\n",
      "train loss:0.00764642518729371\n",
      "train loss:0.010607480153252807\n",
      "train loss:0.010612934575797152\n",
      "train loss:0.028356471327268012\n",
      "train loss:0.03251561595543877\n",
      "train loss:0.0036164599132764317\n",
      "train loss:0.030959708673055197\n",
      "train loss:0.024799573748722867\n",
      "train loss:0.022592260472976924\n",
      "train loss:0.02893192600926613\n",
      "train loss:0.01027933075628048\n",
      "train loss:0.12639034335235905\n",
      "train loss:0.027638671403625033\n",
      "train loss:0.008539219661790788\n",
      "train loss:0.011905664131710821\n",
      "train loss:0.09133693749533733\n",
      "train loss:0.075903748311952\n",
      "train loss:0.01237195013061556\n",
      "train loss:0.048713371760893735\n",
      "train loss:0.010871252117766607\n",
      "train loss:0.05761653676878842\n",
      "train loss:0.011675573146308928\n",
      "train loss:0.022951159499384297\n",
      "train loss:0.012747218194324235\n",
      "train loss:0.004641987399929003\n",
      "train loss:0.02278953594429585\n",
      "train loss:0.02074632515004228\n",
      "train loss:0.016392602042355164\n",
      "train loss:0.011822425281022383\n",
      "train loss:0.017319203901920453\n",
      "train loss:0.05989258217045936\n",
      "train loss:0.0076180500230259626\n",
      "train loss:0.01651410958515853\n",
      "train loss:0.06948805944928428\n",
      "train loss:0.009688539846460991\n",
      "train loss:0.006978453737871116\n",
      "train loss:0.04161977308015777\n",
      "train loss:0.0253333100309227\n",
      "train loss:0.08160051065693631\n",
      "train loss:0.017403970849965134\n",
      "train loss:0.00883421278472489\n",
      "train loss:0.006899561168241321\n",
      "train loss:0.030835414296854245\n",
      "train loss:0.02073308222843919\n",
      "train loss:0.008473700746952206\n",
      "train loss:0.0372816715453287\n",
      "train loss:0.006707442005804776\n",
      "train loss:0.014627509561158193\n",
      "train loss:0.007063750025622844\n",
      "train loss:0.0054235657946171715\n",
      "train loss:0.029102058858737827\n",
      "train loss:0.045690866912114804\n",
      "train loss:0.021126767935319174\n",
      "train loss:0.03561877528921817\n",
      "train loss:0.057791400842242595\n",
      "train loss:0.030404539221189658\n",
      "train loss:0.013751290407825358\n",
      "train loss:0.02168932969943556\n",
      "train loss:0.018639999010550704\n",
      "train loss:0.03878639713012644\n",
      "train loss:0.026432531697518438\n",
      "train loss:0.009455368308631706\n",
      "train loss:0.059269638421576704\n",
      "train loss:0.03512113569614874\n",
      "train loss:0.032803638844104366\n",
      "train loss:0.01919374936259413\n",
      "train loss:0.018650535373788434\n",
      "train loss:0.008682763905480295\n",
      "train loss:0.03329273563924015\n",
      "train loss:0.014365887607932842\n",
      "train loss:0.01473025375753142\n",
      "train loss:0.0032813980780151005\n",
      "train loss:0.01206777509991181\n",
      "train loss:0.03635676579032782\n",
      "train loss:0.016550309944129836\n",
      "train loss:0.06112257361016224\n",
      "train loss:0.04080752886743052\n",
      "train loss:0.004987093127420748\n",
      "train loss:0.021268772608657865\n",
      "train loss:0.0037261926998824356\n",
      "train loss:0.011678477817786859\n",
      "train loss:0.026486728656133388\n",
      "train loss:0.01218015686339503\n",
      "train loss:0.00816511089732709\n",
      "train loss:0.049263019825813714\n",
      "train loss:0.014521219606086084\n",
      "train loss:0.06802301463483244\n",
      "train loss:0.014952798257281893\n",
      "train loss:0.00861620682126648\n",
      "train loss:0.05315017443341861\n",
      "train loss:0.02182860279283373\n",
      "train loss:0.020063982290743524\n",
      "train loss:0.019809310608889793\n",
      "train loss:0.051478209696240194\n",
      "train loss:0.010525938760180566\n",
      "train loss:0.03751248015717759\n",
      "train loss:0.03080423416592883\n",
      "train loss:0.060022437174500454\n",
      "train loss:0.023819536858336657\n",
      "train loss:0.015228679850623268\n",
      "train loss:0.015628919873442827\n",
      "train loss:0.01916747563922251\n",
      "train loss:0.014773348438981615\n",
      "train loss:0.02346705886515983\n",
      "train loss:0.027036367352506887\n",
      "train loss:0.009705238243073422\n",
      "train loss:0.040018893449176994\n",
      "train loss:0.05714442233197053\n",
      "train loss:0.015568303782339072\n",
      "train loss:0.02748274129576425\n",
      "train loss:0.010566115808512829\n",
      "train loss:0.060740070598828994\n",
      "train loss:0.016060926128628892\n",
      "train loss:0.031171328707240126\n",
      "=== epoch:6, train acc:0.988, test acc:0.988 ===\n",
      "train loss:0.02177756057007301\n",
      "train loss:0.005209229098487414\n",
      "train loss:0.005267138184900555\n",
      "train loss:0.008037558607709648\n",
      "train loss:0.013206830268661181\n",
      "train loss:0.00497867914680973\n",
      "train loss:0.04260972927319409\n",
      "train loss:0.008599726068858893\n",
      "train loss:0.053513212570813866\n",
      "train loss:0.028581936328512136\n",
      "train loss:0.011929564928553666\n",
      "train loss:0.008942037845724749\n",
      "train loss:0.017144338640079016\n",
      "train loss:0.005655459956457773\n",
      "train loss:0.029983447232830383\n",
      "train loss:0.0188530295241955\n",
      "train loss:0.027656927498888914\n",
      "train loss:0.019376869367104116\n",
      "train loss:0.019435448139560232\n",
      "train loss:0.029649484644414015\n",
      "train loss:0.020722002235921556\n",
      "train loss:0.034068250002041396\n",
      "train loss:0.009319715127840203\n",
      "train loss:0.08255194348981128\n",
      "train loss:0.05162546003978101\n",
      "train loss:0.003032288072645019\n",
      "train loss:0.014044158917371638\n",
      "train loss:0.002827873182768254\n",
      "train loss:0.0026959525116850304\n",
      "train loss:0.014080222799773993\n",
      "train loss:0.028616353574490327\n",
      "train loss:0.011410529045423145\n",
      "train loss:0.008283994967304384\n",
      "train loss:0.017573372625714158\n",
      "train loss:0.012308097509122151\n",
      "train loss:0.005755794922207586\n",
      "train loss:0.043975887293012994\n",
      "train loss:0.012128393343479848\n",
      "train loss:0.014654780384353536\n",
      "train loss:0.01777020588721924\n",
      "train loss:0.008317777261032448\n",
      "train loss:0.00901171727174588\n",
      "train loss:0.01135618182191545\n",
      "train loss:0.018648388996199392\n",
      "train loss:0.03216370727610799\n",
      "train loss:0.043101594637223434\n",
      "train loss:0.004479216031332049\n",
      "train loss:0.007753531465098218\n",
      "train loss:0.010024178160192736\n",
      "train loss:0.029403848940270465\n",
      "train loss:0.0025639774929501085\n",
      "train loss:0.01421362792935405\n",
      "train loss:0.04854025616574586\n",
      "train loss:0.006515831784048831\n",
      "train loss:0.0040364270232363915\n",
      "train loss:0.052664027169630284\n",
      "train loss:0.01115687290039229\n",
      "train loss:0.007665547532094035\n",
      "train loss:0.0046695324935894355\n",
      "train loss:0.013548740450814887\n",
      "train loss:0.01813717531112585\n",
      "train loss:0.0351739670086158\n",
      "train loss:0.005513369969395269\n",
      "train loss:0.008823079881231788\n",
      "train loss:0.00874314252435642\n",
      "train loss:0.012367897639445423\n",
      "train loss:0.011577874409505907\n",
      "train loss:0.006364272121797331\n",
      "train loss:0.06359580266349385\n",
      "train loss:0.015267598434777705\n",
      "train loss:0.00904450201817093\n",
      "train loss:0.01925303751080321\n",
      "train loss:0.019016771717878057\n",
      "train loss:0.011092047728539755\n",
      "train loss:0.014807419920030054\n",
      "train loss:0.006740079710589359\n",
      "train loss:0.014213867735037555\n",
      "train loss:0.00167226165169164\n",
      "train loss:0.01830152957520211\n",
      "train loss:0.0222128647209126\n",
      "train loss:0.02714237330216768\n",
      "train loss:0.09838064947871857\n",
      "train loss:0.012167638072902314\n",
      "train loss:0.015183020930700793\n",
      "train loss:0.003205402448420936\n",
      "train loss:0.07183143188979507\n",
      "train loss:0.023281471081218676\n",
      "train loss:0.011096520460313342\n",
      "train loss:0.017822655222163194\n",
      "train loss:0.03749603108160751\n",
      "train loss:0.00998373361926679\n",
      "train loss:0.05009720782450887\n",
      "train loss:0.029663014740208778\n",
      "train loss:0.01659172273317775\n",
      "train loss:0.01437203942486007\n",
      "train loss:0.006203138966505223\n",
      "train loss:0.062311191204166914\n",
      "train loss:0.025544016064112142\n",
      "train loss:0.01239985168017346\n",
      "train loss:0.013305236941547838\n",
      "train loss:0.006599036890310602\n",
      "train loss:0.02337032959356182\n",
      "train loss:0.015591854856524893\n",
      "train loss:0.00857079714184203\n",
      "train loss:0.019609508043675707\n",
      "train loss:0.021199429809314073\n",
      "train loss:0.010632970073950754\n",
      "train loss:0.010570773147805237\n",
      "train loss:0.02776058853753558\n",
      "train loss:0.0033829433530998877\n",
      "train loss:0.005894108337677004\n",
      "train loss:0.027898974879466788\n",
      "train loss:0.004944771303602238\n",
      "train loss:0.022446614040484446\n",
      "train loss:0.013331643076150692\n",
      "train loss:0.06794422983075368\n",
      "train loss:0.022327901517227754\n",
      "train loss:0.022870218530091982\n",
      "train loss:0.13336328929560087\n",
      "train loss:0.025738188503119805\n",
      "train loss:0.007376780362681782\n",
      "train loss:0.004435197670274707\n",
      "train loss:0.015720149539852145\n",
      "train loss:0.013586741347878219\n",
      "train loss:0.011303288708178363\n",
      "train loss:0.021154743850073807\n",
      "train loss:0.014252755741109797\n",
      "train loss:0.023162617902280615\n",
      "train loss:0.053723612908291224\n",
      "train loss:0.003830645981126149\n",
      "train loss:0.007182634956332633\n",
      "train loss:0.01911067050225033\n",
      "train loss:0.02863908020386453\n",
      "train loss:0.011965684781936166\n",
      "train loss:0.010359532376566323\n",
      "train loss:0.018067975775488618\n",
      "train loss:0.010993239518642547\n",
      "train loss:0.026947109326486123\n",
      "train loss:0.03979075885535324\n",
      "train loss:0.019649182735502136\n",
      "train loss:0.011233534191128778\n",
      "train loss:0.016364477272110992\n",
      "train loss:0.023152167390998218\n",
      "train loss:0.01529438171821322\n",
      "train loss:0.00614047995392539\n",
      "train loss:0.010839592427277549\n",
      "train loss:0.019214423342201584\n",
      "train loss:0.023097845719468806\n",
      "train loss:0.006268710392322226\n",
      "train loss:0.010991303943517394\n",
      "train loss:0.01942396899542451\n",
      "train loss:0.009192266281075535\n",
      "train loss:0.008801812261246347\n",
      "train loss:0.027873300898211165\n",
      "train loss:0.015543275957768485\n",
      "train loss:0.012818366084155344\n",
      "train loss:0.0026256269932756777\n",
      "train loss:0.03780785183467533\n",
      "train loss:0.014838636811384046\n",
      "train loss:0.021057949576675034\n",
      "train loss:0.029135524388183735\n",
      "train loss:0.009370839471886702\n",
      "train loss:0.006704102463229266\n",
      "train loss:0.0416009229521924\n",
      "train loss:0.05891394815423605\n",
      "train loss:0.007900586495556227\n",
      "train loss:0.017154937609653385\n",
      "train loss:0.012564928698461082\n",
      "train loss:0.007489020344087782\n",
      "train loss:0.00978163635508917\n",
      "train loss:0.09742192218204897\n",
      "train loss:0.010701337111332474\n",
      "train loss:0.046719652772055\n",
      "train loss:0.026887090784825624\n",
      "train loss:0.007368935215025425\n",
      "train loss:0.045260048945981624\n",
      "train loss:0.16296384936385797\n",
      "train loss:0.0068826160019443885\n",
      "train loss:0.017125225093577633\n",
      "train loss:0.0203447099236215\n",
      "train loss:0.01120834379916486\n",
      "train loss:0.0273962661003236\n",
      "train loss:0.016326802636831058\n",
      "train loss:0.0033232114110098277\n",
      "train loss:0.028339574671312068\n",
      "train loss:0.012629471111298656\n",
      "train loss:0.008905191635914394\n",
      "train loss:0.036268756692796236\n",
      "train loss:0.01904217797645985\n",
      "train loss:0.005470805920120024\n",
      "train loss:0.031334234805121326\n",
      "train loss:0.02036051924416893\n",
      "train loss:0.016425609449888214\n",
      "train loss:0.003452408774483334\n",
      "train loss:0.005104717377554323\n",
      "train loss:0.006215676623886727\n",
      "train loss:0.008223794020060328\n",
      "train loss:0.014788085196863572\n",
      "train loss:0.01811932879068908\n",
      "train loss:0.0142692673592829\n",
      "train loss:0.016484872928078657\n",
      "train loss:0.0154169924828894\n",
      "train loss:0.034690736249528085\n",
      "train loss:0.003501751959811183\n",
      "train loss:0.022877166339371643\n",
      "train loss:0.010823613408506207\n",
      "train loss:0.017875019012249412\n",
      "train loss:0.01125123790569525\n",
      "train loss:0.021436977792576268\n",
      "train loss:0.025445028274079177\n",
      "train loss:0.005881588106580408\n",
      "train loss:0.006734694351749176\n",
      "train loss:0.01677924009210972\n",
      "train loss:0.010654364085778587\n",
      "train loss:0.020491302279792577\n",
      "train loss:0.0221218628413201\n",
      "train loss:0.0032403425737890647\n",
      "train loss:0.09845863471725176\n",
      "train loss:0.01218978564505971\n",
      "train loss:0.014122099665895727\n",
      "train loss:0.02439830058953627\n",
      "train loss:0.008347495573692559\n",
      "train loss:0.00973863516440138\n",
      "train loss:0.009483097693636948\n",
      "train loss:0.00914605691087493\n",
      "train loss:0.021406076746961156\n",
      "train loss:0.02853679013247739\n",
      "train loss:0.0028602491390574613\n",
      "train loss:0.03246985958861828\n",
      "train loss:0.017344935958689474\n",
      "train loss:0.008680857328735456\n",
      "train loss:0.0062872995556080115\n",
      "train loss:0.013161962930368774\n",
      "train loss:0.044198378665931404\n",
      "train loss:0.008001702448298785\n",
      "train loss:0.009626371900866858\n",
      "train loss:0.04228689788708612\n",
      "train loss:0.03032867642979209\n",
      "train loss:0.06177025014819465\n",
      "train loss:0.016607299217281494\n",
      "train loss:0.005975667144512974\n",
      "train loss:0.005418207078374946\n",
      "train loss:0.002155857433895165\n",
      "train loss:0.026372352710485453\n",
      "train loss:0.028353201267113572\n",
      "train loss:0.01764040077732796\n",
      "train loss:0.002991769464550274\n",
      "train loss:0.012599978239656952\n",
      "train loss:0.011568177451615569\n",
      "train loss:0.011414777904382499\n",
      "train loss:0.009282914890734\n",
      "train loss:0.022722338354499452\n",
      "train loss:0.01509172616939156\n",
      "train loss:0.03015526095347668\n",
      "train loss:0.0351955050765316\n",
      "train loss:0.02959095146920017\n",
      "train loss:0.01953898455078901\n",
      "train loss:0.0023958222835738403\n",
      "train loss:0.0067419083286267955\n",
      "train loss:0.026213635629979755\n",
      "train loss:0.009102736127389146\n",
      "train loss:0.024604434517278798\n",
      "train loss:0.009358441407304331\n",
      "train loss:0.02276534950639546\n",
      "train loss:0.004410855536127921\n",
      "train loss:0.0044856006783482545\n",
      "train loss:0.018605074589908562\n",
      "train loss:0.02007261770736159\n",
      "train loss:0.013040148972707244\n",
      "train loss:0.021935585469421568\n",
      "train loss:0.019678840555296485\n",
      "train loss:0.003947319304944838\n",
      "train loss:0.014912983683790022\n",
      "train loss:0.017951198119254493\n",
      "train loss:0.049244032729675265\n",
      "train loss:0.020199520871590562\n",
      "train loss:0.009766413841350446\n",
      "train loss:0.003499724021327978\n",
      "train loss:0.004036932012305576\n",
      "train loss:0.05381344980487898\n",
      "train loss:0.021688024808434427\n",
      "train loss:0.007945724122487785\n",
      "train loss:0.004073273116910562\n",
      "train loss:0.021228256523795137\n",
      "train loss:0.03418796384629616\n",
      "train loss:0.01568993480919171\n",
      "train loss:0.003581613858617133\n",
      "train loss:0.007435460353622356\n",
      "train loss:0.025172767883191182\n",
      "train loss:0.009333153747520265\n",
      "train loss:0.018157303764030006\n",
      "train loss:0.014758169947285094\n",
      "train loss:0.002231703665344098\n",
      "train loss:0.007890721129069293\n",
      "train loss:0.01760419222910388\n",
      "train loss:0.005641353504707723\n",
      "train loss:0.019230005283400246\n",
      "train loss:0.03557772703912292\n",
      "train loss:0.0057776993453266335\n",
      "train loss:0.00934654009210701\n",
      "train loss:0.08146440708073871\n",
      "train loss:0.005821597810414556\n",
      "train loss:0.018171901599346514\n",
      "train loss:0.014735683416599848\n",
      "train loss:0.017837815813255182\n",
      "train loss:0.01142276415540482\n",
      "train loss:0.013300003314439628\n",
      "train loss:0.04147495543282878\n",
      "train loss:0.030710410171974713\n",
      "train loss:0.011139679366279916\n",
      "train loss:0.0259781317638086\n",
      "train loss:0.005119704003283616\n",
      "train loss:0.11335736635738095\n",
      "train loss:0.015719625866184132\n",
      "train loss:0.021645904116548462\n",
      "train loss:0.010822578935608023\n",
      "train loss:0.023810129925622463\n",
      "train loss:0.005633287502271941\n",
      "train loss:0.16119069134843006\n",
      "train loss:0.004512096350469302\n",
      "train loss:0.0049152489042640825\n",
      "train loss:0.09290397144803704\n",
      "train loss:0.02405146068989418\n",
      "train loss:0.0013044707863848109\n",
      "train loss:0.04139119650362522\n",
      "train loss:0.006742905889705433\n",
      "train loss:0.015060280013795356\n",
      "train loss:0.011482479177451705\n",
      "train loss:0.006842935086619116\n",
      "train loss:0.01704351991482851\n",
      "train loss:0.0065947271120737816\n",
      "train loss:0.0036831597292520386\n",
      "train loss:0.00338325677296309\n",
      "train loss:0.013537721991479386\n",
      "train loss:0.005481145182602018\n",
      "train loss:0.019552373172908567\n",
      "train loss:0.01941299441445782\n",
      "train loss:0.0029262076131472835\n",
      "train loss:0.022297619402306325\n",
      "train loss:0.01912278807659073\n",
      "train loss:0.02179333135703386\n",
      "train loss:0.027270671596398354\n",
      "train loss:0.00789597825619673\n",
      "train loss:0.0032104280279645512\n",
      "train loss:0.006055470364682683\n",
      "train loss:0.022620302322011784\n",
      "train loss:0.009042831094821643\n",
      "train loss:0.011525400995613212\n",
      "train loss:0.03591106328435925\n",
      "train loss:0.004322053040876599\n",
      "train loss:0.015397922862387859\n",
      "train loss:0.03886751337804883\n",
      "train loss:0.010787145107435954\n",
      "train loss:0.005599175116047903\n",
      "train loss:0.04301470011391768\n",
      "train loss:0.00670607197956665\n",
      "train loss:0.005028071371001907\n",
      "train loss:0.02997879266168705\n",
      "train loss:0.008399852387885421\n",
      "train loss:0.00464940594507879\n",
      "train loss:0.006664979818254195\n",
      "train loss:0.014336951391019497\n",
      "train loss:0.028223014469518894\n",
      "train loss:0.03370894835166359\n",
      "train loss:0.05627417230751458\n",
      "train loss:0.016979656843838075\n",
      "train loss:0.012587172693096697\n",
      "train loss:0.0035330517992923473\n",
      "train loss:0.006506092809289413\n",
      "train loss:0.015371611812891307\n",
      "train loss:0.005294271735315103\n",
      "train loss:0.012172631792799817\n",
      "train loss:0.016686512996003544\n",
      "train loss:0.033561359675053394\n",
      "train loss:0.03851604971781853\n",
      "train loss:0.04501243710130764\n",
      "train loss:0.009817954900890486\n",
      "train loss:0.013453646418434719\n",
      "train loss:0.029016098071321376\n",
      "train loss:0.005570834128316645\n",
      "train loss:0.009731978120110446\n",
      "train loss:0.025798091839126135\n",
      "train loss:0.02972754508262831\n",
      "train loss:0.0168938628775072\n",
      "train loss:0.019615702564070178\n",
      "train loss:0.008464383341913921\n",
      "train loss:0.005006500347417491\n",
      "train loss:0.016564574894753794\n",
      "train loss:0.007961861577250574\n",
      "train loss:0.009930486504920413\n",
      "train loss:0.0025022739121754282\n",
      "train loss:0.043306239097254916\n",
      "train loss:0.016089055073542132\n",
      "train loss:0.00590929655297529\n",
      "train loss:0.04393687703966702\n",
      "train loss:0.010362940986668692\n",
      "train loss:0.0020009177492673965\n",
      "train loss:0.020872326152051292\n",
      "train loss:0.02279969241573318\n",
      "train loss:0.012840194509430691\n",
      "train loss:0.007359628768075591\n",
      "train loss:0.009457454892419843\n",
      "train loss:0.0035404347656664862\n",
      "train loss:0.08102549631774923\n",
      "train loss:0.007351250203034074\n",
      "train loss:0.007480937550875561\n",
      "train loss:0.00912500883139096\n",
      "train loss:0.01960870242251151\n",
      "train loss:0.06817144458069949\n",
      "train loss:0.009674675146706549\n",
      "train loss:0.02318461997788213\n",
      "train loss:0.009432233510051685\n",
      "train loss:0.013927328946373569\n",
      "train loss:0.032113458413115595\n",
      "train loss:0.02747908223258736\n",
      "train loss:0.0017848298647908847\n",
      "train loss:0.03479044834423503\n",
      "train loss:0.007675240181179115\n",
      "train loss:0.0024632349987296293\n",
      "train loss:0.005774307841558598\n",
      "train loss:0.01028705181751149\n",
      "train loss:0.0060018331507493425\n",
      "train loss:0.0060543602930023584\n",
      "train loss:0.007446918267766912\n",
      "train loss:0.007931881386242423\n",
      "train loss:0.004547886872718498\n",
      "train loss:0.008240161760041522\n",
      "train loss:0.0060549907181986305\n",
      "train loss:0.022834129805098153\n",
      "train loss:0.007975569276978152\n",
      "train loss:0.004823982276925672\n",
      "train loss:0.018912030895000508\n",
      "train loss:0.009549742892021899\n",
      "train loss:0.0344949817970029\n",
      "train loss:0.04879178885993522\n",
      "train loss:0.009508680210604166\n",
      "train loss:0.013927238535215896\n",
      "train loss:0.00450162113992863\n",
      "train loss:0.03654575219703189\n",
      "train loss:0.007834635494878027\n",
      "train loss:0.012532394379097494\n",
      "train loss:0.008338114227239847\n",
      "train loss:0.0020491644219419996\n",
      "train loss:0.04865841536629697\n",
      "train loss:0.006042004413884675\n",
      "train loss:0.019328716373638248\n",
      "train loss:0.0041781092574490674\n",
      "train loss:0.005032158031004974\n",
      "train loss:0.003635251811978584\n",
      "train loss:0.020073450141029844\n",
      "train loss:0.009235536946592026\n",
      "train loss:0.022721449544225548\n",
      "train loss:0.017617148301249407\n",
      "train loss:0.07076278725512218\n",
      "train loss:0.011963300609558532\n",
      "train loss:0.008700069978301082\n",
      "train loss:0.007208080023918735\n",
      "train loss:0.05757774779537811\n",
      "train loss:0.04525674400379094\n",
      "train loss:0.008706122299943199\n",
      "train loss:0.004164946848701873\n",
      "train loss:0.016080227218798097\n",
      "train loss:0.04299056868401488\n",
      "train loss:0.04365168704099544\n",
      "train loss:0.004639923452963591\n",
      "train loss:0.08072356093916479\n",
      "train loss:0.003908677471908175\n",
      "train loss:0.01894787284033318\n",
      "train loss:0.023505044420036002\n",
      "train loss:0.005760836289397839\n",
      "train loss:0.00769712871505186\n",
      "train loss:0.007408909852964754\n",
      "train loss:0.01712219192734689\n",
      "train loss:0.013197540637705962\n",
      "train loss:0.05797039984151747\n",
      "train loss:0.005958323676000914\n",
      "train loss:0.024089019312029798\n",
      "train loss:0.057093186814826405\n",
      "train loss:0.01798970956415749\n",
      "train loss:0.00813752791656875\n",
      "train loss:0.019946192177320878\n",
      "train loss:0.005785128333875163\n",
      "train loss:0.011107298154818045\n",
      "train loss:0.015119035533295718\n",
      "train loss:0.014732319950410848\n",
      "train loss:0.08483390644649902\n",
      "train loss:0.0036811144407786957\n",
      "train loss:0.014456073348560526\n",
      "train loss:0.014965943773987654\n",
      "train loss:0.051513697103335164\n",
      "train loss:0.034683858169094604\n",
      "train loss:0.02955732040222818\n",
      "train loss:0.022575564065733043\n",
      "train loss:0.028855493759161955\n",
      "train loss:0.06651541437911324\n",
      "train loss:0.0220989594872309\n",
      "train loss:0.010900988529747212\n",
      "train loss:0.08213283052842274\n",
      "train loss:0.04426029321575586\n",
      "train loss:0.012573207440404532\n",
      "train loss:0.004415481089312246\n",
      "train loss:0.009603152758906344\n",
      "train loss:0.012160297569082308\n",
      "train loss:0.011579531337983253\n",
      "train loss:0.018949208006042415\n",
      "train loss:0.004050450817853446\n",
      "train loss:0.042864481113557895\n",
      "train loss:0.011077334619087185\n",
      "train loss:0.007062996520970092\n",
      "train loss:0.01730498506232137\n",
      "train loss:0.013875804958354493\n",
      "train loss:0.05085974207046872\n",
      "train loss:0.01061918529727569\n",
      "train loss:0.00118230204856301\n",
      "train loss:0.011371309870433782\n",
      "train loss:0.029596796097268757\n",
      "train loss:0.020418720443775143\n",
      "train loss:0.026344745775412216\n",
      "train loss:0.039401106625181544\n",
      "train loss:0.019252333882852468\n",
      "train loss:0.038183089537809425\n",
      "train loss:0.006549942870888556\n",
      "train loss:0.04607312758675294\n",
      "train loss:0.021661299820096503\n",
      "train loss:0.007636888082841502\n",
      "train loss:0.023115424280786775\n",
      "train loss:0.021951806836303153\n",
      "train loss:0.06314721745008284\n",
      "train loss:0.06324055239419804\n",
      "train loss:0.01580508713771234\n",
      "train loss:0.02476091914361471\n",
      "train loss:0.01503361494150668\n",
      "train loss:0.015178485608173222\n",
      "train loss:0.006392663177612942\n",
      "train loss:0.12189684225757266\n",
      "train loss:0.02589030785457623\n",
      "train loss:0.024196897909466872\n",
      "train loss:0.006741484036323595\n",
      "train loss:0.0066212240280256185\n",
      "train loss:0.019183088528269623\n",
      "train loss:0.017221168041184103\n",
      "train loss:0.014659886518935128\n",
      "train loss:0.020890699407084056\n",
      "train loss:0.0051476886153862915\n",
      "train loss:0.01505056528528121\n",
      "train loss:0.016623960406496042\n",
      "train loss:0.0032806471304660466\n",
      "train loss:0.02989662871565069\n",
      "train loss:0.016929793311793798\n",
      "train loss:0.02076126386173425\n",
      "train loss:0.018677897174424706\n",
      "train loss:0.018151381871465592\n",
      "train loss:0.03523572129435768\n",
      "train loss:0.0027017844728667163\n",
      "train loss:0.0020465774239461936\n",
      "train loss:0.03390709400600921\n",
      "train loss:0.009197228649918045\n",
      "train loss:0.015925684980614686\n",
      "train loss:0.008168760048262242\n",
      "train loss:0.059893488476314344\n",
      "train loss:0.009156251084997704\n",
      "train loss:0.011325061281241089\n",
      "train loss:0.0073421009969788665\n",
      "train loss:0.02123505913073622\n",
      "train loss:0.02071181813015305\n",
      "train loss:0.013612955752952951\n",
      "train loss:0.008601994230076532\n",
      "train loss:0.014908912296112386\n",
      "train loss:0.04292376652365625\n",
      "train loss:0.006309199938466666\n",
      "train loss:0.01754001580578509\n",
      "train loss:0.05543793019126067\n",
      "train loss:0.00535222522207753\n",
      "train loss:0.0077981447685425585\n",
      "train loss:0.003990526843581474\n",
      "train loss:0.04063684091303568\n",
      "train loss:0.008580642908500065\n",
      "train loss:0.023197673922610202\n",
      "train loss:0.036039469758412795\n",
      "train loss:0.0737404226668158\n",
      "train loss:0.023703767022182628\n",
      "train loss:0.015870881833185645\n",
      "train loss:0.0025585428364891505\n",
      "train loss:0.0046694891455092\n",
      "train loss:0.024537778598769287\n",
      "train loss:0.02929349302236699\n",
      "train loss:0.006490244969394015\n",
      "train loss:0.023217383222449484\n",
      "train loss:0.004887816315741967\n",
      "train loss:0.012291224231026772\n",
      "train loss:0.009604073411720336\n",
      "train loss:0.014811372033365187\n",
      "train loss:0.041159435770550264\n",
      "train loss:0.011204774300025129\n",
      "train loss:0.04004630681973764\n",
      "train loss:0.0028735989191735027\n",
      "train loss:0.01273364689323036\n",
      "train loss:0.006093542596705387\n",
      "train loss:0.04455356461001261\n",
      "train loss:0.004215005443287345\n",
      "=== epoch:7, train acc:0.988, test acc:0.986 ===\n",
      "train loss:0.02003438621297352\n",
      "train loss:0.002517098375878143\n",
      "train loss:0.009362026848077543\n",
      "train loss:0.003847911343116497\n",
      "train loss:0.0036691460983070312\n",
      "train loss:0.0317420170220077\n",
      "train loss:0.009132604462216526\n",
      "train loss:0.020646186791319767\n",
      "train loss:0.11029446598317579\n",
      "train loss:0.004349848609935718\n",
      "train loss:0.009086072813720744\n",
      "train loss:0.009973619261104467\n",
      "train loss:0.029406189765889167\n",
      "train loss:0.010969279447776427\n",
      "train loss:0.00519245510978728\n",
      "train loss:0.013367858410717613\n",
      "train loss:0.049253343715663804\n",
      "train loss:0.01723030322933934\n",
      "train loss:0.013574882026327739\n",
      "train loss:0.009189285701002012\n",
      "train loss:0.0017040432195416422\n",
      "train loss:0.0226533517459387\n",
      "train loss:0.024140678535981275\n",
      "train loss:0.010254936105444416\n",
      "train loss:0.029133850703345593\n",
      "train loss:0.008480708219627034\n",
      "train loss:0.06899368667924563\n",
      "train loss:0.004563240607701176\n",
      "train loss:0.013782798723230776\n",
      "train loss:0.02278031432622095\n",
      "train loss:0.006407372970380853\n",
      "train loss:0.009621381419658704\n",
      "train loss:0.008964099332885424\n",
      "train loss:0.052355998729617124\n",
      "train loss:0.006971452539455851\n",
      "train loss:0.007619976191715794\n",
      "train loss:0.012444699523820563\n",
      "train loss:0.0065956161220093006\n",
      "train loss:0.019835801857827927\n",
      "train loss:0.010510454814617766\n",
      "train loss:0.008493517280159789\n",
      "train loss:0.014580176746469274\n",
      "train loss:0.08919126540124242\n",
      "train loss:0.005588785769837093\n",
      "train loss:0.007174634811435407\n",
      "train loss:0.013261113637186897\n",
      "train loss:0.005817612154627303\n",
      "train loss:0.007539016682946911\n",
      "train loss:0.05419094304155634\n",
      "train loss:0.03622660999592315\n",
      "train loss:0.06458915993363278\n",
      "train loss:0.0190347651376834\n",
      "train loss:0.0052114804148042536\n",
      "train loss:0.0035455416034390706\n",
      "train loss:0.011764501782202617\n",
      "train loss:0.013552397172018267\n",
      "train loss:0.005160498422491447\n",
      "train loss:0.03472373277209977\n",
      "train loss:0.0042970707312155595\n",
      "train loss:0.03768216786906892\n",
      "train loss:0.015308585286160465\n",
      "train loss:0.023863064512513285\n",
      "train loss:0.005042599159058154\n",
      "train loss:0.04221559990875987\n",
      "train loss:0.059009410964041685\n",
      "train loss:0.008566629320114117\n",
      "train loss:0.005240478258852595\n",
      "train loss:0.005008591614533453\n",
      "train loss:0.0048438960191074295\n",
      "train loss:0.01578229554742599\n",
      "train loss:0.01155670943545569\n",
      "train loss:0.005157249038911269\n",
      "train loss:0.007690821782081819\n",
      "train loss:0.00515672667045075\n",
      "train loss:0.036879947302044344\n",
      "train loss:0.027085230269616734\n",
      "train loss:0.03618455265034758\n",
      "train loss:0.0426928393352549\n",
      "train loss:0.0038457225002775947\n",
      "train loss:0.002796012787929784\n",
      "train loss:0.023229082224513916\n",
      "train loss:0.013188984338490844\n",
      "train loss:0.05000722249421721\n",
      "train loss:0.02379575663055008\n",
      "train loss:0.016133833465808867\n",
      "train loss:0.0187060895150099\n",
      "train loss:0.006632812103457667\n",
      "train loss:0.011984427217546023\n",
      "train loss:0.004980143966932208\n",
      "train loss:0.012297674853337142\n",
      "train loss:0.016009654961997397\n",
      "train loss:0.010300907013019923\n",
      "train loss:0.0026693275598775484\n",
      "train loss:0.009789045447210369\n",
      "train loss:0.008531052396623783\n",
      "train loss:0.009774564684523188\n",
      "train loss:0.005282745059602475\n",
      "train loss:0.03277240758259515\n",
      "train loss:0.006110158321676293\n",
      "train loss:0.01006624217142268\n",
      "train loss:0.00570278954521237\n",
      "train loss:0.005819142872983729\n",
      "train loss:0.00795563134876337\n",
      "train loss:0.0032394045718015423\n",
      "train loss:0.012720294489646037\n",
      "train loss:0.002132004976052765\n",
      "train loss:0.004357513593847624\n",
      "train loss:0.014936527677132695\n",
      "train loss:0.023301028382117797\n",
      "train loss:0.012992748356517324\n",
      "train loss:0.004086266651365495\n",
      "train loss:0.025795809673071782\n",
      "train loss:0.01548184356748718\n",
      "train loss:0.034164114922111376\n",
      "train loss:0.005874443724910008\n",
      "train loss:0.013086242578260765\n",
      "train loss:0.03029483160437153\n",
      "train loss:0.0030889713874392238\n",
      "train loss:0.009299773283050958\n",
      "train loss:0.01831002637884672\n",
      "train loss:0.012758815743180893\n",
      "train loss:0.018327883481322107\n",
      "train loss:0.022147447476019745\n",
      "train loss:0.007083716153805943\n",
      "train loss:0.005402138206485223\n",
      "train loss:0.003952465327012924\n",
      "train loss:0.0031018701228438055\n",
      "train loss:0.015164365998881548\n",
      "train loss:0.010224195841378497\n",
      "train loss:0.021588102807804002\n",
      "train loss:0.03599200706634148\n",
      "train loss:0.014890309604935618\n",
      "train loss:0.005048474371082095\n",
      "train loss:0.0038846439605716115\n",
      "train loss:0.01720541129941861\n",
      "train loss:0.011819229149613085\n",
      "train loss:0.0385216868272806\n",
      "train loss:0.007087070294093478\n",
      "train loss:0.0014134324268479342\n",
      "train loss:0.022334860915008924\n",
      "train loss:0.008317616495042143\n",
      "train loss:0.04427513424362775\n",
      "train loss:0.005774881455797434\n",
      "train loss:0.0049150616403886675\n",
      "train loss:0.055662414430722514\n",
      "train loss:0.010992050755429519\n",
      "train loss:0.00687648644037711\n",
      "train loss:0.0034255264322463246\n",
      "train loss:0.04029686738929575\n",
      "train loss:0.013678367284206632\n",
      "train loss:0.006056063723870436\n",
      "train loss:0.02952415864866238\n",
      "train loss:0.031388820465444306\n",
      "train loss:0.007427452527564662\n",
      "train loss:0.014705625135294826\n",
      "train loss:0.01468512914634278\n",
      "train loss:0.0025976289330038927\n",
      "train loss:0.01502573173808366\n",
      "train loss:0.012930689683350552\n",
      "train loss:0.010736651077740043\n",
      "train loss:0.026353845303958165\n",
      "train loss:0.003991268182126379\n",
      "train loss:0.04184855543911707\n",
      "train loss:0.009179090847645753\n",
      "train loss:0.015247012136466655\n",
      "train loss:0.006202751980554449\n",
      "train loss:0.029698833025620548\n",
      "train loss:0.01549958486499274\n",
      "train loss:0.032780539406004394\n",
      "train loss:0.0058515413457759105\n",
      "train loss:0.006271900933741835\n",
      "train loss:0.019003390355725177\n",
      "train loss:0.01928265205091243\n",
      "train loss:0.015283725677786096\n",
      "train loss:0.00311318786656755\n",
      "train loss:0.11304612265949983\n",
      "train loss:0.0066366074723931655\n",
      "train loss:0.009573291246139915\n",
      "train loss:0.00882332535450673\n",
      "train loss:0.006094908006516358\n",
      "train loss:0.009222621684349449\n",
      "train loss:0.016132677819770954\n",
      "train loss:0.023135736291685728\n",
      "train loss:0.009225467055423481\n",
      "train loss:0.015470123632644646\n",
      "train loss:0.10960891129742352\n",
      "train loss:0.017111855506223385\n",
      "train loss:0.011943045154444108\n",
      "train loss:0.012085781973382937\n",
      "train loss:0.014613415852106687\n",
      "train loss:0.005274183187410772\n",
      "train loss:0.004509609314316195\n",
      "train loss:0.003210313666021335\n",
      "train loss:0.009489819381010964\n",
      "train loss:0.014743715793009085\n",
      "train loss:0.016352312613820405\n",
      "train loss:0.013569514434476989\n",
      "train loss:0.006297776558324443\n",
      "train loss:0.008226086308535815\n",
      "train loss:0.04741288530161846\n",
      "train loss:0.020373430809256993\n",
      "train loss:0.0037677717901114195\n",
      "train loss:0.009070512403573093\n",
      "train loss:0.012290224165244536\n",
      "train loss:0.003222401694440765\n",
      "train loss:0.005888199117534182\n",
      "train loss:0.006619738020999331\n",
      "train loss:0.001188170996704892\n",
      "train loss:0.023193084408788343\n",
      "train loss:0.005649255421017474\n",
      "train loss:0.015844288613064826\n",
      "train loss:0.003977297538827235\n",
      "train loss:0.062156402512112637\n",
      "train loss:0.0020723031492432317\n",
      "train loss:0.013301614610180137\n",
      "train loss:0.01926521439539782\n",
      "train loss:0.004004655992429498\n",
      "train loss:0.012092875566577866\n",
      "train loss:0.004136310232778642\n",
      "train loss:0.0014079096943278421\n",
      "train loss:0.003006633170571366\n",
      "train loss:0.01050443783156834\n",
      "train loss:0.00878085893846079\n",
      "train loss:0.014835169135409316\n",
      "train loss:0.011382095800232138\n",
      "train loss:0.002869277808500313\n",
      "train loss:0.010826476819145465\n",
      "train loss:0.008312959730702342\n",
      "train loss:0.003475879240080498\n",
      "train loss:0.00605141617400607\n",
      "train loss:0.011444879674875376\n",
      "train loss:0.002673036066930836\n",
      "train loss:0.022289046004291792\n",
      "train loss:0.026171783377973323\n",
      "train loss:0.014767614660748734\n",
      "train loss:0.006561676004326671\n",
      "train loss:0.019519598672281476\n",
      "train loss:0.016260622318022087\n",
      "train loss:0.0030006365734203833\n",
      "train loss:0.05481174034906894\n",
      "train loss:0.006016123105864198\n",
      "train loss:0.006425362983459122\n",
      "train loss:0.017296675191558496\n",
      "train loss:0.011796190570129856\n",
      "train loss:0.04921407159574938\n",
      "train loss:0.0021778997962121852\n",
      "train loss:0.012836699447189737\n",
      "train loss:0.010820593479507517\n",
      "train loss:0.010409664328211055\n",
      "train loss:0.0018943938928546583\n",
      "train loss:0.006002006817115878\n",
      "train loss:0.016560501693793493\n",
      "train loss:0.029989246067341536\n",
      "train loss:0.014581235976617504\n",
      "train loss:0.024919975408059937\n",
      "train loss:0.06342576621432984\n",
      "train loss:0.023828641003417195\n",
      "train loss:0.0075939285831780135\n",
      "train loss:0.0020116946513062408\n",
      "train loss:0.010155941824298003\n",
      "train loss:0.022591947355759742\n",
      "train loss:0.026441939797030623\n",
      "train loss:0.012281430354614799\n",
      "train loss:0.013061605863233799\n",
      "train loss:0.01636694736592272\n",
      "train loss:0.00908686781378017\n",
      "train loss:0.00903228908991584\n",
      "train loss:0.006667269616478783\n",
      "train loss:0.00792066762304128\n",
      "train loss:0.015728667141635226\n",
      "train loss:0.012924412776904289\n",
      "train loss:0.00892670914496451\n",
      "train loss:0.010186698926083797\n",
      "train loss:0.019565406749907862\n",
      "train loss:0.0033092061474284972\n",
      "train loss:0.006971637887094163\n",
      "train loss:0.035698320119892143\n",
      "train loss:0.0032867984707296884\n",
      "train loss:0.010438686921868777\n",
      "train loss:0.009874174144153485\n",
      "train loss:0.02129920347311169\n",
      "train loss:0.025120645307523715\n",
      "train loss:0.013658434053865808\n",
      "train loss:0.027768827146582766\n",
      "train loss:0.02048937178457198\n",
      "train loss:0.003376893956102868\n",
      "train loss:0.0094673207129811\n",
      "train loss:0.0028553585809628712\n",
      "train loss:0.012709496960050644\n",
      "train loss:0.013621939752721217\n",
      "train loss:0.008472119251349358\n",
      "train loss:0.006102155760998282\n",
      "train loss:0.02559794695282751\n",
      "train loss:0.01657059887482046\n",
      "train loss:0.0020222867504837132\n",
      "train loss:0.002626331351019884\n",
      "train loss:0.10171514441992191\n",
      "train loss:0.011896013410429673\n",
      "train loss:0.02169322357583852\n",
      "train loss:0.04290929767485481\n",
      "train loss:0.008222589631940084\n",
      "train loss:0.005334848533656383\n",
      "train loss:0.011634386181099314\n",
      "train loss:0.010518308337376285\n",
      "train loss:0.008883887449210108\n",
      "train loss:0.02232338141089604\n",
      "train loss:0.09658098767881054\n",
      "train loss:0.0060293938776123605\n",
      "train loss:0.01126554824913541\n",
      "train loss:0.012363218139445065\n",
      "train loss:0.019249037474343776\n",
      "train loss:0.010042858413371549\n",
      "train loss:0.02049146483192316\n",
      "train loss:0.009589094302447775\n",
      "train loss:0.005117153925599307\n",
      "train loss:0.004375790583079538\n",
      "train loss:0.010399464802821279\n",
      "train loss:0.01167601648267713\n",
      "train loss:0.02482029199120399\n",
      "train loss:0.00359838367394832\n",
      "train loss:0.015576318970481595\n",
      "train loss:0.010191181950240517\n",
      "train loss:0.04033103871464132\n",
      "train loss:0.011429494903378603\n",
      "train loss:0.015497348871039507\n",
      "train loss:0.008785618545713957\n",
      "train loss:0.03905691534221818\n",
      "train loss:0.0029525906396089\n",
      "train loss:0.004597000828814738\n",
      "train loss:0.00411936968946986\n",
      "train loss:0.012714472783917526\n",
      "train loss:0.0026037799317600125\n",
      "train loss:0.004607930503382985\n",
      "train loss:0.005741710482470882\n",
      "train loss:0.018362532948330644\n",
      "train loss:0.006206485061126203\n",
      "train loss:0.002560338717580393\n",
      "train loss:0.0028013158512743743\n",
      "train loss:0.06060183145477385\n",
      "train loss:0.0048296226524143894\n",
      "train loss:0.0015117418532661574\n",
      "train loss:0.0026281852173529728\n",
      "train loss:0.006155718803017156\n",
      "train loss:0.013320483219575331\n",
      "train loss:0.004670120104775937\n",
      "train loss:0.025057254315324674\n",
      "train loss:0.013288693117624331\n",
      "train loss:0.0031005615221661458\n",
      "train loss:0.0069898359889665725\n",
      "train loss:0.008960895649290318\n",
      "train loss:0.023800457475222535\n",
      "train loss:0.028394320402056198\n",
      "train loss:0.002832649146636716\n",
      "train loss:0.0076183376815149115\n",
      "train loss:0.018848303555143883\n",
      "train loss:0.013107862039221733\n",
      "train loss:0.001972835969209077\n",
      "train loss:0.020584553977252795\n",
      "train loss:0.004486102098823065\n",
      "train loss:0.0030525454157936615\n",
      "train loss:0.008089467485367258\n",
      "train loss:0.015242448837858023\n",
      "train loss:0.04522651354201306\n",
      "train loss:0.009632443267584792\n",
      "train loss:0.017779143354525496\n",
      "train loss:0.015053521328639314\n",
      "train loss:0.010687706836515187\n",
      "train loss:0.0075771613868247985\n",
      "train loss:0.047262104562373765\n",
      "train loss:0.007660161686433765\n",
      "train loss:0.006192934790460986\n",
      "train loss:0.00429248018809063\n",
      "train loss:0.027810124808170866\n",
      "train loss:0.002010352532642878\n",
      "train loss:0.027716798404998366\n",
      "train loss:0.0034961348531217856\n",
      "train loss:0.007276709638133864\n",
      "train loss:0.031179389232767873\n",
      "train loss:0.00412150326653706\n",
      "train loss:0.004300616517158084\n",
      "train loss:0.026737442092263825\n",
      "train loss:0.0018218735415790246\n",
      "train loss:0.03592936316575692\n",
      "train loss:0.01381921638035872\n",
      "train loss:0.017970462075280944\n",
      "train loss:0.01420990596750977\n",
      "train loss:0.022218652283448347\n",
      "train loss:0.004542028596464973\n",
      "train loss:0.031401518988022147\n",
      "train loss:0.014030320078205143\n",
      "train loss:0.01346404710330288\n",
      "train loss:0.006902997992741284\n",
      "train loss:0.0406324931289486\n",
      "train loss:0.005549503165162803\n",
      "train loss:0.01269310340174398\n",
      "train loss:0.022484944848235485\n",
      "train loss:0.008482207109238386\n",
      "train loss:0.029351037139484438\n",
      "train loss:0.02068072768169297\n",
      "train loss:0.01919233287493652\n",
      "train loss:0.029169895517468784\n",
      "train loss:0.01943883863222466\n",
      "train loss:0.019020298024611696\n",
      "train loss:0.007811450346070316\n",
      "train loss:0.003383518596620993\n",
      "train loss:0.0015504997113953733\n",
      "train loss:0.06731781158350675\n",
      "train loss:0.0013931418026409586\n",
      "train loss:0.010664359593540151\n",
      "train loss:0.014661228884680218\n",
      "train loss:0.01594377751138289\n",
      "train loss:0.005927209421086793\n",
      "train loss:0.0073434794006307525\n",
      "train loss:0.009644847462698941\n",
      "train loss:0.03409067742224267\n",
      "train loss:0.03200574836928018\n",
      "train loss:0.005840863513804568\n",
      "train loss:0.006100178214213565\n",
      "train loss:0.0016315852238702965\n",
      "train loss:0.023181434515363742\n",
      "train loss:0.05054897599950265\n",
      "train loss:0.046554567240460344\n",
      "train loss:0.0030140543691854218\n",
      "train loss:0.05347399156294662\n",
      "train loss:0.01134293609422934\n",
      "train loss:0.00500832275877742\n",
      "train loss:0.007470216138390214\n",
      "train loss:0.005847982535494147\n",
      "train loss:0.006522285649748747\n",
      "train loss:0.03603369239305066\n",
      "train loss:0.01211441992905014\n",
      "train loss:0.0027600092940450937\n",
      "train loss:0.00937862679044665\n",
      "train loss:0.007958433569467727\n",
      "train loss:0.009907578023063914\n",
      "train loss:0.005647362654547952\n",
      "train loss:0.017936159960586052\n",
      "train loss:0.011400687456993656\n",
      "train loss:0.008810788751147072\n",
      "train loss:0.015264401639537564\n",
      "train loss:0.12062054174662405\n",
      "train loss:0.029588682954678525\n",
      "train loss:0.008576152779196463\n",
      "train loss:0.02538926457424438\n",
      "train loss:0.010141490573861933\n",
      "train loss:0.004618915599655766\n",
      "train loss:0.012566299824550077\n",
      "train loss:0.005927682856696009\n",
      "train loss:0.004525369392050209\n",
      "train loss:0.03083281828856629\n",
      "train loss:0.01645759360491493\n",
      "train loss:0.00852481542191138\n",
      "train loss:0.014149510376826662\n",
      "train loss:0.006849213167094673\n",
      "train loss:0.012242299391675366\n",
      "train loss:0.0057758088071655335\n",
      "train loss:0.00841284022475355\n",
      "train loss:0.012161101272279476\n",
      "train loss:0.007158034264762953\n",
      "train loss:0.007965610908580658\n",
      "train loss:0.03296832140089973\n",
      "train loss:0.008847688016404964\n",
      "train loss:0.021621106163714477\n",
      "train loss:0.022558165143330394\n",
      "train loss:0.005697139576062764\n",
      "train loss:0.01015932638520954\n",
      "train loss:0.022259653233685867\n",
      "train loss:0.007246191993990388\n",
      "train loss:0.010912771776101124\n",
      "train loss:0.006405549223176975\n",
      "train loss:0.033687234231039975\n",
      "train loss:0.002253683716250675\n",
      "train loss:0.018203708965287814\n",
      "train loss:0.008272008711194483\n",
      "train loss:0.03655293079920326\n",
      "train loss:0.011006926762996964\n",
      "train loss:0.014829054359322842\n",
      "train loss:0.02996171052920177\n",
      "train loss:0.004320175827696353\n",
      "train loss:0.0013735546183224268\n",
      "train loss:0.0021695127603333537\n",
      "train loss:0.03181591843821797\n",
      "train loss:0.013779253335753174\n",
      "train loss:0.004240353063170114\n",
      "train loss:0.006295511394864411\n",
      "train loss:0.009818819572431742\n",
      "train loss:0.003427413970556348\n",
      "train loss:0.009319170038633404\n",
      "train loss:0.02743283447212197\n",
      "train loss:0.009121731657721281\n",
      "train loss:0.010781283887095365\n",
      "train loss:0.0019034973839760138\n",
      "train loss:0.062262264343029186\n",
      "train loss:0.0038047181475251396\n",
      "train loss:0.010589680120384175\n",
      "train loss:0.003798953306731942\n",
      "train loss:0.04687321177964716\n",
      "train loss:0.008653253939847148\n",
      "train loss:0.05567620694375493\n",
      "train loss:0.013520264294551854\n",
      "train loss:0.001469255642054117\n",
      "train loss:0.008366932687647856\n",
      "train loss:0.007272772120616202\n",
      "train loss:0.07209785399957981\n",
      "train loss:0.008544336003714088\n",
      "train loss:0.017121693179546114\n",
      "train loss:0.010298650986701137\n",
      "train loss:0.011649397341958077\n",
      "train loss:0.0024726169633962126\n",
      "train loss:0.004911541298283438\n",
      "train loss:0.013310211164352296\n",
      "train loss:0.015390117637158297\n",
      "train loss:0.08280553143534167\n",
      "train loss:0.03828093307258535\n",
      "train loss:0.028735342490421666\n",
      "train loss:0.005655947348546944\n",
      "train loss:0.023643693196309667\n",
      "train loss:0.007177761439800263\n",
      "train loss:0.013950104758801646\n",
      "train loss:0.0022898600011014222\n",
      "train loss:0.014629207456252616\n",
      "train loss:0.010001203358431294\n",
      "train loss:0.005114647491502665\n",
      "train loss:0.007629770984662516\n",
      "train loss:0.01203960917567337\n",
      "train loss:0.03845978722992739\n",
      "train loss:0.008390718798302759\n",
      "train loss:0.03386495120315397\n",
      "train loss:0.005835973497481589\n",
      "train loss:0.061410399669783365\n",
      "train loss:0.01960450817828787\n",
      "train loss:0.009668759644079917\n",
      "train loss:0.005848774151649892\n",
      "train loss:0.010829214880911495\n",
      "train loss:0.0031860424910105218\n",
      "train loss:0.03423687581385739\n",
      "train loss:0.006901375038958175\n",
      "train loss:0.004697127862728913\n",
      "train loss:0.007253497792107995\n",
      "train loss:0.010697726812789028\n",
      "train loss:0.006720146487155921\n",
      "train loss:0.01141502344389254\n",
      "train loss:0.01823420890070533\n",
      "train loss:0.01423301430187906\n",
      "train loss:0.010878107799236949\n",
      "train loss:0.030671936091936032\n",
      "train loss:0.0034224297343960403\n",
      "train loss:0.0031995456367586612\n",
      "train loss:0.005684706280289788\n",
      "train loss:0.0497949408740229\n",
      "train loss:0.004430441345153643\n",
      "train loss:0.0050530539842701784\n",
      "train loss:0.002050479519449844\n",
      "train loss:0.014614081991085081\n",
      "train loss:0.0048704746914963295\n",
      "train loss:0.05783742982523891\n",
      "train loss:0.010654434897221987\n",
      "train loss:0.08932987505542936\n",
      "train loss:0.006353427633720634\n",
      "train loss:0.011566558730807263\n",
      "train loss:0.016896742574178055\n",
      "train loss:0.016682213171014888\n",
      "train loss:0.003369968154051697\n",
      "train loss:0.007875332231043622\n",
      "train loss:0.029474915410119117\n",
      "train loss:0.009777709567451639\n",
      "train loss:0.022918146392709463\n",
      "train loss:0.012486615414571358\n",
      "train loss:0.02230365918965125\n",
      "train loss:0.014559540547375079\n",
      "train loss:0.004364428333469147\n",
      "train loss:0.010825961549476189\n",
      "train loss:0.027446639914416694\n",
      "train loss:0.015204781802993506\n",
      "train loss:0.008819351405213872\n",
      "train loss:0.01292179349535516\n",
      "train loss:0.001958727852737583\n",
      "train loss:0.004034621862773418\n",
      "train loss:0.006148230833711526\n",
      "train loss:0.02726352155250478\n",
      "train loss:0.02073997808398366\n",
      "train loss:0.01519404067570105\n",
      "train loss:0.011395387334175855\n",
      "train loss:0.0019252899262360312\n",
      "train loss:0.022920033473084928\n",
      "train loss:0.009160760675156088\n",
      "train loss:0.01882727810248575\n",
      "train loss:0.012049509605772135\n",
      "train loss:0.005988455531033998\n",
      "train loss:0.007762738616872652\n",
      "train loss:0.007973508147864263\n",
      "train loss:0.009141953236569397\n",
      "train loss:0.015343698205134159\n",
      "train loss:0.010950675166423222\n",
      "train loss:0.004446869223408481\n",
      "train loss:0.007958538740454957\n",
      "train loss:0.027266011789378777\n",
      "train loss:0.022765562524577936\n",
      "train loss:0.014531630094067535\n",
      "train loss:0.008321518288069733\n",
      "=== epoch:8, train acc:0.993, test acc:0.99 ===\n",
      "train loss:0.00200730368709119\n",
      "train loss:0.0017860046545741112\n",
      "train loss:0.004323512076224839\n",
      "train loss:0.008260413957977879\n",
      "train loss:0.014723694817674826\n",
      "train loss:0.00744846030375228\n",
      "train loss:0.016780541668460335\n",
      "train loss:0.009025327299130168\n",
      "train loss:0.06253717518758968\n",
      "train loss:0.004426808530569636\n",
      "train loss:0.010922898008908674\n",
      "train loss:0.007217713307520219\n",
      "train loss:0.006960251820456687\n",
      "train loss:0.030201676471846996\n",
      "train loss:0.02259543839215228\n",
      "train loss:0.004003102004738735\n",
      "train loss:0.021689894789856234\n",
      "train loss:0.011196564364945589\n",
      "train loss:0.041411533299480094\n",
      "train loss:0.012892820995880619\n",
      "train loss:0.01663500569941423\n",
      "train loss:0.0388041016327278\n",
      "train loss:0.03207581743810521\n",
      "train loss:0.0080878543595854\n",
      "train loss:0.0049085250386576434\n",
      "train loss:0.0032641677558782035\n",
      "train loss:0.01109832904464437\n",
      "train loss:0.00783636396605132\n",
      "train loss:0.023924680847557594\n",
      "train loss:0.0019382910184252997\n",
      "train loss:0.029392116088145393\n",
      "train loss:0.0012773190316906523\n",
      "train loss:0.008544122308367817\n",
      "train loss:0.04486449550230718\n",
      "train loss:0.012420064702147546\n",
      "train loss:0.014573926611149502\n",
      "train loss:0.004689801900444299\n",
      "train loss:0.0023928735944000763\n",
      "train loss:0.008833128798752839\n",
      "train loss:0.012252238322792468\n",
      "train loss:0.005387141462656395\n",
      "train loss:0.022569048610452808\n",
      "train loss:0.0032086605820300013\n",
      "train loss:0.004019106867053377\n",
      "train loss:0.0029134102871023115\n",
      "train loss:0.006393179601896519\n",
      "train loss:0.005288754324280448\n",
      "train loss:0.023798688989556872\n",
      "train loss:0.005843605193776726\n",
      "train loss:0.00475675579534376\n",
      "train loss:0.005318935176933099\n",
      "train loss:0.00632710786231272\n",
      "train loss:0.010634685721912798\n",
      "train loss:0.006626669736481858\n",
      "train loss:0.0020950235950990205\n",
      "train loss:0.00986750442034959\n",
      "train loss:0.012300035966269812\n",
      "train loss:0.003952117685040537\n",
      "train loss:0.006877456260817252\n",
      "train loss:0.003953496657849847\n",
      "train loss:0.004219502862091221\n",
      "train loss:0.011219133722993501\n",
      "train loss:0.005180991895749074\n",
      "train loss:0.0059842612828662186\n",
      "train loss:0.017965576970328204\n",
      "train loss:0.006074452230811334\n",
      "train loss:0.030737566762939542\n",
      "train loss:0.0033131512697878447\n",
      "train loss:0.0041329387222553545\n",
      "train loss:0.006018325883802706\n",
      "train loss:0.01152614218270267\n",
      "train loss:0.011935827060043197\n",
      "train loss:0.010485083680515137\n",
      "train loss:0.012441304754657536\n",
      "train loss:0.014811434519016644\n",
      "train loss:0.002794682059294994\n",
      "train loss:0.032388599433364265\n",
      "train loss:0.0021748350125260748\n",
      "train loss:0.0022417717055428694\n",
      "train loss:0.007866106554958324\n",
      "train loss:0.008853631559102319\n",
      "train loss:0.0018580033641628062\n",
      "train loss:0.020405033543264627\n",
      "train loss:0.001819088338088423\n",
      "train loss:0.025832956724350563\n",
      "train loss:0.0009323614662999234\n",
      "train loss:0.009937392573267501\n",
      "train loss:0.007996675031643951\n",
      "train loss:0.0010685994225113737\n",
      "train loss:0.01000730353865953\n",
      "train loss:0.002819479132478042\n",
      "train loss:0.02607428161988472\n",
      "train loss:0.001713956420175585\n",
      "train loss:0.0593659728084866\n",
      "train loss:0.10289552916650183\n",
      "train loss:0.00543389891163654\n",
      "train loss:0.002912753796169395\n",
      "train loss:0.0031202754433759337\n",
      "train loss:0.006011318842642502\n",
      "train loss:0.0014898477097736718\n",
      "train loss:0.005419704266460851\n",
      "train loss:0.0013028889741201742\n",
      "train loss:0.00665168290762562\n",
      "train loss:0.0017065891747540473\n",
      "train loss:0.00543068871700966\n",
      "train loss:0.014677329962799161\n",
      "train loss:0.010193501396072065\n",
      "train loss:0.011531039704615149\n",
      "train loss:0.0049665842448214795\n",
      "train loss:0.003545235942717746\n",
      "train loss:0.0049774307618144515\n",
      "train loss:0.011119863703262007\n",
      "train loss:0.011438642710401925\n",
      "train loss:0.0036274093452006067\n",
      "train loss:0.00867909508393326\n",
      "train loss:0.01085673159606142\n",
      "train loss:0.004281069592967983\n",
      "train loss:0.012603448508928755\n",
      "train loss:0.0064174906267582595\n",
      "train loss:0.010402415550068399\n",
      "train loss:0.016195626215705507\n",
      "train loss:0.009238264351296436\n",
      "train loss:0.00836676656083771\n",
      "train loss:0.007330399242294414\n",
      "train loss:0.056387444893229735\n",
      "train loss:0.004579744368109658\n",
      "train loss:0.046912321297793706\n",
      "train loss:0.0008611047336899434\n",
      "train loss:0.016537327594998315\n",
      "train loss:0.019682490728497176\n",
      "train loss:0.024943779941883987\n",
      "train loss:0.004936648844261796\n",
      "train loss:0.013085825411265734\n",
      "train loss:0.02578794903504777\n",
      "train loss:0.0043154189554256255\n",
      "train loss:0.02377460856124054\n",
      "train loss:0.04559838361860332\n",
      "train loss:0.0020042760458441064\n",
      "train loss:0.014902018391639498\n",
      "train loss:0.0022517070812790845\n",
      "train loss:0.013032069619578616\n",
      "train loss:0.0013314050167215642\n",
      "train loss:0.016969892569088145\n",
      "train loss:0.011708807431073014\n",
      "train loss:0.0075572035618826534\n",
      "train loss:0.010434275429508423\n",
      "train loss:0.005350698184259301\n",
      "train loss:0.0011295787758372454\n",
      "train loss:0.004073038849349489\n",
      "train loss:0.020310577296636954\n",
      "train loss:0.0063379447789437045\n",
      "train loss:0.02338644736152679\n",
      "train loss:0.017923883474016477\n",
      "train loss:0.00508749443166421\n",
      "train loss:0.017656099686650377\n",
      "train loss:0.004670728588930131\n",
      "train loss:0.013953243296633323\n",
      "train loss:0.003323992768398163\n",
      "train loss:0.0024172613931042197\n",
      "train loss:0.006053020258891404\n",
      "train loss:0.003987495201230087\n",
      "train loss:0.06442474689151506\n",
      "train loss:0.009342647928827694\n",
      "train loss:0.0019244274373433335\n",
      "train loss:0.08469688239242774\n",
      "train loss:0.023486015964918516\n",
      "train loss:0.00833773025737827\n",
      "train loss:0.0018409415146590185\n",
      "train loss:0.005334017935027579\n",
      "train loss:0.018013822735019527\n",
      "train loss:0.008058383318426622\n",
      "train loss:0.09005204390082731\n",
      "train loss:0.0023542865849574407\n",
      "train loss:0.03330187003822066\n",
      "train loss:0.009369013080213255\n",
      "train loss:0.024824132558337632\n",
      "train loss:0.04102702427559634\n",
      "train loss:0.012743929467648178\n",
      "train loss:0.008472359941596027\n",
      "train loss:0.016442789628732538\n",
      "train loss:0.00859965816601408\n",
      "train loss:0.006480507920460172\n",
      "train loss:0.007423730298025914\n",
      "train loss:0.004234830973378848\n",
      "train loss:0.011281620487747786\n",
      "train loss:0.01146529808884616\n",
      "train loss:0.007063974595080066\n",
      "train loss:0.009976290401134496\n",
      "train loss:0.0018395486178501815\n",
      "train loss:0.008299554091677383\n",
      "train loss:0.06737235265041426\n",
      "train loss:0.003802938543210145\n",
      "train loss:0.0418119800226537\n",
      "train loss:0.002817234636705296\n",
      "train loss:0.006495638905171002\n",
      "train loss:0.003928184762356303\n",
      "train loss:0.0746836741298619\n",
      "train loss:0.027958707236735013\n",
      "train loss:0.008073922254227341\n",
      "train loss:0.011342683678091126\n",
      "train loss:0.010132200840825762\n",
      "train loss:0.002119118522232776\n",
      "train loss:0.0028787602684850195\n",
      "train loss:0.01514665730725317\n",
      "train loss:0.007459106891822383\n",
      "train loss:0.03171605267237094\n",
      "train loss:0.0018306333094650889\n",
      "train loss:0.00555776819720148\n",
      "train loss:0.005732857990004479\n",
      "train loss:0.006251416603285768\n",
      "train loss:0.0019554596444092023\n",
      "train loss:0.0009163482712248113\n",
      "train loss:0.00392371591560007\n",
      "train loss:0.008740941220713129\n",
      "train loss:0.0028431417248644675\n",
      "train loss:0.0042808565510116916\n",
      "train loss:0.007536985063542093\n",
      "train loss:0.00395168689606885\n",
      "train loss:0.0013606958367476788\n",
      "train loss:0.023845364825464562\n",
      "train loss:0.00512639634280533\n",
      "train loss:0.013879299693155552\n",
      "train loss:0.010047053944506619\n",
      "train loss:0.015450080187728987\n",
      "train loss:0.009030986832023621\n",
      "train loss:0.08123820878581281\n",
      "train loss:0.0053840647122114435\n",
      "train loss:0.0061628331147437244\n",
      "train loss:0.04550374787694934\n",
      "train loss:0.003193463866816858\n",
      "train loss:0.03586316026544661\n",
      "train loss:0.009136168391133287\n",
      "train loss:0.012970746017182342\n",
      "train loss:0.020638131335956964\n",
      "train loss:0.008629581298038352\n",
      "train loss:0.009542338975862031\n",
      "train loss:0.017277819407674234\n",
      "train loss:0.0024421024090788205\n",
      "train loss:0.0031410249880254202\n",
      "train loss:0.0037238238864252056\n",
      "train loss:0.004834403888536284\n",
      "train loss:0.013608307516897287\n",
      "train loss:0.012803946798152143\n",
      "train loss:0.02103986296846171\n",
      "train loss:0.0034783888359253127\n",
      "train loss:0.008727071488510934\n",
      "train loss:0.0033573345775062885\n",
      "train loss:0.017213223927766398\n",
      "train loss:0.004500190394026754\n",
      "train loss:0.02187445323901792\n",
      "train loss:0.0025501512463968158\n",
      "train loss:0.0075751974200075145\n",
      "train loss:0.009644963131070949\n",
      "train loss:0.008100679958076246\n",
      "train loss:0.012755277662803885\n",
      "train loss:0.012224583353766978\n",
      "train loss:0.0033671526973067527\n",
      "train loss:0.00109619425708501\n",
      "train loss:0.003556559361467872\n",
      "train loss:0.010904905372025224\n",
      "train loss:0.005974772581775783\n",
      "train loss:0.0161770492224962\n",
      "train loss:0.017449361072374336\n",
      "train loss:0.010013449320822687\n",
      "train loss:0.0034022982337819775\n",
      "train loss:0.007963373454092315\n",
      "train loss:0.019801033803033476\n",
      "train loss:0.011708959243933403\n",
      "train loss:0.015178498261547435\n",
      "train loss:0.009891885589232798\n",
      "train loss:0.007356211975958197\n",
      "train loss:0.0007143793740509187\n",
      "train loss:0.004716718705349066\n",
      "train loss:0.002288922060943134\n",
      "train loss:0.0014879703661808835\n",
      "train loss:0.002504604868703926\n",
      "train loss:0.03094925509892258\n",
      "train loss:0.004171062673551583\n",
      "train loss:0.003555021868689155\n",
      "train loss:0.0019734762479795115\n",
      "train loss:0.009288294659354589\n",
      "train loss:0.0007685830266773272\n",
      "train loss:0.009754852224254172\n",
      "train loss:0.0009528283022975989\n",
      "train loss:0.018472553225981507\n",
      "train loss:0.015209566584882287\n",
      "train loss:0.0053656401900833775\n",
      "train loss:0.04387345573753233\n",
      "train loss:0.002301429232596363\n",
      "train loss:0.004180934320370059\n",
      "train loss:0.0023828743158174934\n",
      "train loss:0.004063215420410993\n",
      "train loss:0.010256861839548288\n",
      "train loss:0.007188241514048291\n",
      "train loss:0.007138188871956197\n",
      "train loss:0.134399249314475\n",
      "train loss:0.0058565512121147665\n",
      "train loss:0.012586204452309275\n",
      "train loss:0.00260380741802921\n",
      "train loss:0.048360336606433824\n",
      "train loss:0.08351203770126553\n",
      "train loss:0.0018882021607416163\n",
      "train loss:0.0209251822957019\n",
      "train loss:0.005531112395830481\n",
      "train loss:0.011074050833553353\n",
      "train loss:0.005658158148608142\n",
      "train loss:0.014214651046909837\n",
      "train loss:0.01091414748505032\n",
      "train loss:0.005197191965908654\n",
      "train loss:0.021538138247089108\n",
      "train loss:0.008619302684533932\n",
      "train loss:0.0012648335030738917\n",
      "train loss:0.011493840420052517\n",
      "train loss:0.0147733958663731\n",
      "train loss:0.08343931074956677\n",
      "train loss:0.0027891713825735887\n",
      "train loss:0.0020623519945252695\n",
      "train loss:0.03091232563822699\n",
      "train loss:0.0022735201408578282\n",
      "train loss:0.004415690864076944\n",
      "train loss:0.00436912545170463\n",
      "train loss:0.010060816732584714\n",
      "train loss:0.07531413924752144\n",
      "train loss:0.012695041749499343\n",
      "train loss:0.008731181657915733\n",
      "train loss:0.01620091447913632\n",
      "train loss:0.011528956918597564\n",
      "train loss:0.0015166653338540492\n",
      "train loss:0.01103315269556252\n",
      "train loss:0.013207143071633762\n",
      "train loss:0.004036190683315644\n",
      "train loss:0.002257820658285788\n",
      "train loss:0.0036424951894070963\n",
      "train loss:0.006281327940310183\n",
      "train loss:0.00807185348423531\n",
      "train loss:0.027914960606818882\n",
      "train loss:0.0034303431033291063\n",
      "train loss:0.016430440290225938\n",
      "train loss:0.006143326852458333\n",
      "train loss:0.009688054116758509\n",
      "train loss:0.014726559093201936\n",
      "train loss:0.007251155520406838\n",
      "train loss:0.025537249439077172\n",
      "train loss:0.01347475717516623\n",
      "train loss:0.011709449568485788\n",
      "train loss:0.0117362964292958\n",
      "train loss:0.010865961068130547\n",
      "train loss:0.0071870011906425835\n",
      "train loss:0.0013546452022364216\n",
      "train loss:0.002869710467551358\n",
      "train loss:0.07665681919373699\n",
      "train loss:0.016386259231153933\n",
      "train loss:0.007848103538452304\n",
      "train loss:0.011548795477888712\n",
      "train loss:0.005875486884928298\n",
      "train loss:0.00935283485453042\n",
      "train loss:0.003352759566477798\n",
      "train loss:0.007541628961516468\n",
      "train loss:0.020440961446622524\n",
      "train loss:0.00487038119374937\n",
      "train loss:0.003745868447645202\n",
      "train loss:0.020904764688816312\n",
      "train loss:0.010681176050930195\n",
      "train loss:0.004798999698827279\n",
      "train loss:0.035765597883350014\n",
      "train loss:0.027261603931597614\n",
      "train loss:0.021448292056533334\n",
      "train loss:0.0020838081417380314\n",
      "train loss:0.004312917518091731\n",
      "train loss:0.002577493178505787\n",
      "train loss:0.0022921262662775107\n",
      "train loss:0.011072410874115923\n",
      "train loss:0.05501890160783824\n",
      "train loss:0.03856996055474779\n",
      "train loss:0.0037889507095223204\n",
      "train loss:0.005500837177179362\n",
      "train loss:0.01677532505365707\n",
      "train loss:0.015636672733849187\n",
      "train loss:0.039498546699917286\n",
      "train loss:0.03462426006359169\n",
      "train loss:0.002026864314333117\n",
      "train loss:0.040018687716403045\n",
      "train loss:0.004983624506115478\n",
      "train loss:0.010980186596101438\n",
      "train loss:0.002769813903342669\n",
      "train loss:0.006830452535723555\n",
      "train loss:0.004493948024170551\n",
      "train loss:0.00718631758690892\n",
      "train loss:0.0033878169801797426\n",
      "train loss:0.0017927854872741866\n",
      "train loss:0.0034401384004698605\n",
      "train loss:0.0209498012007303\n",
      "train loss:0.05191636840430169\n",
      "train loss:0.02035950337786466\n",
      "train loss:0.011305227780571647\n",
      "train loss:0.010455028446041355\n",
      "train loss:0.008085789831000788\n",
      "train loss:0.0008927124468364477\n",
      "train loss:0.006075036470693102\n",
      "train loss:0.0034775956780739854\n",
      "train loss:0.0278916675494005\n",
      "train loss:0.057932424014009165\n",
      "train loss:0.05944385066908154\n",
      "train loss:0.003699948607921111\n",
      "train loss:0.006010844593682613\n",
      "train loss:0.0024487761380366205\n",
      "train loss:0.006002843758640701\n",
      "train loss:0.018823494123145604\n",
      "train loss:0.010600203184860673\n",
      "train loss:0.0010264143169191782\n",
      "train loss:0.0034701280861966573\n",
      "train loss:0.03257313417753662\n",
      "train loss:0.008388398303746571\n",
      "train loss:0.008883319090816081\n",
      "train loss:0.0056803972539613504\n",
      "train loss:0.0053314445867482544\n",
      "train loss:0.0015107340063487307\n",
      "train loss:0.0033370208801513273\n",
      "train loss:0.0023602198434209904\n",
      "train loss:0.0022977222024939473\n",
      "train loss:0.0005369349621279982\n",
      "train loss:0.03589669349062327\n",
      "train loss:0.001501323730268526\n",
      "train loss:0.004142566718987527\n",
      "train loss:0.0019303252562948405\n",
      "train loss:0.004439219080640825\n",
      "train loss:0.005242107507434005\n",
      "train loss:0.018184637873444896\n",
      "train loss:0.011315939029718567\n",
      "train loss:0.01205036934669979\n",
      "train loss:0.010387112747734333\n",
      "train loss:0.045518060093174766\n",
      "train loss:0.0018703764154755554\n",
      "train loss:0.009916831859028016\n",
      "train loss:0.018253778897018357\n",
      "train loss:0.015592411466878186\n",
      "train loss:0.005992704584128199\n",
      "train loss:0.01542608290063184\n",
      "train loss:0.008324894624149657\n",
      "train loss:0.005317058748140513\n",
      "train loss:0.02443883153922494\n",
      "train loss:0.0022843546116210977\n",
      "train loss:0.005917619655449916\n",
      "train loss:0.0038015183749029206\n",
      "train loss:0.005445275124798279\n",
      "train loss:0.0077872199595213545\n",
      "train loss:0.00211354075644743\n",
      "train loss:0.0013867391322186962\n",
      "train loss:0.010647649216509436\n",
      "train loss:0.005217806139966997\n",
      "train loss:0.001095109552190692\n",
      "train loss:0.009358818206571744\n",
      "train loss:0.003123905022731729\n",
      "train loss:0.024768624133109925\n",
      "train loss:0.008473734200429463\n",
      "train loss:0.0024596057023316734\n",
      "train loss:0.012625411454534729\n",
      "train loss:0.0720568051428073\n",
      "train loss:0.003560637807002145\n",
      "train loss:0.003236440129970885\n",
      "train loss:0.005567023063660836\n",
      "train loss:0.021948554859383775\n",
      "train loss:0.004534029127656191\n",
      "train loss:0.0019775211579002995\n",
      "train loss:0.026442130640206146\n",
      "train loss:0.032971833752148336\n",
      "train loss:0.023581075765315512\n",
      "train loss:0.0033193775034778116\n",
      "train loss:0.005785777526182523\n",
      "train loss:0.01839981905994459\n",
      "train loss:0.004516026807034815\n",
      "train loss:0.0019507883149402804\n",
      "train loss:0.003142363461745088\n",
      "train loss:0.015702464706333515\n",
      "train loss:0.04942661647778342\n",
      "train loss:0.002515188671467875\n",
      "train loss:0.002697411670306399\n",
      "train loss:0.007174144741765377\n",
      "train loss:0.033886823353700975\n",
      "train loss:0.001615793393670167\n",
      "train loss:0.025539718403517243\n",
      "train loss:0.011071969771669205\n",
      "train loss:0.02395665729560001\n",
      "train loss:0.003879730366445559\n",
      "train loss:0.00793773427330147\n",
      "train loss:0.0035475293993711887\n",
      "train loss:0.007865770237892063\n",
      "train loss:0.03475431329796353\n",
      "train loss:0.004711187439509314\n",
      "train loss:0.009182841837870432\n",
      "train loss:0.002953949149936802\n",
      "train loss:0.006215221461816851\n",
      "train loss:0.003755457455950749\n",
      "train loss:0.0029383199814678627\n",
      "train loss:0.0013355366696609678\n",
      "train loss:0.004450454211463802\n",
      "train loss:0.007912404185166042\n",
      "train loss:0.018442761095693837\n",
      "train loss:0.00463230895212374\n",
      "train loss:0.0022659518594377345\n",
      "train loss:0.02663143316450829\n",
      "train loss:0.01068673392022369\n",
      "train loss:0.010357956675480624\n",
      "train loss:0.016497375752930955\n",
      "train loss:0.006889698236171304\n",
      "train loss:0.003958574151190216\n",
      "train loss:0.0056344313833623086\n",
      "train loss:0.011624339060879332\n",
      "train loss:0.004469355331157462\n",
      "train loss:0.04189266980009628\n",
      "train loss:0.02581108407159189\n",
      "train loss:0.009453115028946836\n",
      "train loss:0.002284518131585756\n",
      "train loss:0.004801387839899452\n",
      "train loss:0.001262966937517287\n",
      "train loss:0.013147475009490771\n",
      "train loss:0.004590094103087293\n",
      "train loss:0.059451430642188295\n",
      "train loss:0.00287764795561315\n",
      "train loss:0.010690375945848112\n",
      "train loss:0.008577154828338242\n",
      "train loss:0.008377300464253\n",
      "train loss:0.005603127541456171\n",
      "train loss:0.004717830943200566\n",
      "train loss:0.011609124938902409\n",
      "train loss:0.013421113748018965\n",
      "train loss:0.002171033535993118\n",
      "train loss:0.020453224557637234\n",
      "train loss:0.0016844721845803848\n",
      "train loss:0.00688995037863729\n",
      "train loss:0.004165852701294211\n",
      "train loss:0.012606589909171908\n",
      "train loss:0.012431940775134516\n",
      "train loss:0.011068629168444435\n",
      "train loss:0.005609130482899993\n",
      "train loss:0.002055985848694326\n",
      "train loss:0.07761231053397666\n",
      "train loss:0.004134577974213281\n",
      "train loss:0.0021085437612182053\n",
      "train loss:0.0038235028696559413\n",
      "train loss:0.012780607925502537\n",
      "train loss:0.005438814624938972\n",
      "train loss:0.010185231064105705\n",
      "train loss:0.0030588099078740338\n",
      "train loss:0.0036742520743490215\n",
      "train loss:0.0085586618960011\n",
      "train loss:0.002875731830905039\n",
      "train loss:0.010050654991905238\n",
      "train loss:0.006306087589985682\n",
      "train loss:0.00751957157414293\n",
      "train loss:0.0030371231048833213\n",
      "train loss:0.0031270094820629994\n",
      "train loss:0.006252805822599743\n",
      "train loss:0.0050771615829381545\n",
      "train loss:0.003539679003192046\n",
      "train loss:0.0061932380175107205\n",
      "train loss:0.0014759670354931836\n",
      "train loss:0.02419909301467972\n",
      "train loss:0.01882788125968847\n",
      "train loss:0.0024055062615988177\n",
      "train loss:0.0012493310964612162\n",
      "train loss:0.002215896863831484\n",
      "train loss:0.0040299166758289585\n",
      "train loss:0.0008736892518797703\n",
      "train loss:0.012328893593440873\n",
      "train loss:0.003934254362663337\n",
      "train loss:0.010989942900489809\n",
      "train loss:0.005553005715199084\n",
      "train loss:0.009439912613566984\n",
      "train loss:0.04128583232841905\n",
      "train loss:0.017680383807122904\n",
      "train loss:0.0021084033265374538\n",
      "train loss:0.02844591145674692\n",
      "train loss:0.009600926481787888\n",
      "train loss:0.013285118156978339\n",
      "train loss:0.0035233736949006433\n",
      "train loss:0.004644265944526826\n",
      "train loss:0.00409667219110968\n",
      "train loss:0.005839412089721532\n",
      "train loss:0.008882509074321332\n",
      "train loss:0.0035163084684002215\n",
      "train loss:0.03886951514789775\n",
      "train loss:0.008294890110881319\n",
      "train loss:0.011176897735538711\n",
      "train loss:0.009315583346644849\n",
      "train loss:0.03042285780205105\n",
      "train loss:0.0038079108549666034\n",
      "train loss:0.0016528030571724278\n",
      "train loss:0.006977040011236926\n",
      "train loss:0.002122542217952483\n",
      "train loss:0.00855107537402394\n",
      "train loss:0.006977172413799613\n",
      "train loss:0.0021864178445307083\n",
      "train loss:0.014703605489373666\n",
      "train loss:0.005689041757245478\n",
      "train loss:0.006546701760841425\n",
      "train loss:0.0029373081660469197\n",
      "train loss:0.003374592129333934\n",
      "train loss:0.0043318364725915505\n",
      "train loss:0.010418608551651118\n",
      "=== epoch:9, train acc:0.993, test acc:0.985 ===\n",
      "train loss:0.002220106718799373\n",
      "train loss:0.023124470355434735\n",
      "train loss:0.013035587540595396\n",
      "train loss:0.0052737646200497765\n",
      "train loss:0.008835368302854906\n",
      "train loss:0.011688284485935034\n",
      "train loss:0.0060997579821728855\n",
      "train loss:0.002064677122187951\n",
      "train loss:0.017710079151656778\n",
      "train loss:0.01679103365403192\n",
      "train loss:0.006898952494275242\n",
      "train loss:0.0007014788796727501\n",
      "train loss:0.005139067585759822\n",
      "train loss:0.027588974804036014\n",
      "train loss:0.007673037859905274\n",
      "train loss:0.018186890080633247\n",
      "train loss:0.0039910554088563085\n",
      "train loss:0.01337236303749085\n",
      "train loss:0.006930389750086547\n",
      "train loss:0.010091762485324358\n",
      "train loss:0.003115601577869722\n",
      "train loss:0.03541569494037695\n",
      "train loss:0.0014106977425197625\n",
      "train loss:0.0077458016406965315\n",
      "train loss:0.03288630159950113\n",
      "train loss:0.01066206906745484\n",
      "train loss:0.0049465195711904135\n",
      "train loss:0.002419705942596395\n",
      "train loss:0.010014763100067142\n",
      "train loss:0.005695839674484865\n",
      "train loss:0.021028587410715095\n",
      "train loss:0.008314944913703848\n",
      "train loss:0.007323179562333503\n",
      "train loss:0.009513192333521197\n",
      "train loss:0.04840165230802018\n",
      "train loss:0.0035317013810085302\n",
      "train loss:0.0056848703981627864\n",
      "train loss:0.0021863367888110942\n",
      "train loss:0.0044705319623858635\n",
      "train loss:0.07034610007462666\n",
      "train loss:0.011321100206035273\n",
      "train loss:0.008592880135669988\n",
      "train loss:0.034901018036405745\n",
      "train loss:0.008953593013195083\n",
      "train loss:0.010306351757518343\n",
      "train loss:0.0330310506817127\n",
      "train loss:0.0041110729114009975\n",
      "train loss:0.001274910870357984\n",
      "train loss:0.004429537031426315\n",
      "train loss:0.010815699498910395\n",
      "train loss:0.005920335586380479\n",
      "train loss:0.0038430333554456382\n",
      "train loss:0.03612557763242246\n",
      "train loss:0.007350649055070026\n",
      "train loss:0.008468092964494835\n",
      "train loss:0.04321641813764379\n",
      "train loss:0.003759089292339644\n",
      "train loss:0.0012936958897437744\n",
      "train loss:0.051284336331850894\n",
      "train loss:0.030168126317376847\n",
      "train loss:0.01311263770528557\n",
      "train loss:0.0047547679974327675\n",
      "train loss:0.00617034753399209\n",
      "train loss:0.003389016945564819\n",
      "train loss:0.0026058449784519566\n",
      "train loss:0.004723901999190772\n",
      "train loss:0.00643714891180786\n",
      "train loss:0.00967431667425897\n",
      "train loss:0.0025144303828391725\n",
      "train loss:0.004044787528883274\n",
      "train loss:0.011537145638290518\n",
      "train loss:0.0016715872689645355\n",
      "train loss:0.0004388022705378503\n",
      "train loss:0.06136650665749256\n",
      "train loss:0.0024245269097308893\n",
      "train loss:0.05816379245527454\n",
      "train loss:0.003274481253717321\n",
      "train loss:0.015722516558707256\n",
      "train loss:0.005253311146272691\n",
      "train loss:0.002195728593512413\n",
      "train loss:0.004450809955233956\n",
      "train loss:0.015799851406974402\n",
      "train loss:0.01790730897348318\n",
      "train loss:0.023265054847954773\n",
      "train loss:0.03382581716983982\n",
      "train loss:0.007126580913485851\n",
      "train loss:0.011170971671278446\n",
      "train loss:0.0036914632108391555\n",
      "train loss:0.006322552297061801\n",
      "train loss:0.025877153582863816\n",
      "train loss:0.0043674211682933044\n",
      "train loss:0.006035110443381472\n",
      "train loss:0.0033145587578988916\n",
      "train loss:0.015553582690419438\n",
      "train loss:0.010256600790182282\n",
      "train loss:0.0010245756351093315\n",
      "train loss:0.006401195559514477\n",
      "train loss:0.004331026928776333\n",
      "train loss:0.006029319395377697\n",
      "train loss:0.03021878155247075\n",
      "train loss:0.037926873650843344\n",
      "train loss:0.0018175538417026427\n",
      "train loss:0.0021502444243753933\n",
      "train loss:0.002271572274968861\n",
      "train loss:0.011502497219236218\n",
      "train loss:0.010632899553885937\n",
      "train loss:0.00933533059900773\n",
      "train loss:0.029888042850882753\n",
      "train loss:0.019928175358349655\n",
      "train loss:0.013866021075099304\n",
      "train loss:0.005739573212849517\n",
      "train loss:0.008960434365904105\n",
      "train loss:0.0004282368506664499\n",
      "train loss:0.007105744502251937\n",
      "train loss:0.0009903761749637606\n",
      "train loss:0.004875847303836471\n",
      "train loss:0.01354090148317032\n",
      "train loss:0.0007346787862259653\n",
      "train loss:0.008890697010984942\n",
      "train loss:0.002965097926303087\n",
      "train loss:0.0008932040734208998\n",
      "train loss:0.00346171737524812\n",
      "train loss:0.0066406810825201034\n",
      "train loss:0.016987569022992838\n",
      "train loss:0.00587366050574921\n",
      "train loss:0.002904764335487387\n",
      "train loss:0.0027562235370100175\n",
      "train loss:0.00913500989615333\n",
      "train loss:0.002783372170026524\n",
      "train loss:0.009104971731309981\n",
      "train loss:0.0029761082125386007\n",
      "train loss:0.003553421027607855\n",
      "train loss:0.005627039421768739\n",
      "train loss:0.007521545291986672\n",
      "train loss:0.006010198912335975\n",
      "train loss:0.0020443380438680938\n",
      "train loss:0.003675074929055169\n",
      "train loss:0.0030708014230059733\n",
      "train loss:0.008908224740403117\n",
      "train loss:0.021979305563977473\n",
      "train loss:0.008363671847142071\n",
      "train loss:0.004872376172755405\n",
      "train loss:0.0035440987926972033\n",
      "train loss:0.0026162689998540656\n",
      "train loss:0.006470956993350353\n",
      "train loss:0.002359235019121013\n",
      "train loss:0.0052850787453324185\n",
      "train loss:0.008104754267541075\n",
      "train loss:0.0017282833076481886\n",
      "train loss:0.0005136282086820196\n",
      "train loss:0.05027885214920676\n",
      "train loss:0.02269277151334495\n",
      "train loss:0.00334028519789767\n",
      "train loss:0.003999925586170892\n",
      "train loss:0.0021137134166411297\n",
      "train loss:0.006973799527625053\n",
      "train loss:0.008334782254507088\n",
      "train loss:0.008940316863586203\n",
      "train loss:0.0017675792876394555\n",
      "train loss:0.03006993357121983\n",
      "train loss:0.00436653035257412\n",
      "train loss:0.0010353567474275071\n",
      "train loss:0.008941861067276763\n",
      "train loss:0.002618483616405183\n",
      "train loss:0.003325854167242645\n",
      "train loss:0.00909133287736142\n",
      "train loss:0.0022836982625116346\n",
      "train loss:0.017168294094632424\n",
      "train loss:0.005144487244032703\n",
      "train loss:0.0031115487107691133\n",
      "train loss:0.0037159321770996274\n",
      "train loss:0.00916102927978849\n",
      "train loss:0.005211664114822668\n",
      "train loss:0.01432310585693061\n",
      "train loss:0.07943457167172378\n",
      "train loss:0.011595957419826606\n",
      "train loss:0.009195482970864947\n",
      "train loss:0.008829908063343262\n",
      "train loss:0.07507187468296575\n",
      "train loss:0.0034190120323434052\n",
      "train loss:0.014218433297086362\n",
      "train loss:0.007266685358571169\n",
      "train loss:0.018240308847970045\n",
      "train loss:0.0037707297640518157\n",
      "train loss:0.00984309373538889\n",
      "train loss:0.008146169304566629\n",
      "train loss:0.03500440989649585\n",
      "train loss:0.0019087482738229552\n",
      "train loss:0.0021269146633101023\n",
      "train loss:0.008368778559369865\n",
      "train loss:0.001347413078646159\n",
      "train loss:0.004027607196709942\n",
      "train loss:0.0014503279455870502\n",
      "train loss:0.020348293422892648\n",
      "train loss:0.006118957796205796\n",
      "train loss:0.017614640166307247\n",
      "train loss:0.00601100460553355\n",
      "train loss:0.005597572968356721\n",
      "train loss:0.004095001944067386\n",
      "train loss:0.0024369481076593883\n",
      "train loss:0.01673245919230312\n",
      "train loss:0.0011086004313704205\n",
      "train loss:0.016186428261426963\n",
      "train loss:0.029642933089706214\n",
      "train loss:0.005174867658059028\n",
      "train loss:0.010785186447463051\n",
      "train loss:0.013758748675990522\n",
      "train loss:0.010233788504736264\n",
      "train loss:0.03887737392553231\n",
      "train loss:0.007000551125733386\n",
      "train loss:0.030984447303201677\n",
      "train loss:0.007608445955628902\n",
      "train loss:0.0017466801528539205\n",
      "train loss:0.004507273592873747\n",
      "train loss:0.0006881231085254305\n",
      "train loss:0.0017501854500756857\n",
      "train loss:0.01102310853285493\n",
      "train loss:0.017669666233741773\n",
      "train loss:0.008899919896040118\n",
      "train loss:0.003956923329395537\n",
      "train loss:0.004705614253401643\n",
      "train loss:0.004176935714018641\n",
      "train loss:0.0023320836106105252\n",
      "train loss:0.001999060730924848\n",
      "train loss:0.009091319146695323\n",
      "train loss:0.0027721976103808293\n",
      "train loss:0.005588268200909644\n",
      "train loss:0.005055696254258804\n",
      "train loss:0.003937774132068504\n",
      "train loss:0.006327705064252539\n",
      "train loss:0.03707216117818322\n",
      "train loss:0.014570937208594458\n",
      "train loss:0.028358330170302936\n",
      "train loss:0.02374259873103854\n",
      "train loss:0.002564357493691236\n",
      "train loss:0.0016794405187026645\n",
      "train loss:0.001167634936144165\n",
      "train loss:0.0012316871029422923\n",
      "train loss:0.005407440711121176\n",
      "train loss:0.0005045648190860545\n",
      "train loss:0.009543629354979207\n",
      "train loss:0.09932841304783463\n",
      "train loss:0.007393908352312354\n",
      "train loss:0.0075394747772104835\n",
      "train loss:0.008805976107877202\n",
      "train loss:0.012890559911379815\n",
      "train loss:0.003814949677929007\n",
      "train loss:0.007126880014644844\n",
      "train loss:0.008113713468365695\n",
      "train loss:0.0071611308107983555\n",
      "train loss:0.052444946026156895\n",
      "train loss:0.027441958687306093\n",
      "train loss:0.004066037404920486\n",
      "train loss:0.012580079941116795\n",
      "train loss:0.0033633654242381877\n",
      "train loss:0.0016640154934660304\n",
      "train loss:0.0017843295072799263\n",
      "train loss:0.002158612709926986\n",
      "train loss:0.04611648207423295\n",
      "train loss:0.007504764177174418\n",
      "train loss:0.0012557780899126437\n",
      "train loss:0.006069243984641328\n",
      "train loss:0.005064619146391248\n",
      "train loss:0.01551388527923678\n",
      "train loss:0.005405175829034953\n",
      "train loss:0.005461839971568908\n",
      "train loss:0.004257767057037106\n",
      "train loss:0.017310382814022376\n",
      "train loss:0.003631985302710248\n",
      "train loss:0.004495695985281154\n",
      "train loss:0.04452650564282822\n",
      "train loss:0.010475127997855145\n",
      "train loss:0.001405430650110208\n",
      "train loss:0.0134619955930248\n",
      "train loss:0.010229265102415855\n",
      "train loss:0.0016741613985453594\n",
      "train loss:0.0028382959910583385\n",
      "train loss:0.006341495114211162\n",
      "train loss:0.018789450077295256\n",
      "train loss:0.011530782649722349\n",
      "train loss:0.015082331244588527\n",
      "train loss:0.00017511663282252733\n",
      "train loss:0.009207017597943406\n",
      "train loss:0.0011692595112659215\n",
      "train loss:0.005870528055658869\n",
      "train loss:0.003685738218348808\n",
      "train loss:0.0021631311869315744\n",
      "train loss:0.0018108339012571036\n",
      "train loss:0.0042911149310269295\n",
      "train loss:0.008492466318822249\n",
      "train loss:0.00468656789316893\n",
      "train loss:0.09618981524850304\n",
      "train loss:0.002233909839848497\n",
      "train loss:0.00580176618936242\n",
      "train loss:0.023143963739449044\n",
      "train loss:0.004594677395480874\n",
      "train loss:0.007560097601081275\n",
      "train loss:0.010727604253823636\n",
      "train loss:0.053521142107488456\n",
      "train loss:0.012963217103703063\n",
      "train loss:0.004136629025340644\n",
      "train loss:0.002950740231598614\n",
      "train loss:0.013931256232567493\n",
      "train loss:0.006157730314781349\n",
      "train loss:0.007595565483037734\n",
      "train loss:0.001879531643023428\n",
      "train loss:0.035010720249602605\n",
      "train loss:0.004181829984149368\n",
      "train loss:0.03016103518636456\n",
      "train loss:0.00623393918968519\n",
      "train loss:0.0033323526375311986\n",
      "train loss:0.006240439779664146\n",
      "train loss:0.01018342996680495\n",
      "train loss:0.004034728952804614\n",
      "train loss:0.007070018085882391\n",
      "train loss:0.009878404281427422\n",
      "train loss:0.026402648157395722\n",
      "train loss:0.001106299972749916\n",
      "train loss:0.01906295360060993\n",
      "train loss:0.004666757259866903\n",
      "train loss:0.017139191640808453\n",
      "train loss:0.014268931053062928\n",
      "train loss:0.004698229825640545\n",
      "train loss:0.0038032085953625394\n",
      "train loss:0.001617488594208059\n",
      "train loss:0.0017226324802083112\n",
      "train loss:0.00041929089349092557\n",
      "train loss:0.0024971719972309153\n",
      "train loss:0.00114739506949891\n",
      "train loss:0.005182374447587631\n",
      "train loss:0.0016668784158009194\n",
      "train loss:0.011778727777853347\n",
      "train loss:0.009152109040846138\n",
      "train loss:0.007683919321087268\n",
      "train loss:0.033403282442964116\n",
      "train loss:0.01129448286871234\n",
      "train loss:0.007148302023303044\n",
      "train loss:0.0021965726157945928\n",
      "train loss:0.03271278815970021\n",
      "train loss:0.0026143560790967513\n",
      "train loss:0.028379659373868975\n",
      "train loss:0.002522387695497918\n",
      "train loss:0.004767570253998183\n",
      "train loss:0.0026566299992914393\n",
      "train loss:0.001071633232585662\n",
      "train loss:0.004787289942760581\n",
      "train loss:0.0428092365266596\n",
      "train loss:0.026308852368659492\n",
      "train loss:0.0033645850247819064\n",
      "train loss:0.004479617448803733\n",
      "train loss:0.01222397322722738\n",
      "train loss:0.007373987310884396\n",
      "train loss:0.002427535413596326\n",
      "train loss:0.0035275432160954048\n",
      "train loss:0.008291255299248509\n",
      "train loss:0.004854991629754777\n",
      "train loss:0.0011800877299456413\n",
      "train loss:0.01252236899239819\n",
      "train loss:0.013316271915631863\n",
      "train loss:0.0007290929554850508\n",
      "train loss:0.009941600334295288\n",
      "train loss:0.01300402890699827\n",
      "train loss:0.0018668930756303222\n",
      "train loss:0.03503564913304432\n",
      "train loss:0.009395506372517353\n",
      "train loss:0.010658965944869753\n",
      "train loss:0.0023535304770696945\n",
      "train loss:0.0020284449680906865\n",
      "train loss:0.0017438689179863382\n",
      "train loss:0.01549587036707184\n",
      "train loss:0.010091361258467824\n",
      "train loss:0.0009548982949541085\n",
      "train loss:0.0052741035329983\n",
      "train loss:0.012158214588616722\n",
      "train loss:0.02172998495039531\n",
      "train loss:0.006199068968881984\n",
      "train loss:0.0023352561958332315\n",
      "train loss:0.007785987059842408\n",
      "train loss:0.006236796139269724\n",
      "train loss:0.004436514986713042\n",
      "train loss:0.0029596432156356444\n",
      "train loss:0.01270794518818486\n",
      "train loss:0.0054455139143458516\n",
      "train loss:0.004971311611892183\n",
      "train loss:0.017115998957383912\n",
      "train loss:0.00806053732791198\n",
      "train loss:0.0052869298895051355\n",
      "train loss:0.0008420580151847048\n",
      "train loss:0.002673014935237771\n",
      "train loss:0.0015820864061580422\n",
      "train loss:0.002772317131944521\n",
      "train loss:0.009472054103089593\n",
      "train loss:0.008280236841768018\n",
      "train loss:0.0029804926749107123\n",
      "train loss:0.0018398426095677931\n",
      "train loss:0.007585099210978149\n",
      "train loss:0.017499762531327283\n",
      "train loss:0.0049632998033264765\n",
      "train loss:0.007896848244763176\n",
      "train loss:0.003427167947538703\n",
      "train loss:0.0041436264359505145\n",
      "train loss:0.005411435968611278\n",
      "train loss:0.0003365501986546141\n",
      "train loss:0.014074021389629819\n",
      "train loss:0.003294083803197839\n",
      "train loss:0.022697001625113268\n",
      "train loss:0.0021462414945100177\n",
      "train loss:0.0020000695079601606\n",
      "train loss:0.00922646809777414\n",
      "train loss:0.0072092077055843275\n",
      "train loss:0.008737877622677444\n",
      "train loss:0.013478142628637314\n",
      "train loss:0.003471509622199135\n",
      "train loss:0.0017857383586648485\n",
      "train loss:0.07988796834178412\n",
      "train loss:0.002358604294792505\n",
      "train loss:0.0037047531216416046\n",
      "train loss:0.018894382866824606\n",
      "train loss:0.009549200274706201\n",
      "train loss:0.005054642599940249\n",
      "train loss:0.001195168021961151\n",
      "train loss:0.00713690257906239\n",
      "train loss:0.012510363419717509\n",
      "train loss:0.02028398804635214\n",
      "train loss:0.0024411265112098107\n",
      "train loss:0.0025650178466724237\n",
      "train loss:0.006984712364837203\n",
      "train loss:0.014966942812674612\n",
      "train loss:0.008023917041355558\n",
      "train loss:0.00752645387950236\n",
      "train loss:0.023956679420403793\n",
      "train loss:0.004299941203209877\n",
      "train loss:0.0035200546141986476\n",
      "train loss:0.0035114432561595306\n",
      "train loss:0.006853181847348839\n",
      "train loss:0.0095058303656759\n",
      "train loss:0.005255098256285115\n",
      "train loss:0.0040286199163435945\n",
      "train loss:0.0043370448145811594\n",
      "train loss:0.005024150142613013\n",
      "train loss:0.003589300834682961\n",
      "train loss:0.005371599347535477\n",
      "train loss:0.002837437631124887\n",
      "train loss:0.00449429817465212\n",
      "train loss:0.010001404522681527\n",
      "train loss:0.0024586878887524095\n",
      "train loss:0.01028002692114307\n",
      "train loss:0.026091255188031782\n",
      "train loss:0.008354639129357792\n",
      "train loss:0.008798861795673104\n",
      "train loss:0.025168080123875648\n",
      "train loss:0.007302057952895383\n",
      "train loss:0.00279641207834864\n",
      "train loss:0.002597043359533224\n",
      "train loss:0.007752965152762142\n",
      "train loss:0.0013869312088306501\n",
      "train loss:0.005456582916357811\n",
      "train loss:0.026897871816014347\n",
      "train loss:0.002055265138842849\n",
      "train loss:0.0015769326928691955\n",
      "train loss:0.0028910273964122095\n",
      "train loss:0.0006725676282972996\n",
      "train loss:0.017304336357944688\n",
      "train loss:0.0062795642754656985\n",
      "train loss:0.0019502417258163924\n",
      "train loss:0.0012240391408027066\n",
      "train loss:0.002170457663025109\n",
      "train loss:0.00962544390715273\n",
      "train loss:0.002812724807192183\n",
      "train loss:0.0017692192793347186\n",
      "train loss:0.008553259337719858\n",
      "train loss:0.00483657115884831\n",
      "train loss:0.049914446930428784\n",
      "train loss:0.0007551580780234969\n",
      "train loss:0.011999779069430753\n",
      "train loss:0.013088598819171847\n",
      "train loss:0.006038104070982683\n",
      "train loss:0.007683750663650626\n",
      "train loss:0.009670867777776489\n",
      "train loss:0.002292462048419378\n",
      "train loss:0.0016480299603887582\n",
      "train loss:0.0202658335729244\n",
      "train loss:0.0058795733628822225\n",
      "train loss:0.0038184918243559366\n",
      "train loss:0.004283849823837624\n",
      "train loss:0.011931204599233278\n",
      "train loss:0.0019145383735646232\n",
      "train loss:0.005198442528876932\n",
      "train loss:0.0012270340797252827\n",
      "train loss:0.0025591684212321214\n",
      "train loss:0.001645829747761847\n",
      "train loss:0.008050225779561484\n",
      "train loss:0.0031198256054372725\n",
      "train loss:0.0014039853055034235\n",
      "train loss:0.009948329504949513\n",
      "train loss:0.001964600236209478\n",
      "train loss:0.007267267454918857\n",
      "train loss:0.006817224345053721\n",
      "train loss:0.0003260433565981368\n",
      "train loss:0.02216883420724964\n",
      "train loss:0.006850307126076656\n",
      "train loss:0.004017491623854273\n",
      "train loss:0.007194178363138892\n",
      "train loss:0.010355152390084076\n",
      "train loss:0.002066487961230655\n",
      "train loss:0.0006751739862989448\n",
      "train loss:0.005511278436277083\n",
      "train loss:0.010076493681409221\n",
      "train loss:0.044435450632950964\n",
      "train loss:0.0028179998239128783\n",
      "train loss:0.00309664885327598\n",
      "train loss:0.004938639998328233\n",
      "train loss:0.010980637684892878\n",
      "train loss:0.00043800523860984883\n",
      "train loss:0.009841582385584205\n",
      "train loss:0.002217666766794145\n",
      "train loss:0.006038225331576319\n",
      "train loss:0.014617183385714501\n",
      "train loss:0.08445320137231997\n",
      "train loss:0.002507108369838881\n",
      "train loss:0.03699429665465937\n",
      "train loss:0.007000504571506929\n",
      "train loss:0.0048401906402785995\n",
      "train loss:0.025452662398056946\n",
      "train loss:0.005029199954200626\n",
      "train loss:0.020562871581578414\n",
      "train loss:0.0007669329888041108\n",
      "train loss:0.01829837622420251\n",
      "train loss:0.0028650202486553257\n",
      "train loss:0.00572435514061704\n",
      "train loss:0.003929960892101767\n",
      "train loss:0.017443725347406673\n",
      "train loss:0.002187558937761166\n",
      "train loss:0.0026687591698939727\n",
      "train loss:0.0016643940100761958\n",
      "train loss:0.006055990141900241\n",
      "train loss:0.02067117618010266\n",
      "train loss:0.031811739052418235\n",
      "train loss:0.0004178897168427106\n",
      "train loss:0.006314354101764957\n",
      "train loss:0.0031595225468380376\n",
      "train loss:0.0056103135764419085\n",
      "train loss:0.003422423478054405\n",
      "train loss:0.007947955549227175\n",
      "train loss:0.007035594189934605\n",
      "train loss:0.050826769830026874\n",
      "train loss:0.0034173619530106884\n",
      "train loss:0.005837876959020644\n",
      "train loss:0.000972665259321533\n",
      "train loss:0.012433149913025491\n",
      "train loss:0.03183701351378469\n",
      "train loss:0.02218867277161943\n",
      "train loss:0.018473165709109993\n",
      "train loss:0.03652372584402864\n",
      "train loss:0.0018967611860636897\n",
      "train loss:0.016471774735968704\n",
      "train loss:0.011281969122679003\n",
      "train loss:0.015801070157317253\n",
      "train loss:0.008575981452390082\n",
      "train loss:0.0035799058571134956\n",
      "train loss:0.002061864977731573\n",
      "train loss:0.010596019457917985\n",
      "train loss:0.01953115217561674\n",
      "train loss:0.04223395677063753\n",
      "train loss:0.0035347596590235147\n",
      "train loss:0.004011867983184828\n",
      "train loss:0.002336546277581816\n",
      "train loss:0.012240116933358696\n",
      "train loss:0.005063328556477731\n",
      "train loss:0.04764614079105473\n",
      "train loss:0.02291901541148725\n",
      "train loss:0.010290407553916813\n",
      "train loss:0.0016297207679107023\n",
      "train loss:0.0010369723825673026\n",
      "train loss:0.002848283809000064\n",
      "train loss:0.011896303207004516\n",
      "train loss:0.006275028333846193\n",
      "train loss:0.021417945280524098\n",
      "train loss:0.0049199973896704345\n",
      "train loss:0.008480473221525474\n",
      "train loss:0.014668444787508868\n",
      "train loss:0.011808041522241311\n",
      "train loss:0.001779054311643294\n",
      "train loss:0.0037309820420714417\n",
      "train loss:0.005281034556685299\n",
      "train loss:0.008162132694425405\n",
      "train loss:0.008267122172531994\n",
      "train loss:0.003547387966031333\n",
      "train loss:0.006420479246340875\n",
      "train loss:0.010304043150750649\n",
      "train loss:0.0035449242919809447\n",
      "train loss:0.0018194118109693936\n",
      "train loss:0.0028567625358388586\n",
      "train loss:0.006564522977313319\n",
      "train loss:0.019004361345165255\n",
      "train loss:0.010687637435349277\n",
      "train loss:0.010709456608216516\n",
      "train loss:0.02400118697010581\n",
      "train loss:0.007863382709852752\n",
      "train loss:0.0018143574641953943\n",
      "=== epoch:10, train acc:0.995, test acc:0.991 ===\n",
      "train loss:0.0017013636578750086\n",
      "train loss:0.002158106303730647\n",
      "train loss:0.0019768889674507462\n",
      "train loss:0.010160149306886112\n",
      "train loss:0.004632087767674957\n",
      "train loss:0.011330515251035685\n",
      "train loss:0.004367241986594903\n",
      "train loss:0.008964986478291293\n",
      "train loss:0.009148673249607468\n",
      "train loss:0.0032020733466966915\n",
      "train loss:0.019419306618036716\n",
      "train loss:0.0034832765755636458\n",
      "train loss:0.0010300827644083835\n",
      "train loss:0.010758620783402948\n",
      "train loss:0.0009876006881027537\n",
      "train loss:0.004054279074318541\n",
      "train loss:0.00380726388451093\n",
      "train loss:0.009558280634522074\n",
      "train loss:0.004965144904278922\n",
      "train loss:0.03761846016341515\n",
      "train loss:0.013798377728607846\n",
      "train loss:0.0058744261566542715\n",
      "train loss:0.0032780854314388057\n",
      "train loss:0.004791579136974487\n",
      "train loss:0.0019773600528615997\n",
      "train loss:0.004787289947178145\n",
      "train loss:0.0036046606159246823\n",
      "train loss:0.0033237899989638636\n",
      "train loss:0.015920267659660866\n",
      "train loss:0.00520064779496773\n",
      "train loss:0.002788353147437138\n",
      "train loss:0.003073231560631584\n",
      "train loss:0.021798823883843226\n",
      "train loss:0.001881697713023856\n",
      "train loss:0.0010330551781009216\n",
      "train loss:0.002557336179491229\n",
      "train loss:0.003408791365754692\n",
      "train loss:0.0023817136114080125\n",
      "train loss:0.00700313965917645\n",
      "train loss:0.005568398313682896\n",
      "train loss:0.019982214017674083\n",
      "train loss:0.0020321082120079307\n",
      "train loss:0.03143855305303793\n",
      "train loss:0.022443135566399812\n",
      "train loss:0.010033159081596965\n",
      "train loss:0.01276960479752331\n",
      "train loss:0.012449949046424942\n",
      "train loss:0.02531597212044696\n",
      "train loss:0.0013372835902819358\n",
      "train loss:0.008548821956436603\n",
      "train loss:0.007450393379791203\n",
      "train loss:0.0007424908425713776\n",
      "train loss:0.003252330172643797\n",
      "train loss:0.019348713574803923\n",
      "train loss:0.011376699328369372\n",
      "train loss:0.005337726422002916\n",
      "train loss:0.0051500720606540385\n",
      "train loss:0.0047150591090947816\n",
      "train loss:0.004531361414525082\n",
      "train loss:0.004755292647635408\n",
      "train loss:0.0009140280221329815\n",
      "train loss:0.002680640800812051\n",
      "train loss:0.011686701618298306\n",
      "train loss:0.007276618724691862\n",
      "train loss:0.029891585109593336\n",
      "train loss:0.003313378822594044\n",
      "train loss:0.0039045082890024414\n",
      "train loss:0.0011859141049282496\n",
      "train loss:0.004036185149971484\n",
      "train loss:0.001619007536754809\n",
      "train loss:0.004834745808625819\n",
      "train loss:0.01142947243879851\n",
      "train loss:0.00881373451794479\n",
      "train loss:0.002008314205205505\n",
      "train loss:0.0032370237382334105\n",
      "train loss:0.012806876743334061\n",
      "train loss:0.0035195984471942067\n",
      "train loss:0.0045225013125092285\n",
      "train loss:0.0022802970410565784\n",
      "train loss:0.008701921294340107\n",
      "train loss:0.00748343104995236\n",
      "train loss:0.004050754364581297\n",
      "train loss:0.005621849486157721\n",
      "train loss:0.0016749111973186903\n",
      "train loss:0.011255925080069028\n",
      "train loss:0.003098531250164426\n",
      "train loss:0.0184320679031772\n",
      "train loss:0.011485966811051785\n",
      "train loss:0.015196303261105059\n",
      "train loss:0.002786105704526458\n",
      "train loss:0.009662259042445337\n",
      "train loss:0.007167866252475967\n",
      "train loss:0.023351673093836248\n",
      "train loss:0.006180883249352887\n",
      "train loss:0.0034930348671823415\n",
      "train loss:0.0032103875514589157\n",
      "train loss:0.022881847326464252\n",
      "train loss:0.00525137772981442\n",
      "train loss:0.009596007016421963\n",
      "train loss:0.0038739009472404324\n",
      "train loss:0.0007031771866776941\n",
      "train loss:0.00036315905559777204\n",
      "train loss:0.004304745467120965\n",
      "train loss:0.010926673747360099\n",
      "train loss:0.01629655409373289\n",
      "train loss:0.010233861815257381\n",
      "train loss:0.0019874787562606184\n",
      "train loss:0.010472743415892905\n",
      "train loss:0.004154687576513643\n",
      "train loss:0.0028742302412689347\n",
      "train loss:0.0014434247592544332\n",
      "train loss:0.00965235444517406\n",
      "train loss:0.001643601714167206\n",
      "train loss:0.007554063939293937\n",
      "train loss:0.010700705395065813\n",
      "train loss:0.00582297934693574\n",
      "train loss:0.04161866479739141\n",
      "train loss:0.00499538172928246\n",
      "train loss:0.0006372714257515069\n",
      "train loss:0.0026252544746050432\n",
      "train loss:0.019622867067115014\n",
      "train loss:0.0017740247232050958\n",
      "train loss:0.00245326910939451\n",
      "train loss:0.0051762493541485976\n",
      "train loss:0.008365753477164452\n",
      "train loss:0.0026060846909578776\n",
      "train loss:0.002476774579022391\n",
      "train loss:0.0030722881841287603\n",
      "train loss:0.003908383968349738\n",
      "train loss:0.02841805138002588\n",
      "train loss:0.011289227287638069\n",
      "train loss:0.0016299286780114919\n",
      "train loss:0.020262157988097114\n",
      "train loss:0.019971787186343418\n",
      "train loss:0.007884298422420683\n",
      "train loss:0.002950407463470432\n",
      "train loss:0.003380743393611889\n",
      "train loss:0.0022303700074492653\n",
      "train loss:0.0011452822314185\n",
      "train loss:0.0030547101799947574\n",
      "train loss:0.0006315729509378345\n",
      "train loss:0.00036675367832122996\n",
      "train loss:0.007356101811371988\n",
      "train loss:0.021143189145402676\n",
      "train loss:0.0007405930184645828\n",
      "train loss:0.0005388611501340162\n",
      "train loss:0.0009663339220168496\n",
      "train loss:0.0006687851711044193\n",
      "train loss:0.003659706715873664\n",
      "train loss:0.0031536790910467287\n",
      "train loss:0.0035568011284578763\n",
      "train loss:0.0052526639099991935\n",
      "train loss:0.006803001537080464\n",
      "train loss:0.0025397960434712275\n",
      "train loss:0.0018704858467268421\n",
      "train loss:0.005226399329560118\n",
      "train loss:0.003120306366695548\n",
      "train loss:0.0010981061163846052\n",
      "train loss:0.0016106615058327789\n",
      "train loss:0.004188862912099156\n",
      "train loss:0.03989592257338997\n",
      "train loss:0.001754025782910926\n",
      "train loss:0.00466018191005796\n",
      "train loss:0.0005627500809550403\n",
      "train loss:0.0029193656216681073\n",
      "train loss:0.00421817300978739\n",
      "train loss:0.0011559186590810754\n",
      "train loss:0.0030604841852990825\n",
      "train loss:0.001149678596230495\n",
      "train loss:0.01901618927155402\n",
      "train loss:0.000980183810286988\n",
      "train loss:0.006218109098519381\n",
      "train loss:0.002670457729795222\n",
      "train loss:0.0004904937028449757\n",
      "train loss:0.0033230207317014797\n",
      "train loss:0.0012050188172896274\n",
      "train loss:0.0034959045217653213\n",
      "train loss:0.0024398594292962955\n",
      "train loss:0.0009775291949813227\n",
      "train loss:0.01508839425224781\n",
      "train loss:0.00501256027774312\n",
      "train loss:0.003863472096803301\n",
      "train loss:0.0006007048964845544\n",
      "train loss:0.0015908957470358639\n",
      "train loss:0.0022275274880468572\n",
      "train loss:0.00237167881292501\n",
      "train loss:0.0010476439096074456\n",
      "train loss:0.002245002736140653\n",
      "train loss:0.0018373425245215265\n",
      "train loss:0.0036550253215163063\n",
      "train loss:0.006956611878231371\n",
      "train loss:0.0026030337753832566\n",
      "train loss:0.004833962474289036\n",
      "train loss:0.010716642945160471\n",
      "train loss:0.0031127531812105104\n",
      "train loss:0.006039689031487144\n",
      "train loss:0.0014643407243542577\n",
      "train loss:0.0038782269393925865\n",
      "train loss:0.0008085854053358925\n",
      "train loss:0.006147614221067378\n",
      "train loss:0.0012095743613418203\n",
      "train loss:0.003049004546852526\n",
      "train loss:0.005948696631158724\n",
      "train loss:0.006042771204261658\n",
      "train loss:0.00030917612025274053\n",
      "train loss:0.0038742927631796997\n",
      "train loss:0.008262041579414577\n",
      "train loss:0.00195205456654846\n",
      "train loss:0.01291450561763099\n",
      "train loss:0.0015069589896152854\n",
      "train loss:0.00041290651745464363\n",
      "train loss:0.00157566935853077\n",
      "train loss:0.01213090406323065\n",
      "train loss:0.0035680825515615306\n",
      "train loss:0.0013935283833877163\n",
      "train loss:0.0017594834447146371\n",
      "train loss:0.0007174491861486807\n",
      "train loss:0.023000383636866153\n",
      "train loss:0.0012980567928471169\n",
      "train loss:0.0055141340043350804\n",
      "train loss:0.011210451796846162\n",
      "train loss:0.0268370042184108\n",
      "train loss:0.016599042928009497\n",
      "train loss:0.0035982437964151644\n",
      "train loss:0.029209905341618814\n",
      "train loss:0.010295215234418122\n",
      "train loss:0.000496687931977735\n",
      "train loss:0.006746763995511415\n",
      "train loss:0.015721596825048093\n",
      "train loss:0.004358124488467707\n",
      "train loss:0.013107901742042995\n",
      "train loss:0.00853308262158792\n",
      "train loss:0.0007676148648024166\n",
      "train loss:0.002214519389343754\n",
      "train loss:0.004723247597468304\n",
      "train loss:0.0007269230791180709\n",
      "train loss:0.002972902824521274\n",
      "train loss:0.004954290649479825\n",
      "train loss:0.03946583175881265\n",
      "train loss:0.0010923825758569134\n",
      "train loss:0.0020304669424038102\n",
      "train loss:0.0016158685337478579\n",
      "train loss:0.0034342589952380065\n",
      "train loss:0.0027073019418712234\n",
      "train loss:0.007829865890821595\n",
      "train loss:0.000885693685612734\n",
      "train loss:0.011381584537524431\n",
      "train loss:0.0002832550969637073\n",
      "train loss:0.001996400976422542\n",
      "train loss:0.0010212529198262885\n",
      "train loss:0.015405764733682506\n",
      "train loss:0.004186008329989196\n",
      "train loss:0.010282121762914256\n",
      "train loss:0.0029803817277381933\n",
      "train loss:0.0017939116647060392\n",
      "train loss:0.005361613927147394\n",
      "train loss:0.0010483626457938552\n",
      "train loss:0.0010483244169477322\n",
      "train loss:0.018620083786455154\n",
      "train loss:0.004170383484276746\n",
      "train loss:0.0018628578547738785\n",
      "train loss:0.004242288056373472\n",
      "train loss:0.0041068499911910365\n",
      "train loss:0.006348924590012192\n",
      "train loss:0.005995298650965312\n",
      "train loss:0.002995336948996062\n",
      "train loss:0.004725437124661866\n",
      "train loss:0.005640746132465051\n",
      "train loss:0.0013792602755416093\n",
      "train loss:0.0018257242660595677\n",
      "train loss:0.010794481614152805\n",
      "train loss:0.006128878314518102\n",
      "train loss:0.004737388852415213\n",
      "train loss:0.00125335612395648\n",
      "train loss:0.0029649791193225345\n",
      "train loss:0.00488738009767169\n",
      "train loss:0.009746506135652741\n",
      "train loss:0.0034578775122269963\n",
      "train loss:0.00900590260993751\n",
      "train loss:0.0038288697106833654\n",
      "train loss:0.002351323828672565\n",
      "train loss:0.004030519976009251\n",
      "train loss:0.003887668646971826\n",
      "train loss:0.0037872358790335616\n",
      "train loss:0.00029660648962043424\n",
      "train loss:0.0053377361332607245\n",
      "train loss:0.024320897430613317\n",
      "train loss:0.008355306346758355\n",
      "train loss:0.009626541628395541\n",
      "train loss:0.008318031771086545\n",
      "train loss:0.0026679495677799266\n",
      "train loss:0.009502463877932334\n",
      "train loss:0.01033661226467644\n",
      "train loss:0.010307189431930687\n",
      "train loss:0.009577481702717978\n",
      "train loss:0.0032697077959483694\n",
      "train loss:0.0021488057845778117\n",
      "train loss:0.003548737651960892\n",
      "train loss:0.0014405381590241115\n",
      "train loss:0.003375282270809614\n",
      "train loss:0.019525819504479593\n",
      "train loss:0.043231787695442725\n",
      "train loss:0.004708190826377414\n",
      "train loss:0.0028667899699454874\n",
      "train loss:0.009366822188558402\n",
      "train loss:0.011110709256787279\n",
      "train loss:0.0017931123036598222\n",
      "train loss:0.008030889716830702\n",
      "train loss:0.0019910756368041196\n",
      "train loss:0.003752605360499853\n",
      "train loss:0.02164168222396886\n",
      "train loss:0.006937029465598522\n",
      "train loss:0.0009268056665084302\n",
      "train loss:0.000302582846220681\n",
      "train loss:0.0017691845022800687\n",
      "train loss:0.0030719238325552884\n",
      "train loss:0.008231467640071185\n",
      "train loss:0.00826019831304709\n",
      "train loss:0.006544685398775429\n",
      "train loss:0.0010030104969519613\n",
      "train loss:0.00564774110407067\n",
      "train loss:0.01358250214347465\n",
      "train loss:0.006820739822682768\n",
      "train loss:0.0050290484679829635\n",
      "train loss:0.0037463078608669553\n",
      "train loss:0.0012882744550977829\n",
      "train loss:0.0017653780552684822\n",
      "train loss:0.007008158389587428\n",
      "train loss:0.03416011295698208\n",
      "train loss:0.006671689418599742\n",
      "train loss:0.0013480580106431034\n",
      "train loss:0.0027110685416745894\n",
      "train loss:0.0002133492809818646\n",
      "train loss:0.001658869915900437\n",
      "train loss:0.004753564936283894\n",
      "train loss:0.004903334297169506\n",
      "train loss:0.007011131984720334\n",
      "train loss:0.00453822827317758\n",
      "train loss:0.0071598181788162275\n",
      "train loss:0.0025629202855082457\n",
      "train loss:0.0015683634358613743\n",
      "train loss:0.0026564218944331347\n",
      "train loss:0.01861361076649695\n",
      "train loss:0.0008895691663341551\n",
      "train loss:0.0126980523723347\n",
      "train loss:0.004195415283664247\n",
      "train loss:0.003017111293004962\n",
      "train loss:0.002839414895799261\n",
      "train loss:0.026734795379857932\n",
      "train loss:0.004300656283190043\n",
      "train loss:0.0018281377441492607\n",
      "train loss:0.0025891872461669685\n",
      "train loss:0.002938309025268145\n",
      "train loss:0.0037802775161044203\n",
      "train loss:0.004999599253760329\n",
      "train loss:0.0016230314521896677\n",
      "train loss:0.0007036768599732205\n",
      "train loss:0.0035091576376606883\n",
      "train loss:0.0048380787569926136\n",
      "train loss:0.002571516489160883\n",
      "train loss:0.0007631031429470378\n",
      "train loss:0.00398681059479444\n",
      "train loss:0.0058533844143564915\n",
      "train loss:0.002159269727525304\n",
      "train loss:0.0009858301471205007\n",
      "train loss:0.01256613362712643\n",
      "train loss:0.00916143887915266\n",
      "train loss:0.0010116864710786508\n",
      "train loss:0.020469429979611112\n",
      "train loss:0.03097017517141781\n",
      "train loss:0.0035100799689664064\n",
      "train loss:0.003384646374968181\n",
      "train loss:0.00012603284971350365\n",
      "train loss:0.0002257550477470187\n",
      "train loss:0.004701935659900172\n",
      "train loss:0.0009935023158022715\n",
      "train loss:0.0006728205309462211\n",
      "train loss:0.0014002231374343915\n",
      "train loss:0.0006248394190103279\n",
      "train loss:0.000997636039392362\n",
      "train loss:0.00032098526347032865\n",
      "train loss:0.002979904325467515\n",
      "train loss:0.0010004081683871143\n",
      "train loss:0.0026114665581243378\n",
      "train loss:0.001422228845990886\n",
      "train loss:0.0009479112238094747\n",
      "train loss:0.0021016320291481526\n",
      "train loss:0.004362018014837388\n",
      "train loss:0.0008318158826753182\n",
      "train loss:0.0005806999258171214\n",
      "train loss:0.00618766138325669\n",
      "train loss:0.0017209775813567165\n",
      "train loss:0.0018124521767074735\n",
      "train loss:0.00304160874433547\n",
      "train loss:0.0010568582343030814\n",
      "train loss:0.0007341366005239669\n",
      "train loss:0.0031144945591153332\n",
      "train loss:0.004292378058021129\n",
      "train loss:0.0032476427995248008\n",
      "train loss:0.0010332267473854525\n",
      "train loss:0.001841581507102727\n",
      "train loss:0.0100472902206479\n",
      "train loss:0.0035815993974067616\n",
      "train loss:0.009263794772950534\n",
      "train loss:0.006956411823102547\n",
      "train loss:0.010140716276357178\n",
      "train loss:0.0012579652550570345\n",
      "train loss:0.010127138088421726\n",
      "train loss:0.0021303148712156494\n",
      "train loss:0.00014890923633854045\n",
      "train loss:0.0012020621511187508\n",
      "train loss:0.0033961297812886227\n",
      "train loss:0.005970701143572432\n",
      "train loss:0.006524026081321873\n",
      "train loss:0.009010990002460495\n",
      "train loss:0.006212648348490451\n",
      "train loss:0.0031074255238250537\n",
      "train loss:0.003194398035434326\n",
      "train loss:0.0024727809614490427\n",
      "train loss:0.024050655408228833\n",
      "train loss:0.015188745505375321\n",
      "train loss:0.0011907410726344314\n",
      "train loss:0.00036347055658799196\n",
      "train loss:0.013473676146517037\n",
      "train loss:0.002800005504954874\n",
      "train loss:0.001576352861794221\n",
      "train loss:0.005306401372098284\n",
      "train loss:0.006762801063679614\n",
      "train loss:0.07657660104851549\n",
      "train loss:0.0010254665327995118\n",
      "train loss:0.005653974547709434\n",
      "train loss:0.0020896606034608765\n",
      "train loss:0.016201830361464258\n",
      "train loss:0.002883458116784421\n",
      "train loss:0.0020770349640805695\n",
      "train loss:0.0035663942019717454\n",
      "train loss:0.009430872316493574\n",
      "train loss:0.002717573975175212\n",
      "train loss:0.0017624334317905145\n",
      "train loss:0.0020789259936476578\n",
      "train loss:0.010436372682107075\n",
      "train loss:0.0016102255719377043\n",
      "train loss:0.014548754941979578\n",
      "train loss:0.003189937447690073\n",
      "train loss:0.004227169531083602\n",
      "train loss:0.0024090840891126076\n",
      "train loss:0.005105823647924502\n",
      "train loss:0.005187925346726728\n",
      "train loss:0.006000036216563024\n",
      "train loss:0.0034235555467930817\n",
      "train loss:0.0009871269276561544\n",
      "train loss:0.011469182278868919\n",
      "train loss:0.005269857076036356\n",
      "train loss:0.0016981016301508942\n",
      "train loss:0.004183480501100691\n",
      "train loss:0.0042264372287085725\n",
      "train loss:0.0013196291446463681\n",
      "train loss:0.0026310096437795766\n",
      "train loss:0.0034094337611154995\n",
      "train loss:0.0022944858300037053\n",
      "train loss:0.00764166124621689\n",
      "train loss:0.004584116759216234\n",
      "train loss:0.002463080926152138\n",
      "train loss:0.0015557100351317652\n",
      "train loss:0.004806540968313444\n",
      "train loss:0.0013772226116899064\n",
      "train loss:0.0023921564307932503\n",
      "train loss:0.004406791772774143\n",
      "train loss:0.002240151529749353\n",
      "train loss:0.00036581100058543937\n",
      "train loss:0.011206284976014771\n",
      "train loss:0.008070146362002149\n",
      "train loss:0.003220343944500958\n",
      "train loss:0.002654725507268494\n",
      "train loss:0.0009088625652560892\n",
      "train loss:0.0061241341721429855\n",
      "train loss:0.0007308755755028381\n",
      "train loss:0.0019049514603668464\n",
      "train loss:0.0008037929956511623\n",
      "train loss:0.005485468543737892\n",
      "train loss:0.0018755213045608232\n",
      "train loss:0.0017561456778796012\n",
      "train loss:0.004695883788392049\n",
      "train loss:0.0013988901212486913\n",
      "train loss:0.00512776697021892\n",
      "train loss:0.0066642611065199295\n",
      "train loss:0.003699415548153199\n",
      "train loss:0.0067876526621894265\n",
      "train loss:0.0017472085855452862\n",
      "train loss:0.007044508866169307\n",
      "train loss:0.000871491911164157\n",
      "train loss:0.0022132409206458174\n",
      "train loss:0.0015366729605115373\n",
      "train loss:0.001111753398299007\n",
      "train loss:0.0030156370906873104\n",
      "train loss:0.0028142436441749162\n",
      "train loss:0.014326960379550857\n",
      "train loss:0.0004808844775648534\n",
      "train loss:0.003463488113228806\n",
      "train loss:0.005000204328630705\n",
      "train loss:0.0027329008875249857\n",
      "train loss:0.0006375863378137957\n",
      "train loss:0.000303019235222368\n",
      "train loss:0.0064762153270602\n",
      "train loss:0.003774931569624163\n",
      "train loss:0.00200541902348592\n",
      "train loss:0.003056284264293738\n",
      "train loss:0.007100916619586835\n",
      "train loss:0.0014844674995996127\n",
      "train loss:0.0006112270277584066\n",
      "train loss:0.0019252360277367119\n",
      "train loss:0.003744476925205468\n",
      "train loss:0.0033777313311763413\n",
      "train loss:0.0018282115878539681\n",
      "train loss:0.0017553986428587257\n",
      "train loss:0.0047391962427226\n",
      "train loss:0.001879437441577429\n",
      "train loss:0.02800632744450827\n",
      "train loss:0.0027187092833751646\n",
      "train loss:0.010089721915346904\n",
      "train loss:0.0029700169569866043\n",
      "train loss:0.0016443394799552237\n",
      "train loss:0.002218827675800495\n",
      "train loss:0.000692514935749432\n",
      "train loss:0.01781884870738674\n",
      "train loss:0.023679109905135415\n",
      "train loss:0.005628533600886345\n",
      "train loss:0.011523770569717475\n",
      "train loss:0.025671381416580222\n",
      "train loss:0.00413226735775053\n",
      "train loss:0.0020629824236629507\n",
      "train loss:0.004993877714227254\n",
      "train loss:0.007304678795794414\n",
      "train loss:0.0023409728158956438\n",
      "train loss:0.013985633883885176\n",
      "train loss:0.0015330737801878456\n",
      "train loss:0.0042642377105477055\n",
      "train loss:0.006022715793560653\n",
      "train loss:0.0004903949723671989\n",
      "train loss:0.008649940230646573\n",
      "train loss:0.0014152883838252335\n",
      "train loss:0.03270682643491468\n",
      "train loss:0.09119879425231966\n",
      "train loss:0.0005088531673498556\n",
      "train loss:0.0014129747247337147\n",
      "train loss:0.0019369941112522895\n",
      "train loss:0.054561709826865534\n",
      "train loss:0.002884179784076316\n",
      "train loss:0.0031749953076558608\n",
      "train loss:0.003586240127648479\n",
      "train loss:0.012739407035412209\n",
      "train loss:0.003236911030835391\n",
      "train loss:0.0009579603033449361\n",
      "train loss:0.0005578480300889131\n",
      "train loss:0.0006298588818117502\n",
      "train loss:0.01292353844837841\n",
      "train loss:0.00271811154825908\n",
      "train loss:0.001458086784924259\n",
      "train loss:0.008418092347358398\n",
      "train loss:0.008621779416770866\n",
      "train loss:0.08952665120497047\n",
      "train loss:0.0021060955355938892\n",
      "train loss:0.02195838770961235\n",
      "train loss:0.004904847047317621\n",
      "train loss:0.0020960848628497437\n",
      "train loss:0.002645196811374518\n",
      "train loss:0.005962716501498888\n",
      "train loss:0.000976265285393095\n",
      "train loss:0.005544421493237366\n",
      "train loss:0.00043945806946868384\n",
      "train loss:0.0017243240196129178\n",
      "train loss:0.0014312294246783394\n",
      "train loss:0.006887424173985191\n",
      "train loss:0.013185743653928243\n",
      "train loss:0.0015696507614254573\n",
      "train loss:0.01084839845653136\n",
      "train loss:0.003001890681349734\n",
      "train loss:0.00224975788404615\n",
      "train loss:0.001346005790549517\n",
      "train loss:0.007318131324775094\n",
      "train loss:0.007796267129917262\n",
      "train loss:0.0068244334757434745\n",
      "train loss:0.009180759897651575\n",
      "train loss:0.006586451071061278\n",
      "train loss:0.0016093968088821211\n",
      "train loss:0.010330100914592775\n",
      "train loss:0.006848102174018416\n",
      "train loss:0.012661705823698155\n",
      "train loss:0.001599900429831484\n",
      "train loss:0.0032359038189374127\n",
      "train loss:0.0019106351558773264\n",
      "train loss:0.0021040228505471814\n",
      "train loss:0.0034466504158071672\n",
      "train loss:0.005521658810793739\n",
      "train loss:0.0008491637442228639\n",
      "train loss:0.008326397270470586\n",
      "train loss:0.008576714845110883\n",
      "train loss:0.0016082582726873853\n",
      "train loss:0.0027587433328373425\n",
      "train loss:0.0022811405712608018\n",
      "=== epoch:11, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0008025448339557116\n",
      "train loss:0.011553541546115842\n",
      "train loss:0.012467614706908598\n",
      "train loss:0.001444347585781435\n",
      "train loss:0.0025679550203530155\n",
      "train loss:0.005308512961245074\n",
      "train loss:0.005951562058977088\n",
      "train loss:0.007269315985559362\n",
      "train loss:0.002993005321872662\n",
      "train loss:0.0016281524862224869\n",
      "train loss:0.019249141857753126\n",
      "train loss:0.008556688864981015\n",
      "train loss:0.006450286021829736\n",
      "train loss:0.019557889554111328\n",
      "train loss:0.0015961101939580846\n",
      "train loss:0.00553361873907119\n",
      "train loss:0.02047119738625179\n",
      "train loss:0.0017166580676925033\n",
      "train loss:0.0012591097246187225\n",
      "train loss:0.0050737590802079745\n",
      "train loss:0.014063314083811779\n",
      "train loss:0.0009442867530475108\n",
      "train loss:0.00400792598509141\n",
      "train loss:0.003507781918742552\n",
      "train loss:0.006530537004834081\n",
      "train loss:0.004135590927613253\n",
      "train loss:0.0008690830057451006\n",
      "train loss:0.00034869142499848447\n",
      "train loss:0.002445984612683681\n",
      "train loss:0.0010402218274437154\n",
      "train loss:0.0016806150021246161\n",
      "train loss:0.0038516435272353488\n",
      "train loss:0.017263240986555527\n",
      "train loss:0.00906867426299929\n",
      "train loss:0.021940238124179022\n",
      "train loss:0.007371742167732066\n",
      "train loss:0.004096311707291848\n",
      "train loss:0.0020790091609427298\n",
      "train loss:0.0031562045248128365\n",
      "train loss:0.0015485719733587039\n",
      "train loss:0.0029024306128602527\n",
      "train loss:0.0009412186864847918\n",
      "train loss:0.0006341024067449705\n",
      "train loss:0.001074228308301446\n",
      "train loss:0.01650921523069629\n",
      "train loss:0.002121651365065064\n",
      "train loss:0.0028049000911809147\n",
      "train loss:0.0003113677252478584\n",
      "train loss:0.0002956445007932316\n",
      "train loss:0.0068026787235432274\n",
      "train loss:0.003846911671978961\n",
      "train loss:0.002938388804969441\n",
      "train loss:0.004189439660408845\n",
      "train loss:0.0018369967803517956\n",
      "train loss:0.0024173152734995925\n",
      "train loss:0.0032192500132714676\n",
      "train loss:0.010023298215228951\n",
      "train loss:0.0020888112448667977\n",
      "train loss:0.049055026585678625\n",
      "train loss:0.004257802574020126\n",
      "train loss:0.001786866995093378\n",
      "train loss:0.0034774316263385717\n",
      "train loss:0.0020597922646514396\n",
      "train loss:0.00505526909749348\n",
      "train loss:0.0057766534323858984\n",
      "train loss:0.00132423880201538\n",
      "train loss:0.0013469166367918708\n",
      "train loss:0.01387672635039038\n",
      "train loss:0.006089707072337012\n",
      "train loss:0.0032075819535026286\n",
      "train loss:0.001182465046346444\n",
      "train loss:0.012754733112245066\n",
      "train loss:0.004700142464847939\n",
      "train loss:0.0020605793299259003\n",
      "train loss:0.0026392087619481453\n",
      "train loss:0.006575195936345912\n",
      "train loss:0.002161148415950791\n",
      "train loss:0.011124540548342252\n",
      "train loss:0.0029807084395313678\n",
      "train loss:0.00954427418571704\n",
      "train loss:0.0006072541086220749\n",
      "train loss:0.0073401528771006004\n",
      "train loss:0.019859528069672193\n",
      "train loss:0.014376812564054368\n",
      "train loss:0.009040651343012391\n",
      "train loss:0.001534201108271734\n",
      "train loss:0.016040698186933523\n",
      "train loss:0.008564332749544889\n",
      "train loss:0.0019582179142618485\n",
      "train loss:0.012174972134020292\n",
      "train loss:0.026184157193024513\n",
      "train loss:0.016038124005058982\n",
      "train loss:0.0023588523115153177\n",
      "train loss:0.0017853998107329205\n",
      "train loss:0.033707894434855584\n",
      "train loss:0.00017851339912577889\n",
      "train loss:0.0015255666779199824\n",
      "train loss:0.002687233469974211\n",
      "train loss:0.004630379445833587\n",
      "train loss:0.007102235507545676\n",
      "train loss:0.0013846365881247777\n",
      "train loss:0.029410156071415595\n",
      "train loss:0.0016566187592660766\n",
      "train loss:0.0012820353935804885\n",
      "train loss:0.02845225583501755\n",
      "train loss:0.0018411216482253111\n",
      "train loss:0.005473072728441318\n",
      "train loss:0.006123809345486935\n",
      "train loss:0.007033872400217495\n",
      "train loss:0.0031903813698541655\n",
      "train loss:0.004845146661652703\n",
      "train loss:0.009833754836971992\n",
      "train loss:0.0026289083396245677\n",
      "train loss:0.004372381982350397\n",
      "train loss:0.010802647410671466\n",
      "train loss:0.0019381734419378883\n",
      "train loss:0.001746530710902716\n",
      "train loss:0.003559075433713288\n",
      "train loss:0.014808912409931102\n",
      "train loss:0.0039032825401861563\n",
      "train loss:0.0029766255361268535\n",
      "train loss:0.006800909320518119\n",
      "train loss:0.006446481538220056\n",
      "train loss:0.0029411067779420326\n",
      "train loss:0.0022981122098445278\n",
      "train loss:0.0018146239621049853\n",
      "train loss:0.02024423208090151\n",
      "train loss:0.010146153250918628\n",
      "train loss:0.005010942424854131\n",
      "train loss:0.006774927740522494\n",
      "train loss:0.003598492489794365\n",
      "train loss:0.003601382320277557\n",
      "train loss:0.005968813952866799\n",
      "train loss:0.006668018294947252\n",
      "train loss:0.003819810526951\n",
      "train loss:0.0038704814883502824\n",
      "train loss:0.000113859313875194\n",
      "train loss:0.015820947305804495\n",
      "train loss:0.009875971479364136\n",
      "train loss:0.00270567720697874\n",
      "train loss:0.003308930729895777\n",
      "train loss:0.006798209123318454\n",
      "train loss:0.008210170020978153\n",
      "train loss:0.001460654047651825\n",
      "train loss:0.0006603884841092536\n",
      "train loss:0.008063177781246078\n",
      "train loss:0.022368284239184258\n",
      "train loss:0.001054206030696978\n",
      "train loss:0.0023771121502099454\n",
      "train loss:0.00343196529058317\n",
      "train loss:0.0035014765903012344\n",
      "train loss:0.0014297611668162122\n",
      "train loss:0.001942930976686757\n",
      "train loss:0.005184350934389688\n",
      "train loss:0.02727959950283608\n",
      "train loss:0.00036115268447222597\n",
      "train loss:0.00029213269152101137\n",
      "train loss:0.004270651673422589\n",
      "train loss:0.0002998195938743527\n",
      "train loss:0.002627675506425361\n",
      "train loss:0.0017637156952568403\n",
      "train loss:0.006310731240037663\n",
      "train loss:0.0029379818517811223\n",
      "train loss:0.016668885958351528\n",
      "train loss:0.0028569781726151605\n",
      "train loss:0.0026312976040691084\n",
      "train loss:0.0025474671016670392\n",
      "train loss:0.0006934925413832653\n",
      "train loss:0.0032303322976836237\n",
      "train loss:0.006331884964080957\n",
      "train loss:0.0058414219367058885\n",
      "train loss:0.0003023937376151401\n",
      "train loss:0.010994810334059309\n",
      "train loss:0.05004651275887253\n",
      "train loss:0.005895119201340186\n",
      "train loss:0.004667318359729469\n",
      "train loss:0.0019980961032974322\n",
      "train loss:0.007336425243253473\n",
      "train loss:0.006683675720722664\n",
      "train loss:0.0013300985343561967\n",
      "train loss:0.003795081114302905\n",
      "train loss:0.0013522781813675075\n",
      "train loss:0.005954998517407581\n",
      "train loss:0.00723358266480102\n",
      "train loss:0.0008401684008003511\n",
      "train loss:0.0019525251887169037\n",
      "train loss:0.001713084474560096\n",
      "train loss:0.005401911329120235\n",
      "train loss:0.0008970554595104756\n",
      "train loss:0.001968121113888093\n",
      "train loss:0.0008727009550088509\n",
      "train loss:0.0008701353219135756\n",
      "train loss:0.01612720990084622\n",
      "train loss:0.0032609420088619274\n",
      "train loss:0.006834400602328633\n",
      "train loss:0.0018324132885129507\n",
      "train loss:0.010234494017526628\n",
      "train loss:0.002703257095394738\n",
      "train loss:0.00213706275111208\n",
      "train loss:0.0027926346441953446\n",
      "train loss:0.006090246537880245\n",
      "train loss:0.0410920024799943\n",
      "train loss:0.006470603587249369\n",
      "train loss:0.0014288080577641294\n",
      "train loss:0.0013246079675847452\n",
      "train loss:0.0022842400454826054\n",
      "train loss:0.005199785673415903\n",
      "train loss:0.0010684744130416983\n",
      "train loss:0.0019155372179562938\n",
      "train loss:0.002556417292853106\n",
      "train loss:0.0021067853104149176\n",
      "train loss:0.00305689709600415\n",
      "train loss:0.005467939838519595\n",
      "train loss:0.011511606788256325\n",
      "train loss:0.07820806925238687\n",
      "train loss:0.0010542336494011335\n",
      "train loss:0.008431340952470206\n",
      "train loss:0.0033732515332606295\n",
      "train loss:0.007173550433524426\n",
      "train loss:0.007121041537809531\n",
      "train loss:0.0018989565700494912\n",
      "train loss:0.0049173699165915305\n",
      "train loss:0.005084660814309838\n",
      "train loss:0.04243205242860976\n",
      "train loss:0.01370661801618195\n",
      "train loss:0.0027259424280366177\n",
      "train loss:0.01411368956421891\n",
      "train loss:0.002361577670103931\n",
      "train loss:0.000795606835805102\n",
      "train loss:0.0006607244511961734\n",
      "train loss:0.0062721824209488195\n",
      "train loss:0.007029618964218416\n",
      "train loss:0.0011543399602784268\n",
      "train loss:0.01717602421784414\n",
      "train loss:0.008617863036755703\n",
      "train loss:0.0026623477744955088\n",
      "train loss:0.007129021345860151\n",
      "train loss:0.0022383432241814675\n",
      "train loss:0.0059145483390587615\n",
      "train loss:0.0029535602038833243\n",
      "train loss:0.03317265169536276\n",
      "train loss:0.004319435272943259\n",
      "train loss:0.0011826527192786728\n",
      "train loss:0.0016980614556093368\n",
      "train loss:0.0035210386557711997\n",
      "train loss:0.00427513632390341\n",
      "train loss:0.004830136289543546\n",
      "train loss:0.001968615981244024\n",
      "train loss:0.005686092527443295\n",
      "train loss:0.003365470306823264\n",
      "train loss:0.0012540319077385057\n",
      "train loss:0.0003899687048479797\n",
      "train loss:0.001676389717901338\n",
      "train loss:0.001766539170305751\n",
      "train loss:0.0033078804793480444\n",
      "train loss:0.010040062902895773\n",
      "train loss:0.009928163064150265\n",
      "train loss:0.0029447941770754053\n",
      "train loss:0.0010543877806180203\n",
      "train loss:0.022574913924251944\n",
      "train loss:0.0037142159408574916\n",
      "train loss:0.027545017093331917\n",
      "train loss:0.020111293270199018\n",
      "train loss:0.0018944884686520258\n",
      "train loss:0.0008373449166883283\n",
      "train loss:0.005313774386548457\n",
      "train loss:0.012487552467062972\n",
      "train loss:0.0014555820849750912\n",
      "train loss:0.0017565363709084207\n",
      "train loss:0.011828705152014889\n",
      "train loss:0.005939098861242773\n",
      "train loss:0.0029549109335957877\n",
      "train loss:0.0033850049949425815\n",
      "train loss:0.004252107880757289\n",
      "train loss:0.008121360719749884\n",
      "train loss:0.0006383735053938362\n",
      "train loss:0.0023592497612117853\n",
      "train loss:0.0007357560434060272\n",
      "train loss:0.0011718955632185474\n",
      "train loss:0.00196971906786237\n",
      "train loss:0.0026471682985041356\n",
      "train loss:0.019962284946073564\n",
      "train loss:0.002147306125892236\n",
      "train loss:0.01502901398086262\n",
      "train loss:0.002077821001502438\n",
      "train loss:0.01128165972304292\n",
      "train loss:0.010678961772864424\n",
      "train loss:0.009313498674515119\n",
      "train loss:0.0025400626248501556\n",
      "train loss:0.00538878805212809\n",
      "train loss:0.0009001858413602346\n",
      "train loss:0.0012775600683244321\n",
      "train loss:0.006064683219275089\n",
      "train loss:0.009596684708831434\n",
      "train loss:0.0027534755494433238\n",
      "train loss:0.0020024697013679847\n",
      "train loss:0.0051743991013168435\n",
      "train loss:0.0007075855757285989\n",
      "train loss:0.0007428703439781814\n",
      "train loss:0.0019837265588714143\n",
      "train loss:0.0035568974528666403\n",
      "train loss:0.008252652228106217\n",
      "train loss:0.02927042853597937\n",
      "train loss:0.0019370286279683782\n",
      "train loss:0.03485238391713613\n",
      "train loss:0.006442582815810528\n",
      "train loss:0.003064537379411807\n",
      "train loss:0.002946869807529199\n",
      "train loss:0.0025426210963525064\n",
      "train loss:0.0024012027304432023\n",
      "train loss:0.0009259380005702559\n",
      "train loss:0.002816582777080805\n",
      "train loss:0.0014990700551410743\n",
      "train loss:0.0030033354218005326\n",
      "train loss:0.006481891518649058\n",
      "train loss:0.0028533751950886093\n",
      "train loss:0.0012281101357897346\n",
      "train loss:0.015679480604294308\n",
      "train loss:0.0024568205147904075\n",
      "train loss:0.0012281712410915277\n",
      "train loss:0.0037731468506452858\n",
      "train loss:0.027380836905287236\n",
      "train loss:0.011374070699554461\n",
      "train loss:0.001932889479506498\n",
      "train loss:0.0016721230233120437\n",
      "train loss:0.00026038648657457543\n",
      "train loss:0.00501882788252832\n",
      "train loss:0.002991506104524753\n",
      "train loss:0.0006407577188363932\n",
      "train loss:0.0028336016922390402\n",
      "train loss:0.004855260950401448\n",
      "train loss:0.0033665490321476334\n",
      "train loss:0.004270093536387414\n",
      "train loss:0.020972070533770926\n",
      "train loss:0.005777652623674556\n",
      "train loss:0.025786445570131048\n",
      "train loss:0.0038054712754643973\n",
      "train loss:0.00246287536721173\n",
      "train loss:0.00345577610259097\n",
      "train loss:0.003892430860283432\n",
      "train loss:0.004185655853334258\n",
      "train loss:0.0006947264269597739\n",
      "train loss:0.008577870879997885\n",
      "train loss:0.0016505578386508282\n",
      "train loss:0.0018524366132751575\n",
      "train loss:0.001914045532157014\n",
      "train loss:0.009866177538198802\n",
      "train loss:0.00577000288479548\n",
      "train loss:0.00454059042030741\n",
      "train loss:0.0022678371504250027\n",
      "train loss:0.005338648433908909\n",
      "train loss:0.0010388637112043336\n",
      "train loss:0.004237450726018747\n",
      "train loss:0.009648335641012562\n",
      "train loss:0.001802310439765081\n",
      "train loss:0.0013607871545822216\n",
      "train loss:0.03292905891131891\n",
      "train loss:0.003407507036331485\n",
      "train loss:0.00260443867834559\n",
      "train loss:0.008559450873138912\n",
      "train loss:0.0078099494645101466\n",
      "train loss:0.0038785053142458017\n",
      "train loss:0.00676759903680652\n",
      "train loss:0.007739724330884699\n",
      "train loss:0.009501829716078448\n",
      "train loss:0.0019953538297467818\n",
      "train loss:0.001905147478478954\n",
      "train loss:0.0022581235716317176\n",
      "train loss:0.0035745067104071514\n",
      "train loss:0.0007720164725807674\n",
      "train loss:0.008828270753763863\n",
      "train loss:0.0012098796353322465\n",
      "train loss:0.0012784095148282585\n",
      "train loss:0.006648053511345123\n",
      "train loss:0.005950342847887868\n",
      "train loss:0.01052386197818716\n",
      "train loss:0.0038103819019163292\n",
      "train loss:0.0034605089437318047\n",
      "train loss:0.0008705432282187793\n",
      "train loss:0.005633225750897095\n",
      "train loss:0.0006377605934175444\n",
      "train loss:0.005479436930613195\n",
      "train loss:0.0032705553520242796\n",
      "train loss:0.021357425234291613\n",
      "train loss:0.002478284237362247\n",
      "train loss:0.0002807640799958119\n",
      "train loss:0.007412690024739657\n",
      "train loss:0.008650773932809865\n",
      "train loss:0.0019211398350083885\n",
      "train loss:0.01569174399921817\n",
      "train loss:0.0005075724391640857\n",
      "train loss:0.008042669435545062\n",
      "train loss:0.007873435921641468\n",
      "train loss:0.0031807143537301787\n",
      "train loss:0.007994869639550189\n",
      "train loss:0.0008641025032776532\n",
      "train loss:0.013630438604621547\n",
      "train loss:0.0016545099116930307\n",
      "train loss:0.0014265705542221246\n",
      "train loss:0.000810930045877402\n",
      "train loss:0.0008975395411248868\n",
      "train loss:0.0007401904581048736\n",
      "train loss:0.0021714838201268823\n",
      "train loss:0.00313447587407504\n",
      "train loss:0.0018145138686580387\n",
      "train loss:0.023689282150755418\n",
      "train loss:0.024493589454009247\n",
      "train loss:0.005246201782089824\n",
      "train loss:0.003339416076130941\n",
      "train loss:0.04391285698090479\n",
      "train loss:0.0016897376939217668\n",
      "train loss:0.0010639696349944825\n",
      "train loss:0.0051427409827547975\n",
      "train loss:0.011887563163816612\n",
      "train loss:0.0029704547444750424\n",
      "train loss:0.00268631316199237\n",
      "train loss:0.003280451040676438\n",
      "train loss:0.004286637993316793\n",
      "train loss:0.0033105691132822583\n",
      "train loss:0.0013527723443085339\n",
      "train loss:0.03938921966152694\n",
      "train loss:0.008727588970686904\n",
      "train loss:0.0007142917729061853\n",
      "train loss:0.0006511765302592707\n",
      "train loss:0.021062882423295005\n",
      "train loss:0.00299480102868894\n",
      "train loss:0.0042475241664893144\n",
      "train loss:0.012530501154401264\n",
      "train loss:0.0023177872309470167\n",
      "train loss:0.001988259737965654\n",
      "train loss:0.0011965363726122017\n",
      "train loss:0.0027247726753056086\n",
      "train loss:0.002598147053033497\n",
      "train loss:0.015376086142686455\n",
      "train loss:0.008252538660560409\n",
      "train loss:0.004036652494253088\n",
      "train loss:0.024198347237971717\n",
      "train loss:0.0008076871184755501\n",
      "train loss:0.004299695763538084\n",
      "train loss:0.008361705588482888\n",
      "train loss:0.01476056003185467\n",
      "train loss:0.01286390327841139\n",
      "train loss:0.032873975932449305\n",
      "train loss:0.0007144174121861464\n",
      "train loss:0.0009595178302813881\n",
      "train loss:0.008052632769912615\n",
      "train loss:0.0044731444273547975\n",
      "train loss:0.010328129515441865\n",
      "train loss:0.005120822712590424\n",
      "train loss:0.002102707033727908\n",
      "train loss:0.009187585984084864\n",
      "train loss:0.00234336958566423\n",
      "train loss:0.00221456720227333\n",
      "train loss:0.013665141125226923\n",
      "train loss:0.003919460136221008\n",
      "train loss:0.0012838401520662219\n",
      "train loss:0.0023114338672851884\n",
      "train loss:0.03085069071905894\n",
      "train loss:0.004417485339094357\n",
      "train loss:0.04077684696935104\n",
      "train loss:0.01746515753643342\n",
      "train loss:0.006514442455724635\n",
      "train loss:0.002770299823095128\n",
      "train loss:0.005035480254514406\n",
      "train loss:0.027772073095813504\n",
      "train loss:0.0570497642467045\n",
      "train loss:0.010382556408577041\n",
      "train loss:0.0016417969154578292\n",
      "train loss:0.0006813001042062584\n",
      "train loss:0.0015630971433610872\n",
      "train loss:0.004534439292825958\n",
      "train loss:0.001164539820379747\n",
      "train loss:0.0021625333659589566\n",
      "train loss:0.003964835783707224\n",
      "train loss:0.0007196475913805083\n",
      "train loss:0.001473754901424323\n",
      "train loss:0.0016388734702927137\n",
      "train loss:0.011573286875618144\n",
      "train loss:0.004261319605180992\n",
      "train loss:0.0035009696146997447\n",
      "train loss:0.0006801788815646461\n",
      "train loss:0.0012671118815127233\n",
      "train loss:0.02687457033174755\n",
      "train loss:0.0024929861867655123\n",
      "train loss:0.004749383529119344\n",
      "train loss:0.006707628015765733\n",
      "train loss:0.0005452215082516857\n",
      "train loss:0.007975782415067122\n",
      "train loss:0.001206158114955318\n",
      "train loss:0.0017804933220113024\n",
      "train loss:0.04977055932509094\n",
      "train loss:0.0031285402685053533\n",
      "train loss:0.0051583741539495435\n",
      "train loss:0.0017245801324243428\n",
      "train loss:0.0018777640144899729\n",
      "train loss:0.011317751932827391\n",
      "train loss:0.0016811111305206647\n",
      "train loss:0.0030313408185763764\n",
      "train loss:0.004922459712101183\n",
      "train loss:0.003815174448808368\n",
      "train loss:0.0015646768584761015\n",
      "train loss:0.008504844297329119\n",
      "train loss:0.0025437627242687736\n",
      "train loss:0.0013365256646638525\n",
      "train loss:0.0020913438552416183\n",
      "train loss:0.012990067742114721\n",
      "train loss:0.0010475352955681171\n",
      "train loss:0.0005146970101299094\n",
      "train loss:0.009309464182066322\n",
      "train loss:0.004303602713804451\n",
      "train loss:0.009349460602256688\n",
      "train loss:0.0011751045542151943\n",
      "train loss:0.0021216274233703167\n",
      "train loss:0.0026262509949203385\n",
      "train loss:0.004151332762423918\n",
      "train loss:0.0030411036934144763\n",
      "train loss:0.001552778773702908\n",
      "train loss:0.006943344153351242\n",
      "train loss:0.0005214136668788752\n",
      "train loss:0.0022094385500224744\n",
      "train loss:0.000992072660707314\n",
      "train loss:0.0070202153625126325\n",
      "train loss:0.0046676100939032\n",
      "train loss:0.003699049354503962\n",
      "train loss:0.01684050489884268\n",
      "train loss:0.0011035204778942166\n",
      "train loss:0.003818824561973062\n",
      "train loss:0.004655295015499289\n",
      "train loss:0.00047161677874743536\n",
      "train loss:0.016373481741264816\n",
      "train loss:0.011318640445195398\n",
      "train loss:0.0035085256030546958\n",
      "train loss:0.004790706331533225\n",
      "train loss:0.005957186690656595\n",
      "train loss:0.001320832266681602\n",
      "train loss:0.0029741665109269343\n",
      "train loss:0.0011796515671866218\n",
      "train loss:0.005295810229164286\n",
      "train loss:0.01679236907959658\n",
      "train loss:0.006249936181304468\n",
      "train loss:0.007817953057469504\n",
      "train loss:0.0016350661234159\n",
      "train loss:0.005740515711127616\n",
      "train loss:0.0009288394924302867\n",
      "train loss:0.02945162789403406\n",
      "train loss:0.000902580382640912\n",
      "train loss:0.0045184598492385595\n",
      "train loss:0.000779498418915198\n",
      "train loss:0.010474331696614625\n",
      "train loss:0.005189353113898204\n",
      "train loss:0.0002621882513966602\n",
      "train loss:0.00542435421131896\n",
      "train loss:0.0007055772264131599\n",
      "train loss:0.006146713215582776\n",
      "train loss:0.0016833537388360683\n",
      "train loss:0.008901114331156174\n",
      "train loss:0.002264238808748729\n",
      "train loss:0.007824410683594442\n",
      "train loss:0.002371485569304435\n",
      "train loss:0.0049500323114655366\n",
      "train loss:0.0017655462998894275\n",
      "train loss:0.0025629417107901043\n",
      "train loss:0.004210011714704529\n",
      "train loss:0.004518062692495075\n",
      "train loss:0.0028346750662962324\n",
      "train loss:0.0035379326846140874\n",
      "train loss:0.003602246664342808\n",
      "train loss:0.008683150137442868\n",
      "train loss:0.0025627297003183737\n",
      "train loss:0.0023469000826598723\n",
      "train loss:0.0025687478748812596\n",
      "train loss:0.0014185674479557785\n",
      "train loss:0.0013949708574112177\n",
      "train loss:0.00399418147603655\n",
      "train loss:0.0023971090395223556\n",
      "train loss:0.0034978788000395557\n",
      "train loss:0.029760968047237425\n",
      "train loss:0.001034410279818385\n",
      "train loss:0.0015844803892696641\n",
      "train loss:0.003956899463033231\n",
      "train loss:0.003968374252528606\n",
      "train loss:0.0042078923891852036\n",
      "train loss:0.0011238939198978028\n",
      "train loss:0.01017185691346672\n",
      "train loss:0.0005542402952953539\n",
      "train loss:0.0017183976823494662\n",
      "train loss:0.0007205907475919636\n",
      "train loss:0.002537643521348094\n",
      "train loss:0.0002230078723302989\n",
      "train loss:0.0006476335776715238\n",
      "train loss:0.002129908710500591\n",
      "train loss:0.005391730641585132\n",
      "train loss:0.0021435402662653997\n",
      "train loss:0.000526179286722916\n",
      "train loss:0.0034325299685833283\n",
      "train loss:0.0005386029839108625\n",
      "train loss:0.009819628360950523\n",
      "train loss:0.00367353855970872\n",
      "train loss:0.003725534851613711\n",
      "train loss:0.0007856524039292034\n",
      "=== epoch:12, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.0028456462946385474\n",
      "train loss:0.001384261347913636\n",
      "train loss:0.008388444352528623\n",
      "train loss:0.0028388799274641436\n",
      "train loss:0.0013702250767592343\n",
      "train loss:0.0034906290013691455\n",
      "train loss:0.0010624512933463293\n",
      "train loss:0.002562255954783937\n",
      "train loss:0.002546541109515381\n",
      "train loss:0.002866210545030003\n",
      "train loss:0.004323625750299446\n",
      "train loss:0.004446738922640498\n",
      "train loss:0.0022722595306118435\n",
      "train loss:0.0011812530711136262\n",
      "train loss:0.0016886836266739856\n",
      "train loss:0.0008509002249108367\n",
      "train loss:0.007115850937843916\n",
      "train loss:0.0010613200019990096\n",
      "train loss:0.001266896829096754\n",
      "train loss:0.005281973915408911\n",
      "train loss:0.005122284691692676\n",
      "train loss:0.0004799993836995216\n",
      "train loss:0.003611968084373285\n",
      "train loss:0.016220998443300643\n",
      "train loss:0.004170635908980259\n",
      "train loss:0.0012322967982565105\n",
      "train loss:0.0068589725787153635\n",
      "train loss:0.007169201973837322\n",
      "train loss:0.001859681532320986\n",
      "train loss:0.005933676047080208\n",
      "train loss:0.008194578722921744\n",
      "train loss:0.0017229706300647578\n",
      "train loss:0.0012001448568949304\n",
      "train loss:0.007738695709545895\n",
      "train loss:0.003410650948805872\n",
      "train loss:0.008497943145322932\n",
      "train loss:0.0013299451995341142\n",
      "train loss:0.002187701184850923\n",
      "train loss:0.0005250128515445562\n",
      "train loss:0.002668495064585501\n",
      "train loss:0.01599988440694458\n",
      "train loss:0.00015728651081404248\n",
      "train loss:0.018717531868996218\n",
      "train loss:0.0016992502472936277\n",
      "train loss:0.0015119377307977256\n",
      "train loss:0.008609988821994043\n",
      "train loss:0.0009110356787781194\n",
      "train loss:0.004764027664564083\n",
      "train loss:0.0009278378279708321\n",
      "train loss:0.0033259693149909984\n",
      "train loss:0.0014190749181974779\n",
      "train loss:0.013600352994392639\n",
      "train loss:0.0004975673573057346\n",
      "train loss:0.0007615179365479064\n",
      "train loss:0.001330640744948214\n",
      "train loss:0.0014982142913954157\n",
      "train loss:0.0008770027226454124\n",
      "train loss:0.0041921238725460535\n",
      "train loss:0.002249659470980412\n",
      "train loss:0.009271403801184706\n",
      "train loss:0.0007395165264650702\n",
      "train loss:0.005446620432133885\n",
      "train loss:0.009278857905538734\n",
      "train loss:0.0035396027767798997\n",
      "train loss:0.004290985595403463\n",
      "train loss:0.0007675218566195865\n",
      "train loss:0.002931953774117142\n",
      "train loss:0.0016515263124047728\n",
      "train loss:0.007616936352333156\n",
      "train loss:0.0037174684645217737\n",
      "train loss:0.0023984047496374405\n",
      "train loss:0.0026254754780518615\n",
      "train loss:0.0015976590058136195\n",
      "train loss:0.0032150307571421483\n",
      "train loss:0.015336202146480753\n",
      "train loss:0.0016194704202211808\n",
      "train loss:0.0043116419702219164\n",
      "train loss:0.01715779114192267\n",
      "train loss:0.006987677434193741\n",
      "train loss:0.0005829588652003587\n",
      "train loss:0.0006518095249172018\n",
      "train loss:0.009373175074100779\n",
      "train loss:0.0023332526461680024\n",
      "train loss:0.0008079018865118997\n",
      "train loss:0.0014413318031083772\n",
      "train loss:0.004375978253591364\n",
      "train loss:0.0007093268783729337\n",
      "train loss:0.008312191444540462\n",
      "train loss:0.002870784676909775\n",
      "train loss:0.01674759463158524\n",
      "train loss:0.0009298612536389879\n",
      "train loss:0.0010967731901002586\n",
      "train loss:0.01245242457428788\n",
      "train loss:0.002694232835772437\n",
      "train loss:0.0025274071780187783\n",
      "train loss:0.0007857123191966489\n",
      "train loss:0.002618440059674313\n",
      "train loss:0.0033349120581259383\n",
      "train loss:0.005014981128778541\n",
      "train loss:0.00848138299970146\n",
      "train loss:0.0005157159619705204\n",
      "train loss:0.00629495385681697\n",
      "train loss:6.36036533555118e-05\n",
      "train loss:0.00023786019438859146\n",
      "train loss:0.002624651062625273\n",
      "train loss:0.0032281744064218743\n",
      "train loss:0.000934854452691345\n",
      "train loss:0.003994934267608326\n",
      "train loss:0.0013125983514866765\n",
      "train loss:0.000893456820380906\n",
      "train loss:0.0001526127451427602\n",
      "train loss:0.0008862527737272722\n",
      "train loss:0.0010223869574405573\n",
      "train loss:0.001792638936342181\n",
      "train loss:0.000736175718172926\n",
      "train loss:0.04491482384797612\n",
      "train loss:0.008068381636382078\n",
      "train loss:0.0017151759379017534\n",
      "train loss:0.005416603833444711\n",
      "train loss:0.004714253630239799\n",
      "train loss:0.009428525116738267\n",
      "train loss:0.00900452376756696\n",
      "train loss:0.0007529617550746325\n",
      "train loss:0.006885777860626286\n",
      "train loss:0.002005406054506423\n",
      "train loss:0.0135294414968543\n",
      "train loss:0.003988677990497038\n",
      "train loss:0.002137288426243213\n",
      "train loss:0.003967531296936875\n",
      "train loss:0.011646839736032689\n",
      "train loss:0.006182830457205475\n",
      "train loss:0.005190298319995186\n",
      "train loss:0.027379517679931475\n",
      "train loss:0.0025332603832701854\n",
      "train loss:0.0008321631242959954\n",
      "train loss:0.0013013502243828699\n",
      "train loss:0.022347506756383573\n",
      "train loss:0.000352351531927765\n",
      "train loss:0.007115506716304684\n",
      "train loss:0.0028130718729796663\n",
      "train loss:0.004210587099901737\n",
      "train loss:0.013504826913316106\n",
      "train loss:0.0035578512469692796\n",
      "train loss:0.0028562834512419243\n",
      "train loss:0.03964265569724981\n",
      "train loss:0.004876197920164831\n",
      "train loss:0.0006474634295839898\n",
      "train loss:0.0024500189327485602\n",
      "train loss:0.00025745814003573324\n",
      "train loss:0.007597209295655898\n",
      "train loss:0.008942256474166944\n",
      "train loss:0.001884631898320081\n",
      "train loss:0.003473191070035642\n",
      "train loss:0.010223557022041576\n",
      "train loss:0.012186324179366444\n",
      "train loss:0.00236235796019423\n",
      "train loss:0.0009862726129232155\n",
      "train loss:0.0030282634943210335\n",
      "train loss:0.0017348756543499539\n",
      "train loss:0.003989644000633424\n",
      "train loss:0.03965891271161125\n",
      "train loss:0.0013292011547852574\n",
      "train loss:0.0008000344038683842\n",
      "train loss:0.027450263632218187\n",
      "train loss:0.015157690567982027\n",
      "train loss:0.0003784789411157292\n",
      "train loss:0.0009474474124225277\n",
      "train loss:0.003636854222117552\n",
      "train loss:0.002277715682786408\n",
      "train loss:0.01422205334496176\n",
      "train loss:0.002472564113507403\n",
      "train loss:0.012608112993248648\n",
      "train loss:0.003523603760163175\n",
      "train loss:0.00220643679989263\n",
      "train loss:0.00901781929547629\n",
      "train loss:0.0050868606038036775\n",
      "train loss:0.008248084187045443\n",
      "train loss:0.0016271751245143181\n",
      "train loss:0.002146766325149185\n",
      "train loss:0.001599286149815149\n",
      "train loss:0.012409902984460748\n",
      "train loss:0.0008634686447045145\n",
      "train loss:0.005376071157021283\n",
      "train loss:0.016193871894821844\n",
      "train loss:0.006735339211525915\n",
      "train loss:0.0008751956447986531\n",
      "train loss:0.001007104039554355\n",
      "train loss:0.005320216875939505\n",
      "train loss:0.002471097154427207\n",
      "train loss:0.006235756287542816\n",
      "train loss:0.001692247262683629\n",
      "train loss:0.001965459222520983\n",
      "train loss:0.005194639357453553\n",
      "train loss:0.005363667690749413\n",
      "train loss:0.08542437843475574\n",
      "train loss:0.04015326620279782\n",
      "train loss:0.0027478995027997205\n",
      "train loss:0.0017386982141046016\n",
      "train loss:0.0019286764827079978\n",
      "train loss:0.004280961858151954\n",
      "train loss:0.004302129190535632\n",
      "train loss:0.04095976099450627\n",
      "train loss:0.001531619697206248\n",
      "train loss:0.0035708326994403554\n",
      "train loss:0.0049002810637076965\n",
      "train loss:0.0003960091070726932\n",
      "train loss:0.002136284455335667\n",
      "train loss:0.001999243257528567\n",
      "train loss:0.004054271662415942\n",
      "train loss:0.003725725168520875\n",
      "train loss:0.005649100884194572\n",
      "train loss:0.003961705762643189\n",
      "train loss:0.0017318416692368565\n",
      "train loss:0.0009846079135418832\n",
      "train loss:0.005387238537147992\n",
      "train loss:0.003684361777677312\n",
      "train loss:0.00037394214385320717\n",
      "train loss:0.0022967339621110345\n",
      "train loss:0.008024642259118326\n",
      "train loss:0.002752399274915801\n",
      "train loss:0.006486117624657495\n",
      "train loss:0.007052981688750849\n",
      "train loss:0.00047878107879885547\n",
      "train loss:0.005227292327538446\n",
      "train loss:0.005123216483711228\n",
      "train loss:0.006147119889390777\n",
      "train loss:0.010611971536211923\n",
      "train loss:0.012632920190855124\n",
      "train loss:0.00307238675812742\n",
      "train loss:0.0008374638711339259\n",
      "train loss:0.0024200096488322304\n",
      "train loss:0.005695394003347159\n",
      "train loss:0.008429164425538068\n",
      "train loss:0.001285264001805878\n",
      "train loss:0.00047251571911081187\n",
      "train loss:0.007672112055262525\n",
      "train loss:0.002446971532182176\n",
      "train loss:0.0037335793331334296\n",
      "train loss:0.010344057395007565\n",
      "train loss:0.00029913151302205225\n",
      "train loss:0.0102662067161566\n",
      "train loss:0.0004769215266401087\n",
      "train loss:0.0018117149253704253\n",
      "train loss:0.020744649367898643\n",
      "train loss:0.0016067229974937654\n",
      "train loss:0.0032444192972649268\n",
      "train loss:0.008339005418379009\n",
      "train loss:0.005123132958012034\n",
      "train loss:0.006485703478854573\n",
      "train loss:0.0013053661488709445\n",
      "train loss:0.00334147185682503\n",
      "train loss:0.0007843728478034187\n",
      "train loss:0.0030552151756630635\n",
      "train loss:0.0014205402327226587\n",
      "train loss:0.005376333998224113\n",
      "train loss:0.004567287124190121\n",
      "train loss:0.001909696883880364\n",
      "train loss:0.0009930665660700135\n",
      "train loss:0.0032338333118635304\n",
      "train loss:0.0002435014975178838\n",
      "train loss:0.000687255518486212\n",
      "train loss:0.0019932189677667254\n",
      "train loss:0.0010674744882669938\n",
      "train loss:0.0006673187735120269\n",
      "train loss:0.004232672831797804\n",
      "train loss:0.0012435109190679352\n",
      "train loss:0.001502775281301748\n",
      "train loss:0.005038400082541719\n",
      "train loss:0.006272974324355461\n",
      "train loss:0.004411979206167643\n",
      "train loss:0.003290871224465029\n",
      "train loss:0.0007878435926477241\n",
      "train loss:0.003460118658218766\n",
      "train loss:0.005849174841982658\n",
      "train loss:0.0005064100044613521\n",
      "train loss:0.0006555814063034842\n",
      "train loss:0.003485455945323922\n",
      "train loss:0.0036964646464901292\n",
      "train loss:0.0011417998514898194\n",
      "train loss:0.003339554677143004\n",
      "train loss:0.0035831655304397443\n",
      "train loss:0.015534746383931645\n",
      "train loss:0.0051885707849435615\n",
      "train loss:0.0016836804907676853\n",
      "train loss:0.0004450439668416171\n",
      "train loss:0.0011127709038201191\n",
      "train loss:0.00895859627658974\n",
      "train loss:0.002647723010622312\n",
      "train loss:0.0004504592765773387\n",
      "train loss:0.009931796504540333\n",
      "train loss:0.0042175641589999825\n",
      "train loss:0.00486907563447913\n",
      "train loss:0.011012730574335196\n",
      "train loss:0.04162911842661592\n",
      "train loss:0.014803448753661415\n",
      "train loss:0.017690433706685407\n",
      "train loss:0.004859665666241179\n",
      "train loss:0.007555745521598449\n",
      "train loss:0.011667541572689448\n",
      "train loss:0.010164985069941734\n",
      "train loss:0.028574290197910884\n",
      "train loss:0.01886635377306753\n",
      "train loss:0.0015393645037325564\n",
      "train loss:0.00828462196036419\n",
      "train loss:0.004635919502004102\n",
      "train loss:0.002061139857522402\n",
      "train loss:0.0015757843167439776\n",
      "train loss:0.004323266057835155\n",
      "train loss:0.007430500226052291\n",
      "train loss:0.007151232785847596\n",
      "train loss:0.011718751574218754\n",
      "train loss:0.005218881347027037\n",
      "train loss:0.007031035169460184\n",
      "train loss:0.003708448676237313\n",
      "train loss:0.004760328689874078\n",
      "train loss:0.026445419816169227\n",
      "train loss:0.02720233355356304\n",
      "train loss:9.327199437058859e-05\n",
      "train loss:0.00021618192168757313\n",
      "train loss:0.0006970965086119245\n",
      "train loss:0.001304370770263263\n",
      "train loss:0.009076455666985414\n",
      "train loss:0.005189502206677901\n",
      "train loss:0.01694957134730202\n",
      "train loss:0.006425067678621663\n",
      "train loss:0.0023590802985258936\n",
      "train loss:0.0036492231022956616\n",
      "train loss:0.004967035092763425\n",
      "train loss:0.0005426375357261346\n",
      "train loss:0.008220790588224886\n",
      "train loss:0.003221001612750227\n",
      "train loss:0.004315401729772399\n",
      "train loss:0.0022601508001970296\n",
      "train loss:0.006565609151796994\n",
      "train loss:0.008813049491691982\n",
      "train loss:0.0016980352014723623\n",
      "train loss:0.005788415159944688\n",
      "train loss:0.0019678002238631307\n",
      "train loss:0.004463072479539478\n",
      "train loss:0.0034387269974109087\n",
      "train loss:0.014961964581391225\n",
      "train loss:0.009601666962283572\n",
      "train loss:0.0012417633249576393\n",
      "train loss:0.007540201539553564\n",
      "train loss:0.005171460989991974\n",
      "train loss:0.004419826277309384\n",
      "train loss:0.0007598117057616\n",
      "train loss:0.0034122329479377945\n",
      "train loss:0.00518046605728771\n",
      "train loss:0.0026668845897517323\n",
      "train loss:0.0003287933259749227\n",
      "train loss:0.0029016577165090055\n",
      "train loss:0.003547797274441823\n",
      "train loss:0.016923279335531092\n",
      "train loss:0.0003788916995240999\n",
      "train loss:0.006373948841270816\n",
      "train loss:0.0021482805322579767\n",
      "train loss:0.008444898243055748\n",
      "train loss:0.0029254860076234662\n",
      "train loss:0.004530971406338059\n",
      "train loss:0.004636824063655887\n",
      "train loss:0.0016225962246072213\n",
      "train loss:0.003770050737415955\n",
      "train loss:0.007456246447993972\n",
      "train loss:0.002102454995924716\n",
      "train loss:0.006036610427398797\n",
      "train loss:0.011091927034686993\n",
      "train loss:0.0007807941948432994\n",
      "train loss:0.001115967511888834\n",
      "train loss:0.004523102352155473\n",
      "train loss:0.0006944457648699759\n",
      "train loss:0.0020446315357866944\n",
      "train loss:0.008447612881860937\n",
      "train loss:0.01074159352487025\n",
      "train loss:0.0027380357973022782\n",
      "train loss:0.000992056989832739\n",
      "train loss:0.007528375797179712\n",
      "train loss:0.008275269090488762\n",
      "train loss:0.0007596243825637068\n",
      "train loss:0.00925439920513807\n",
      "train loss:0.005411693092099592\n",
      "train loss:0.005960707514284015\n",
      "train loss:0.00030865515556392705\n",
      "train loss:0.002854671788429024\n",
      "train loss:0.005274373791250947\n",
      "train loss:0.0008199157864488076\n",
      "train loss:0.0016976921047573293\n",
      "train loss:0.0009576744286651418\n",
      "train loss:0.0076532228929354455\n",
      "train loss:0.02189538268128653\n",
      "train loss:0.0007275703666759926\n",
      "train loss:0.0004792479860061135\n",
      "train loss:0.008491603262369665\n",
      "train loss:0.013800596618175748\n",
      "train loss:0.0031642054308163832\n",
      "train loss:0.00752607679965652\n",
      "train loss:0.003931270948093964\n",
      "train loss:0.001531354217438282\n",
      "train loss:0.024217628730177125\n",
      "train loss:0.008530536234470445\n",
      "train loss:0.0010784619134309142\n",
      "train loss:0.005372621427402234\n",
      "train loss:0.001036774779603194\n",
      "train loss:0.0022522351728375633\n",
      "train loss:0.0005275809478245311\n",
      "train loss:0.0055497991277766116\n",
      "train loss:0.0018997629121619577\n",
      "train loss:0.001558051204169784\n",
      "train loss:0.019474947596553164\n",
      "train loss:0.008704480007024033\n",
      "train loss:0.004344324001869534\n",
      "train loss:0.004104827320149845\n",
      "train loss:0.0562443597242069\n",
      "train loss:0.0010124859904838796\n",
      "train loss:0.0019655513259789602\n",
      "train loss:0.002401284569090936\n",
      "train loss:0.0006721404823556049\n",
      "train loss:0.00818959161801061\n",
      "train loss:0.006453923748833027\n",
      "train loss:0.008272622856415456\n",
      "train loss:0.002795707421554378\n",
      "train loss:0.004082710691285943\n",
      "train loss:0.009397668239230595\n",
      "train loss:0.0022785184026815754\n",
      "train loss:0.007957034970328382\n",
      "train loss:0.004203297120141851\n",
      "train loss:0.008461388524618862\n",
      "train loss:0.021978369047985936\n",
      "train loss:0.0011145021393765351\n",
      "train loss:0.0011143961241050191\n",
      "train loss:0.0011354842583893464\n",
      "train loss:0.0038106994291763024\n",
      "train loss:0.003384533865007659\n",
      "train loss:0.0003952610797872407\n",
      "train loss:0.004120784649053956\n",
      "train loss:0.002614952719734055\n",
      "train loss:0.0014061831035224862\n",
      "train loss:0.0011532642398340228\n",
      "train loss:0.004542104005366541\n",
      "train loss:0.0036726377014961765\n",
      "train loss:0.005683509792652403\n",
      "train loss:0.0011757611229008683\n",
      "train loss:0.0037860708950999337\n",
      "train loss:0.0022921576766497375\n",
      "train loss:0.003283873985794589\n",
      "train loss:0.0021513393096430798\n",
      "train loss:0.025848928130959195\n",
      "train loss:0.001223649137407733\n",
      "train loss:0.006730408770441229\n",
      "train loss:0.017810441428961547\n",
      "train loss:0.003672584470021561\n",
      "train loss:0.00046884224034464086\n",
      "train loss:0.0014108941917515795\n",
      "train loss:0.0005774628132981063\n",
      "train loss:0.004837431367694622\n",
      "train loss:0.0014654034382594727\n",
      "train loss:0.0006155484519399914\n",
      "train loss:0.0032702616295967814\n",
      "train loss:0.005119779609893985\n",
      "train loss:0.001456597792011859\n",
      "train loss:0.0001065504337162346\n",
      "train loss:0.005697987047738586\n",
      "train loss:0.0005762173886767757\n",
      "train loss:0.0002870130821216881\n",
      "train loss:0.005849649796555905\n",
      "train loss:0.002603361482901222\n",
      "train loss:0.0033816698159643004\n",
      "train loss:0.001557427187539977\n",
      "train loss:0.008755563928745968\n",
      "train loss:0.0016742675415057542\n",
      "train loss:0.0004068608803336366\n",
      "train loss:0.0036682681415228895\n",
      "train loss:0.009708356197437332\n",
      "train loss:0.0004971932935137446\n",
      "train loss:0.0060548233835776115\n",
      "train loss:0.00048252059897518765\n",
      "train loss:0.001843540519954065\n",
      "train loss:0.0029318836643935815\n",
      "train loss:0.00521617819860965\n",
      "train loss:0.005093750717556474\n",
      "train loss:0.00027229564511336375\n",
      "train loss:0.000222520206926312\n",
      "train loss:0.0002942147649041819\n",
      "train loss:0.00824664884176213\n",
      "train loss:0.0008156218513414386\n",
      "train loss:0.000804834922538646\n",
      "train loss:0.0005765224709934344\n",
      "train loss:0.0004138817502380075\n",
      "train loss:0.0003832711553176688\n",
      "train loss:0.0006865994371777058\n",
      "train loss:0.006787792529844749\n",
      "train loss:0.0004339480570817042\n",
      "train loss:0.0027297289385383085\n",
      "train loss:0.0076194327296982165\n",
      "train loss:0.0005435777123572326\n",
      "train loss:0.0015797569696248655\n",
      "train loss:0.006508510908996689\n",
      "train loss:0.002892217791245332\n",
      "train loss:0.0069277821822837544\n",
      "train loss:0.004448843000775889\n",
      "train loss:0.0020386437667111908\n",
      "train loss:0.0034999608857148577\n",
      "train loss:0.00014583319576133468\n",
      "train loss:0.00445821900699531\n",
      "train loss:0.0001976066121537825\n",
      "train loss:0.003004124096480985\n",
      "train loss:0.005153990954924987\n",
      "train loss:0.004212724826759165\n",
      "train loss:0.001827167976829497\n",
      "train loss:0.01853099853913687\n",
      "train loss:0.0060972985731260155\n",
      "train loss:0.004361323213641874\n",
      "train loss:0.002423969192725961\n",
      "train loss:0.004601483050479099\n",
      "train loss:0.00026877994029425817\n",
      "train loss:0.0026306111680524584\n",
      "train loss:0.004709663927750879\n",
      "train loss:0.007853856307237256\n",
      "train loss:0.0030184277403736866\n",
      "train loss:0.0006160941132335435\n",
      "train loss:0.002289368369306352\n",
      "train loss:0.00037290881223453573\n",
      "train loss:0.010714063141303217\n",
      "train loss:0.016332144329444406\n",
      "train loss:0.001752678947314531\n",
      "train loss:0.0004025672851684293\n",
      "train loss:0.00817711659711478\n",
      "train loss:0.005225436020533595\n",
      "train loss:0.004827258804139367\n",
      "train loss:0.002137265828835476\n",
      "train loss:0.0027968241319638516\n",
      "train loss:0.010774365444886864\n",
      "train loss:0.010335000553027152\n",
      "train loss:0.0038194122187829526\n",
      "train loss:0.00024369957938597697\n",
      "train loss:0.0020360740420601957\n",
      "train loss:0.01617729028928775\n",
      "train loss:0.005598373251084188\n",
      "train loss:0.006523353735126577\n",
      "train loss:0.0016490616151970566\n",
      "train loss:0.004587776252683257\n",
      "train loss:0.004204925080658921\n",
      "train loss:0.01992443236931246\n",
      "train loss:0.001743476013912293\n",
      "train loss:0.006482856491730266\n",
      "train loss:0.001091070215354655\n",
      "train loss:0.00017769406085584166\n",
      "train loss:0.0007753951478131437\n",
      "train loss:0.003016032468454679\n",
      "train loss:0.006405823637614633\n",
      "train loss:6.470668574460937e-05\n",
      "train loss:0.0044339321904419285\n",
      "train loss:0.0014414915584774687\n",
      "train loss:0.012190690699670333\n",
      "train loss:0.0033275016578580507\n",
      "train loss:0.00010730710006605376\n",
      "train loss:0.0011153223051983613\n",
      "train loss:0.003888964892790642\n",
      "train loss:0.00666376152305918\n",
      "train loss:0.0015536883802978194\n",
      "train loss:0.002625172648422414\n",
      "train loss:0.000539955119997002\n",
      "train loss:0.0034222581022935682\n",
      "train loss:0.002490339031130733\n",
      "train loss:0.004864452776869593\n",
      "train loss:0.0025201616745912573\n",
      "train loss:0.0013591632648202972\n",
      "train loss:0.004280282919909612\n",
      "train loss:0.0045522308943376074\n",
      "train loss:0.011344959138563015\n",
      "train loss:0.0004864098299123181\n",
      "train loss:0.00541129345305758\n",
      "train loss:0.003350443034107691\n",
      "train loss:0.01408806425559499\n",
      "train loss:0.0013146969786314694\n",
      "train loss:0.01928981892192408\n",
      "train loss:0.005816071087634739\n",
      "train loss:0.0012996241056748294\n",
      "train loss:0.0006908025381777577\n",
      "train loss:0.0027851660102538793\n",
      "train loss:0.0022270414362301405\n",
      "train loss:0.006927617581078798\n",
      "train loss:0.0020025852798368003\n",
      "train loss:0.004690514483884112\n",
      "train loss:0.0020406086548718848\n",
      "train loss:0.0033694253439034653\n",
      "train loss:0.010808710166998541\n",
      "train loss:0.00570276283383704\n",
      "train loss:0.0022818201318229713\n",
      "train loss:0.0027094786129103748\n",
      "train loss:0.0033836839658166196\n",
      "train loss:0.006246867029759318\n",
      "train loss:0.00028995615139564793\n",
      "train loss:0.0018190394160123042\n",
      "train loss:0.010891411881608947\n",
      "train loss:0.008794598818192091\n",
      "train loss:0.0009836598420477224\n",
      "train loss:0.001051734923569122\n",
      "train loss:0.0025559113289244516\n",
      "train loss:0.007007566678034339\n",
      "=== epoch:13, train acc:0.994, test acc:0.983 ===\n",
      "train loss:0.0009663443061286329\n",
      "train loss:0.005202223184999635\n",
      "train loss:0.00029650253313547617\n",
      "train loss:0.0006871157308573912\n",
      "train loss:0.0024026523273960954\n",
      "train loss:0.008532758422720605\n",
      "train loss:0.002811457398798941\n",
      "train loss:0.0012530571132783638\n",
      "train loss:0.0007878288046435422\n",
      "train loss:0.0008045567987003693\n",
      "train loss:0.00484916318682203\n",
      "train loss:0.000295107398487841\n",
      "train loss:0.0016752732838971442\n",
      "train loss:0.004917819683917271\n",
      "train loss:0.0016377538450176579\n",
      "train loss:0.003479482824308452\n",
      "train loss:0.00047210300380249237\n",
      "train loss:0.026454754483719024\n",
      "train loss:0.0017283170786749518\n",
      "train loss:0.002950226508517108\n",
      "train loss:0.0037911981887751023\n",
      "train loss:0.0011651038748044444\n",
      "train loss:0.019051861701714523\n",
      "train loss:0.009713597408142783\n",
      "train loss:0.011154948532185929\n",
      "train loss:0.0007328943230708587\n",
      "train loss:0.0006795126986952446\n",
      "train loss:0.013803566856877397\n",
      "train loss:0.010800428991042972\n",
      "train loss:0.003053851584928419\n",
      "train loss:0.0031576886080521283\n",
      "train loss:0.009710082207566783\n",
      "train loss:0.01810903313785649\n",
      "train loss:0.0044012152506219815\n",
      "train loss:0.03705065792460851\n",
      "train loss:0.0010071025284560972\n",
      "train loss:0.010882930557408627\n",
      "train loss:0.002837835394818159\n",
      "train loss:0.006619549717955039\n",
      "train loss:0.003910138655397472\n",
      "train loss:0.00035856430574388455\n",
      "train loss:0.002897580070103561\n",
      "train loss:0.007373545075077806\n",
      "train loss:0.004164261248031438\n",
      "train loss:0.0040900010587199545\n",
      "train loss:0.00031484321893674664\n",
      "train loss:0.0015905583027293032\n",
      "train loss:0.009278667140218357\n",
      "train loss:0.0005243553701461313\n",
      "train loss:0.0008847783954679434\n",
      "train loss:0.0029518819011205236\n",
      "train loss:0.02691570921689519\n",
      "train loss:0.0009806576234574612\n",
      "train loss:0.0035267327431214063\n",
      "train loss:0.004913556745626898\n",
      "train loss:0.0006499440039013599\n",
      "train loss:0.0002593466399986075\n",
      "train loss:0.003890633162903314\n",
      "train loss:0.0007545613916653833\n",
      "train loss:0.0006331338862570684\n",
      "train loss:0.003558073337597536\n",
      "train loss:0.0016065388321053486\n",
      "train loss:0.005733052132399198\n",
      "train loss:0.0031668867024611707\n",
      "train loss:0.00014459989026988502\n",
      "train loss:0.0014448891138500038\n",
      "train loss:0.001222345643612166\n",
      "train loss:0.011775153029709644\n",
      "train loss:0.003702020145475687\n",
      "train loss:4.278069246897202e-05\n",
      "train loss:0.0029853489319403444\n",
      "train loss:0.00234143362701302\n",
      "train loss:0.001119488566057839\n",
      "train loss:0.007853063358352532\n",
      "train loss:0.002421220478091939\n",
      "train loss:0.010524337054173985\n",
      "train loss:0.002200040781693644\n",
      "train loss:0.008519058751952269\n",
      "train loss:0.001224718720489128\n",
      "train loss:0.0003393814208245693\n",
      "train loss:0.004700693381208024\n",
      "train loss:0.003416653564180769\n",
      "train loss:0.02141229744018537\n",
      "train loss:0.012961345364848076\n",
      "train loss:0.010119369501079554\n",
      "train loss:0.002438832170066225\n",
      "train loss:0.0014452909990851645\n",
      "train loss:0.0015162758824423925\n",
      "train loss:0.010687523797082557\n",
      "train loss:0.002212340127685623\n",
      "train loss:0.005175273513365274\n",
      "train loss:0.004761423154642642\n",
      "train loss:0.0009487820153965707\n",
      "train loss:0.0016905249018567966\n",
      "train loss:0.006735891447885089\n",
      "train loss:0.007872591629974245\n",
      "train loss:0.0010941991392352328\n",
      "train loss:0.0007012013457650196\n",
      "train loss:0.008470623486525393\n",
      "train loss:0.041691747291344984\n",
      "train loss:0.03136558744958132\n",
      "train loss:0.00023680414324169953\n",
      "train loss:0.000103627792990026\n",
      "train loss:0.007354091279034121\n",
      "train loss:0.014279600613879955\n",
      "train loss:0.0031211202778252756\n",
      "train loss:0.0011202042294887716\n",
      "train loss:0.00018661533936003183\n",
      "train loss:0.005114543607216942\n",
      "train loss:0.0009888858140281514\n",
      "train loss:0.004646697404332838\n",
      "train loss:0.003233311601702987\n",
      "train loss:0.005314395062936752\n",
      "train loss:0.0010258352478010027\n",
      "train loss:0.005270600173685502\n",
      "train loss:0.006484215821284885\n",
      "train loss:0.0034091468255607825\n",
      "train loss:0.005355075737402528\n",
      "train loss:0.0009622897566301149\n",
      "train loss:0.00612114159493382\n",
      "train loss:0.00578219543054103\n",
      "train loss:0.0034387583879689483\n",
      "train loss:0.00372463465219696\n",
      "train loss:0.0003607155046262169\n",
      "train loss:0.004207328149985513\n",
      "train loss:0.012566886357054623\n",
      "train loss:0.002844204434037095\n",
      "train loss:0.006531885867994681\n",
      "train loss:0.0009455826093713837\n",
      "train loss:0.003373523817259646\n",
      "train loss:0.01566810826439126\n",
      "train loss:0.0030060929737762737\n",
      "train loss:0.013074303115285514\n",
      "train loss:0.003858266223398704\n",
      "train loss:0.008729030783970596\n",
      "train loss:0.001266398490294799\n",
      "train loss:0.0014449267811370806\n",
      "train loss:0.001226333939262286\n",
      "train loss:0.005136024021596346\n",
      "train loss:0.0029970986955170885\n",
      "train loss:0.009996637562531748\n",
      "train loss:0.016570075119134463\n",
      "train loss:0.007885261992335307\n",
      "train loss:0.0016038781939259625\n",
      "train loss:0.003351966820366309\n",
      "train loss:0.0029568301615874593\n",
      "train loss:0.001110962482610318\n",
      "train loss:0.001797946723915943\n",
      "train loss:0.0031883512873719707\n",
      "train loss:0.0022706592022858625\n",
      "train loss:0.004028071364778405\n",
      "train loss:0.0018169057973601488\n",
      "train loss:0.0012109590133506855\n",
      "train loss:0.0008919012427823948\n",
      "train loss:0.000647146705099611\n",
      "train loss:0.0036671623401801114\n",
      "train loss:0.000551982492508106\n",
      "train loss:0.004461399763492008\n",
      "train loss:0.0008664893286989468\n",
      "train loss:0.00027273803277525594\n",
      "train loss:0.0052705292466831725\n",
      "train loss:0.004338558325545132\n",
      "train loss:0.002220692934983965\n",
      "train loss:0.001405489956967944\n",
      "train loss:0.005007586872437682\n",
      "train loss:0.007774236817887419\n",
      "train loss:0.00280840293972885\n",
      "train loss:0.002367071890908952\n",
      "train loss:0.001962744958612841\n",
      "train loss:0.005095895870260352\n",
      "train loss:0.0010913363735327649\n",
      "train loss:0.0036363164162117965\n",
      "train loss:0.001048561758238397\n",
      "train loss:0.007415566324335539\n",
      "train loss:0.0014432173590025379\n",
      "train loss:0.00022691935654341238\n",
      "train loss:0.0023746630063646136\n",
      "train loss:0.0026960513752524963\n",
      "train loss:0.003456758016446357\n",
      "train loss:0.00132196829597685\n",
      "train loss:0.0009721799386059183\n",
      "train loss:0.0018140618597754135\n",
      "train loss:0.006372001718511445\n",
      "train loss:0.0008791196079876688\n",
      "train loss:0.004407436908289664\n",
      "train loss:0.004966808500582374\n",
      "train loss:0.0034270565370801997\n",
      "train loss:0.000453642900365731\n",
      "train loss:0.004705915259478917\n",
      "train loss:0.0015385618998553059\n",
      "train loss:0.0002484980625194423\n",
      "train loss:0.0010467568236198475\n",
      "train loss:0.004477288624526511\n",
      "train loss:0.00033476295977906856\n",
      "train loss:0.00033237537016034415\n",
      "train loss:0.0015003910906755678\n",
      "train loss:0.00013195161210040568\n",
      "train loss:0.0029582683447078478\n",
      "train loss:0.0016439810872093702\n",
      "train loss:0.0008801405182074248\n",
      "train loss:0.001731648932302475\n",
      "train loss:0.0013626324621244783\n",
      "train loss:0.0013825470666463642\n",
      "train loss:0.00044554291452763884\n",
      "train loss:0.0014520022199103776\n",
      "train loss:0.0007762213334000631\n",
      "train loss:0.0027723946458087095\n",
      "train loss:0.006402947829487522\n",
      "train loss:0.001993639982265925\n",
      "train loss:0.002659986888208123\n",
      "train loss:0.0005268694859567241\n",
      "train loss:0.00053340791989973\n",
      "train loss:0.010633661898755349\n",
      "train loss:0.003688667845222537\n",
      "train loss:0.0007626837727774052\n",
      "train loss:0.0006734061819008783\n",
      "train loss:0.006254923296990476\n",
      "train loss:0.0001569259718303318\n",
      "train loss:0.00057312521344692\n",
      "train loss:0.001133551992226198\n",
      "train loss:0.000792270221726284\n",
      "train loss:0.007632786956242081\n",
      "train loss:0.001463684311686566\n",
      "train loss:0.006306705873450982\n",
      "train loss:0.002034800124803354\n",
      "train loss:0.00026703120081546906\n",
      "train loss:0.0009327291018014019\n",
      "train loss:0.0025962001064763055\n",
      "train loss:0.000538333944138259\n",
      "train loss:0.0036818308734551867\n",
      "train loss:0.0007772622117211485\n",
      "train loss:0.024323634444954573\n",
      "train loss:0.001441249474629465\n",
      "train loss:0.005619458544714033\n",
      "train loss:0.003290989099620245\n",
      "train loss:0.00011696955698094988\n",
      "train loss:0.00852522329655525\n",
      "train loss:0.0006322582502860107\n",
      "train loss:0.0077558866103271396\n",
      "train loss:0.0018648941253253683\n",
      "train loss:0.001525820255667781\n",
      "train loss:0.004132932570768784\n",
      "train loss:0.000783841191650892\n",
      "train loss:0.004098464923251739\n",
      "train loss:0.004647681771458496\n",
      "train loss:0.005541599365768856\n",
      "train loss:0.0015212392135330172\n",
      "train loss:0.0004506842661893464\n",
      "train loss:0.003853046620753719\n",
      "train loss:0.0016372867817489568\n",
      "train loss:0.0010453585708031909\n",
      "train loss:0.003322165635033218\n",
      "train loss:0.013511269880077205\n",
      "train loss:0.005674097310338637\n",
      "train loss:0.005027414641246422\n",
      "train loss:0.0007012949347459783\n",
      "train loss:0.005008315701386304\n",
      "train loss:0.0015641389759584777\n",
      "train loss:0.0023564885439855436\n",
      "train loss:5.946899040828312e-05\n",
      "train loss:8.433731003211026e-05\n",
      "train loss:0.0007164828773421251\n",
      "train loss:0.013308760559957146\n",
      "train loss:0.006062390926076661\n",
      "train loss:0.0016126306251406522\n",
      "train loss:0.03552678964419369\n",
      "train loss:0.0016827074212688318\n",
      "train loss:0.012335788096578326\n",
      "train loss:0.005247768721821694\n",
      "train loss:0.0033589417091054873\n",
      "train loss:0.0017034260692255223\n",
      "train loss:0.003920871019064044\n",
      "train loss:0.0015905060012574423\n",
      "train loss:0.00025544149284691104\n",
      "train loss:0.005342542334072836\n",
      "train loss:0.006279989615164977\n",
      "train loss:0.0025098413069703064\n",
      "train loss:0.0018779218074155585\n",
      "train loss:0.0009354625056888073\n",
      "train loss:0.0018900978375851287\n",
      "train loss:0.009768075298876478\n",
      "train loss:0.005341969112688822\n",
      "train loss:0.006715388711938287\n",
      "train loss:0.0009717207023429335\n",
      "train loss:0.0034072529119605964\n",
      "train loss:0.0013355789701324616\n",
      "train loss:0.0017990352023658388\n",
      "train loss:0.00330674967368362\n",
      "train loss:0.0006096087070806348\n",
      "train loss:0.0017470776189448683\n",
      "train loss:0.0009878133410063507\n",
      "train loss:0.0032642813885967992\n",
      "train loss:0.0003390189456330825\n",
      "train loss:0.0014806127582294099\n",
      "train loss:0.0004804488790170352\n",
      "train loss:0.0012864251467225138\n",
      "train loss:0.00294817548612459\n",
      "train loss:0.000644471670590738\n",
      "train loss:0.0022476898001546077\n",
      "train loss:0.019233316231758227\n",
      "train loss:0.005297820230255023\n",
      "train loss:0.00011066104159538423\n",
      "train loss:0.0011266917211106282\n",
      "train loss:0.000946729314936697\n",
      "train loss:0.0002562696953318366\n",
      "train loss:0.0011636026158355491\n",
      "train loss:0.00043052177918533307\n",
      "train loss:0.0024090936199812523\n",
      "train loss:0.00017465965952269367\n",
      "train loss:0.002492852175380112\n",
      "train loss:0.0037516749737558416\n",
      "train loss:0.000605939741995356\n",
      "train loss:0.0007424494825403268\n",
      "train loss:0.0017078113462432854\n",
      "train loss:0.0019072014614101213\n",
      "train loss:0.0044009405915129245\n",
      "train loss:0.0005166425025171643\n",
      "train loss:0.0017430876384685143\n",
      "train loss:0.0035719379223410146\n",
      "train loss:0.036117981991046856\n",
      "train loss:9.380012275081483e-05\n",
      "train loss:0.0016138327650775759\n",
      "train loss:0.0003010393740125779\n",
      "train loss:0.042152279693972415\n",
      "train loss:0.0006517887607134865\n",
      "train loss:0.025154312386594168\n",
      "train loss:0.008461481197679388\n",
      "train loss:0.004023113710978972\n",
      "train loss:0.006126856966738332\n",
      "train loss:0.0003218780534739952\n",
      "train loss:0.003940397221847258\n",
      "train loss:0.0013470279408529843\n",
      "train loss:0.0034141145309300523\n",
      "train loss:0.0008002834545571184\n",
      "train loss:0.0013248449481333773\n",
      "train loss:0.00034618259025731574\n",
      "train loss:0.0010892916721319367\n",
      "train loss:0.006337751230357713\n",
      "train loss:0.001104179267180612\n",
      "train loss:0.0009636953997208181\n",
      "train loss:0.009132812224266401\n",
      "train loss:0.010511640577387581\n",
      "train loss:0.0006925822640763273\n",
      "train loss:0.0019380857226012607\n",
      "train loss:0.001660924990231639\n",
      "train loss:0.0039282979178070915\n",
      "train loss:0.004389505469129326\n",
      "train loss:0.0009888470813204176\n",
      "train loss:0.0012623320099162396\n",
      "train loss:0.026917478050002934\n",
      "train loss:0.0008711195427921177\n",
      "train loss:0.011275073024034014\n",
      "train loss:0.018977472511895636\n",
      "train loss:0.00032943062310572925\n",
      "train loss:0.00577008920545236\n",
      "train loss:0.000688829973129346\n",
      "train loss:0.005725648586557719\n",
      "train loss:0.0012889338264419378\n",
      "train loss:0.00034575957900913584\n",
      "train loss:0.011863005674337962\n",
      "train loss:0.0028411638104315273\n",
      "train loss:0.003582145593188356\n",
      "train loss:0.0004216758756773308\n",
      "train loss:0.007083915470054727\n",
      "train loss:0.0006811646369513215\n",
      "train loss:0.004957180539999139\n",
      "train loss:0.00013952864956867528\n",
      "train loss:0.007541338670233866\n",
      "train loss:0.001371982324180227\n",
      "train loss:0.053461601602163095\n",
      "train loss:0.0005693667983289703\n",
      "train loss:0.006331115235084573\n",
      "train loss:0.001107589686889023\n",
      "train loss:0.0008088653133221484\n",
      "train loss:0.0520292268672285\n",
      "train loss:0.0028850526897948193\n",
      "train loss:0.0033661784276831793\n",
      "train loss:0.004214719113555169\n",
      "train loss:0.0436929013102906\n",
      "train loss:0.0015219843690766873\n",
      "train loss:0.0007781062945553539\n",
      "train loss:0.002477643125174204\n",
      "train loss:0.0013835484869891745\n",
      "train loss:0.00022472661850570996\n",
      "train loss:0.004284270335589013\n",
      "train loss:0.016280237832990704\n",
      "train loss:0.01255669209886819\n",
      "train loss:0.005605650510437122\n",
      "train loss:0.0010081479650068145\n",
      "train loss:0.0010356875883496244\n",
      "train loss:0.002467959587256435\n",
      "train loss:0.0038873856430263073\n",
      "train loss:0.0003457629648556603\n",
      "train loss:0.0012459824828012567\n",
      "train loss:0.005876167139074433\n",
      "train loss:0.007187515464760437\n",
      "train loss:0.0004437006383585447\n",
      "train loss:0.003215892259172396\n",
      "train loss:0.005049350807550741\n",
      "train loss:0.0039826748120971285\n",
      "train loss:0.005105914199458439\n",
      "train loss:0.0051284870174815676\n",
      "train loss:0.041387214711291836\n",
      "train loss:0.0006590214270865284\n",
      "train loss:0.004241961225358493\n",
      "train loss:0.0030933523415062657\n",
      "train loss:0.0008934352008386358\n",
      "train loss:0.0008894103725372561\n",
      "train loss:0.0016716062401627423\n",
      "train loss:0.0010713487581131289\n",
      "train loss:0.0028006768132478044\n",
      "train loss:0.002696882312387978\n",
      "train loss:0.010685326379692089\n",
      "train loss:0.0007728410797732538\n",
      "train loss:0.0014389915670846847\n",
      "train loss:0.0004136836116499485\n",
      "train loss:0.003422705577612365\n",
      "train loss:0.0002508411563958816\n",
      "train loss:0.0074675262738706635\n",
      "train loss:0.003037996977843306\n",
      "train loss:0.00040304926164299026\n",
      "train loss:0.018604785338049424\n",
      "train loss:0.005007220743493911\n",
      "train loss:0.0026399504592333495\n",
      "train loss:0.0012242365066313227\n",
      "train loss:0.027235253363043707\n",
      "train loss:0.004283092038410934\n",
      "train loss:0.0008333781501716998\n",
      "train loss:0.0012576478064400352\n",
      "train loss:0.0008483749169370164\n",
      "train loss:0.0007054419260805297\n",
      "train loss:0.005252768819676017\n",
      "train loss:0.00014827884201746552\n",
      "train loss:0.016352775607014192\n",
      "train loss:0.001077783293257013\n",
      "train loss:0.0013995080744501106\n",
      "train loss:0.005414761380856547\n",
      "train loss:0.0028539939998741643\n",
      "train loss:0.0011292661540482829\n",
      "train loss:0.003265241958230772\n",
      "train loss:0.005645361211768992\n",
      "train loss:0.002099162863240393\n",
      "train loss:0.0009727642835230577\n",
      "train loss:0.006295095595767801\n",
      "train loss:0.004181746832186782\n",
      "train loss:0.00035340167199303813\n",
      "train loss:0.003178933573830362\n",
      "train loss:0.013256847322740888\n",
      "train loss:0.0036310547113144794\n",
      "train loss:0.019935178292550388\n",
      "train loss:0.0025386126147059333\n",
      "train loss:0.0018825735307449055\n",
      "train loss:0.027431172050873795\n",
      "train loss:0.0005218643642804692\n",
      "train loss:0.002763380399105353\n",
      "train loss:0.0003014629554518254\n",
      "train loss:0.009480105896936073\n",
      "train loss:0.0021243415024911026\n",
      "train loss:0.0005481706563641083\n",
      "train loss:0.004878963440292947\n",
      "train loss:0.011845114568804414\n",
      "train loss:0.001547705767110038\n",
      "train loss:0.007040705767228483\n",
      "train loss:0.0007152423748291734\n",
      "train loss:0.008614422640619103\n",
      "train loss:0.007345826031079001\n",
      "train loss:0.007110426656365651\n",
      "train loss:0.00020999151557603665\n",
      "train loss:0.003096118488331128\n",
      "train loss:0.00044963010238655276\n",
      "train loss:0.002936337137443786\n",
      "train loss:0.0076121426409996714\n",
      "train loss:0.024269618672779106\n",
      "train loss:0.0006857188574870905\n",
      "train loss:0.0017858695220508403\n",
      "train loss:0.00011360195186114844\n",
      "train loss:0.001236403171782736\n",
      "train loss:0.0008185762602273476\n",
      "train loss:0.005417882392348257\n",
      "train loss:0.014352077116327532\n",
      "train loss:0.0007750677529098565\n",
      "train loss:0.002724614881053349\n",
      "train loss:0.004833230704426717\n",
      "train loss:0.0009574774286997936\n",
      "train loss:0.001074741190049433\n",
      "train loss:0.00014370697709154576\n",
      "train loss:0.007594784106219385\n",
      "train loss:0.0020369962722583596\n",
      "train loss:0.001294228168147915\n",
      "train loss:0.0031624072429975027\n",
      "train loss:0.003803133661316704\n",
      "train loss:0.013296759453863185\n",
      "train loss:0.0005469925914044633\n",
      "train loss:0.0024072878246872687\n",
      "train loss:0.002308510446095706\n",
      "train loss:0.007135833789014905\n",
      "train loss:0.002929941122408138\n",
      "train loss:0.0029639836357908673\n",
      "train loss:0.0012653461071684211\n",
      "train loss:0.002454840520888703\n",
      "train loss:0.00019978946664669779\n",
      "train loss:0.0006873008495849849\n",
      "train loss:0.00034315378745776\n",
      "train loss:0.0004554656876379274\n",
      "train loss:0.024985858824892317\n",
      "train loss:0.004496707547130701\n",
      "train loss:0.0011403703188449395\n",
      "train loss:0.005867129433145518\n",
      "train loss:0.005783062651156286\n",
      "train loss:0.0019425116471403464\n",
      "train loss:0.004602840563716653\n",
      "train loss:0.0018433979024856998\n",
      "train loss:0.001353068485768543\n",
      "train loss:0.0014751307269721342\n",
      "train loss:0.0003622440547321859\n",
      "train loss:0.003139108047805034\n",
      "train loss:0.00210941089655865\n",
      "train loss:0.0013878449019018814\n",
      "train loss:0.00038238491088077634\n",
      "train loss:0.0017807258629407286\n",
      "train loss:0.002317397925922097\n",
      "train loss:0.0012911577962436117\n",
      "train loss:0.00026013673044502077\n",
      "train loss:0.0004163648703181228\n",
      "train loss:0.0031240952578817736\n",
      "train loss:0.0059255348033232045\n",
      "train loss:0.041303760209362626\n",
      "train loss:0.006186431875229886\n",
      "train loss:0.0027016315902842337\n",
      "train loss:0.0010888427680266028\n",
      "train loss:0.002033718829648551\n",
      "train loss:0.0022960340319185175\n",
      "train loss:0.00042310640660398114\n",
      "train loss:0.0033168239314850523\n",
      "train loss:0.0021821657846003892\n",
      "train loss:0.003075498297990182\n",
      "train loss:0.001606002239998413\n",
      "train loss:0.0004416205714124161\n",
      "train loss:0.0006508511626411335\n",
      "train loss:0.001975724105602528\n",
      "train loss:0.015793820019532136\n",
      "train loss:0.0014145312999639765\n",
      "train loss:0.03002849664758503\n",
      "train loss:0.0042093581941306\n",
      "train loss:0.04814335673591264\n",
      "train loss:0.004215907363111421\n",
      "train loss:0.002305770133852755\n",
      "train loss:0.0027179253969298388\n",
      "train loss:0.008200247034372943\n",
      "train loss:0.0007042763051356455\n",
      "train loss:0.0011802240098054318\n",
      "train loss:0.003909903386693287\n",
      "train loss:0.02226895848818614\n",
      "train loss:0.001967654837325438\n",
      "train loss:0.012957666969759103\n",
      "train loss:0.006820114776612401\n",
      "train loss:0.004888741506787294\n",
      "train loss:0.00387665566565008\n",
      "train loss:0.029045959558503955\n",
      "train loss:0.015548043705668676\n",
      "train loss:0.001862008809041657\n",
      "train loss:0.0020572083151700225\n",
      "train loss:0.007330027340378369\n",
      "train loss:0.004316413507855364\n",
      "train loss:0.00020401722467415138\n",
      "train loss:0.00474928298324279\n",
      "train loss:0.009655308549705447\n",
      "train loss:0.009341891219108441\n",
      "train loss:0.004658519715463201\n",
      "train loss:0.0037307104923460146\n",
      "train loss:0.00155658413889368\n",
      "train loss:0.003571588997590162\n",
      "train loss:0.003890350504959364\n",
      "train loss:0.00326982769306294\n",
      "train loss:0.0024189038865945005\n",
      "train loss:0.000542084966085403\n",
      "train loss:0.005529722873064892\n",
      "train loss:0.0009944259756666746\n",
      "train loss:0.01023904966303824\n",
      "train loss:0.00350639616972694\n",
      "train loss:0.0004936224997387444\n",
      "train loss:0.0015831365105236253\n",
      "train loss:0.0017828385213126668\n",
      "train loss:0.001192500710464275\n",
      "train loss:0.01233445497899155\n",
      "train loss:0.005954479180786364\n",
      "train loss:0.002862784994395746\n",
      "train loss:0.001029153079272697\n",
      "train loss:0.002535056653214597\n",
      "train loss:0.006933231328230539\n",
      "train loss:0.0011009497204969027\n",
      "train loss:0.0040083987241643915\n",
      "train loss:0.0042195906708753115\n",
      "train loss:0.0011779611498366719\n",
      "train loss:0.001011922159561977\n",
      "train loss:0.00040373591717193726\n",
      "train loss:0.0015138866992154903\n",
      "train loss:0.002310957633051799\n",
      "train loss:0.0020794861467990974\n",
      "train loss:0.006460495021266197\n",
      "=== epoch:14, train acc:0.999, test acc:0.987 ===\n",
      "train loss:0.0016691863262883625\n",
      "train loss:0.002126082441526684\n",
      "train loss:0.00011823303822102197\n",
      "train loss:0.011403110160665884\n",
      "train loss:0.0014350353089443901\n",
      "train loss:0.0006900051167983137\n",
      "train loss:0.001444165297990254\n",
      "train loss:0.0007302686762923146\n",
      "train loss:0.0013926354224321124\n",
      "train loss:0.0009044879609556643\n",
      "train loss:0.013288813457135996\n",
      "train loss:0.0005499068271573018\n",
      "train loss:0.0008650985600444065\n",
      "train loss:0.0017642590400324843\n",
      "train loss:0.0019186266291875418\n",
      "train loss:0.0005892932987698342\n",
      "train loss:0.0001503297174558738\n",
      "train loss:0.000519509308370033\n",
      "train loss:0.0025179060253144258\n",
      "train loss:0.0005577011089591351\n",
      "train loss:0.000512265215566949\n",
      "train loss:0.0021903212414645813\n",
      "train loss:0.00303188337101081\n",
      "train loss:0.0038984536673015986\n",
      "train loss:0.00030558980844580096\n",
      "train loss:9.660904675453386e-05\n",
      "train loss:0.0012315812251940384\n",
      "train loss:0.0012379887460543275\n",
      "train loss:0.003898360354396764\n",
      "train loss:0.006269003649086902\n",
      "train loss:0.00014734996188399107\n",
      "train loss:0.0026517205633378753\n",
      "train loss:0.002384409669351309\n",
      "train loss:0.0018897853494859935\n",
      "train loss:0.0017883942190001691\n",
      "train loss:0.0036573206506355623\n",
      "train loss:0.0022150849583447998\n",
      "train loss:0.003264307122552122\n",
      "train loss:0.006377699432165474\n",
      "train loss:0.001082639812133844\n",
      "train loss:0.0023786371836753014\n",
      "train loss:0.0009693471894744227\n",
      "train loss:0.002098987178351704\n",
      "train loss:0.0003502728459382475\n",
      "train loss:0.0016807192835368943\n",
      "train loss:0.0005211542188670696\n",
      "train loss:0.000771820025656616\n",
      "train loss:0.0006742903049648498\n",
      "train loss:0.0009062327892729495\n",
      "train loss:0.0014854164085635363\n",
      "train loss:0.002216927810735663\n",
      "train loss:0.0006451475657109903\n",
      "train loss:0.009455428602568004\n",
      "train loss:0.005915643370266117\n",
      "train loss:0.0008219131257671953\n",
      "train loss:0.00125348467750485\n",
      "train loss:0.004712306264059513\n",
      "train loss:0.000833113875986525\n",
      "train loss:0.0005300436466940711\n",
      "train loss:0.00906997352050443\n",
      "train loss:0.00023963080333416843\n",
      "train loss:0.0007436993850882217\n",
      "train loss:0.0017543992553614033\n",
      "train loss:0.00023312784607531215\n",
      "train loss:0.00024132726023102336\n",
      "train loss:0.001469524553849617\n",
      "train loss:0.0021052050481634595\n",
      "train loss:0.0008450909033461472\n",
      "train loss:0.003388447374523521\n",
      "train loss:0.012076809620941747\n",
      "train loss:0.0029100661291319046\n",
      "train loss:0.0029356063017005806\n",
      "train loss:0.0006437379425267221\n",
      "train loss:0.003445997514241957\n",
      "train loss:0.001876561754653345\n",
      "train loss:0.00044311728901573927\n",
      "train loss:0.0009269108062880821\n",
      "train loss:0.021627298833295065\n",
      "train loss:0.009484080853666544\n",
      "train loss:0.00037705017467657873\n",
      "train loss:0.0014035787096770046\n",
      "train loss:0.0008605359034980145\n",
      "train loss:0.0015653409051740114\n",
      "train loss:0.0002539117954118803\n",
      "train loss:0.0007709057452071775\n",
      "train loss:0.0010584453618788104\n",
      "train loss:0.0010054519780400579\n",
      "train loss:0.002059960126083229\n",
      "train loss:0.0016819710841820229\n",
      "train loss:0.0007475674694654\n",
      "train loss:0.0019338295496524657\n",
      "train loss:0.004748060997378883\n",
      "train loss:0.001679769340616968\n",
      "train loss:0.010554333980934577\n",
      "train loss:0.003671733293352386\n",
      "train loss:6.207615689969631e-05\n",
      "train loss:0.0018561258759751881\n",
      "train loss:0.0073851706511691125\n",
      "train loss:0.00500717256837445\n",
      "train loss:0.0017688451315954626\n",
      "train loss:0.001631460492890528\n",
      "train loss:0.001230211321300017\n",
      "train loss:0.00037692398491740055\n",
      "train loss:0.00019271332674416114\n",
      "train loss:0.01012395996157508\n",
      "train loss:0.0010961093431413164\n",
      "train loss:0.00015371691594027374\n",
      "train loss:0.001261738768730961\n",
      "train loss:0.0012006534249916938\n",
      "train loss:0.0006553146325009246\n",
      "train loss:0.0015996438423859286\n",
      "train loss:0.0009642828476396321\n",
      "train loss:0.0006800995398508355\n",
      "train loss:0.0017803337214800275\n",
      "train loss:0.001588528742184756\n",
      "train loss:0.00479074992014908\n",
      "train loss:0.005088958975808034\n",
      "train loss:0.001314568817955274\n",
      "train loss:0.005113959566536181\n",
      "train loss:8.61896352648848e-05\n",
      "train loss:0.0033032836252864795\n",
      "train loss:0.0012446326099471098\n",
      "train loss:0.001429457273705998\n",
      "train loss:0.014027827559069282\n",
      "train loss:0.001557371639814455\n",
      "train loss:0.004813015282411593\n",
      "train loss:0.0012760261145008842\n",
      "train loss:0.0017412041175578576\n",
      "train loss:0.005080580913123882\n",
      "train loss:0.0015370208288211645\n",
      "train loss:0.0013386412664182577\n",
      "train loss:0.0009048895894989446\n",
      "train loss:0.0003889073953897976\n",
      "train loss:0.007672272259738906\n",
      "train loss:0.0012275843046865526\n",
      "train loss:0.003962382597479261\n",
      "train loss:0.0035274191507805334\n",
      "train loss:0.0008351363285209013\n",
      "train loss:0.0007375875424533604\n",
      "train loss:0.0027840572919263303\n",
      "train loss:0.0014512818699269246\n",
      "train loss:0.0019933011295974485\n",
      "train loss:0.001030170908996193\n",
      "train loss:0.006674425401480844\n",
      "train loss:0.0005233080753158477\n",
      "train loss:0.00029851326612070114\n",
      "train loss:0.00022601041094717225\n",
      "train loss:0.0010973510262084463\n",
      "train loss:0.001877030479228564\n",
      "train loss:0.0015272296117108041\n",
      "train loss:0.0007998605336850999\n",
      "train loss:0.00010623948754694552\n",
      "train loss:0.0005644221919302378\n",
      "train loss:0.0015314081408502266\n",
      "train loss:0.002864829997055017\n",
      "train loss:0.00014879663385597322\n",
      "train loss:0.0005095535373318963\n",
      "train loss:0.008109594811735083\n",
      "train loss:0.001656082830737334\n",
      "train loss:0.0003762302847667888\n",
      "train loss:0.0004133543503734815\n",
      "train loss:0.00015781578073486224\n",
      "train loss:0.008309361597739403\n",
      "train loss:0.007738226936478862\n",
      "train loss:0.0008987794989295014\n",
      "train loss:0.00048435566030413413\n",
      "train loss:0.00013991466186664143\n",
      "train loss:0.00013195546634271751\n",
      "train loss:0.022085260473623622\n",
      "train loss:0.0010851718761150622\n",
      "train loss:0.0020258623788739806\n",
      "train loss:0.003488535544623587\n",
      "train loss:0.00016248930523594585\n",
      "train loss:0.0009967799356950112\n",
      "train loss:0.0006493568666567307\n",
      "train loss:0.003755760462742875\n",
      "train loss:0.000485791316982876\n",
      "train loss:0.0037379307678820106\n",
      "train loss:0.011113214026906633\n",
      "train loss:0.000970837508766098\n",
      "train loss:0.00647371746046945\n",
      "train loss:0.0039134668631081075\n",
      "train loss:0.0035804056628879954\n",
      "train loss:0.0004676150332864828\n",
      "train loss:0.0022769763804672974\n",
      "train loss:0.005233230372372972\n",
      "train loss:0.0011675775780536207\n",
      "train loss:0.003296028035008934\n",
      "train loss:0.0015604943603424281\n",
      "train loss:0.00011553456800423948\n",
      "train loss:0.0018365624522633742\n",
      "train loss:0.0007438103073465098\n",
      "train loss:0.0004965220905227225\n",
      "train loss:0.0011026021687647134\n",
      "train loss:0.0030009596471891695\n",
      "train loss:0.003348586659514006\n",
      "train loss:0.004147184134716561\n",
      "train loss:0.006515067288078219\n",
      "train loss:0.001307018508204166\n",
      "train loss:0.0015652559563604554\n",
      "train loss:0.0002328058234385268\n",
      "train loss:0.0005379375106304757\n",
      "train loss:0.00030891510357966654\n",
      "train loss:0.0019055180045189576\n",
      "train loss:0.0006612200192841568\n",
      "train loss:0.0006032571795449281\n",
      "train loss:0.058274697485756866\n",
      "train loss:0.0008903181482544595\n",
      "train loss:0.0024541427478839183\n",
      "train loss:0.0017904390773421654\n",
      "train loss:0.0019147554039392475\n",
      "train loss:0.00018792315257359967\n",
      "train loss:0.0014141299905428867\n",
      "train loss:0.0035981541303063353\n",
      "train loss:0.0036865257045427292\n",
      "train loss:0.0007841390780702409\n",
      "train loss:0.0034265979941921865\n",
      "train loss:0.0010933881742359595\n",
      "train loss:0.0025896279351288153\n",
      "train loss:0.001614130437097187\n",
      "train loss:0.001420684886604108\n",
      "train loss:0.004047732962714549\n",
      "train loss:0.0012336947773235072\n",
      "train loss:0.0051113770456649174\n",
      "train loss:0.00012226469079799625\n",
      "train loss:0.01386256852669486\n",
      "train loss:0.004545051421751532\n",
      "train loss:0.0010970262198416265\n",
      "train loss:0.0012478727573764234\n",
      "train loss:0.00660183185927856\n",
      "train loss:0.0029173072941476473\n",
      "train loss:0.007105489110639705\n",
      "train loss:0.0005342509689648003\n",
      "train loss:0.0013811185345979607\n",
      "train loss:0.0038115825510400534\n",
      "train loss:0.011859908085432294\n",
      "train loss:0.0013003371988699255\n",
      "train loss:0.007093245502601527\n",
      "train loss:0.003895277450785315\n",
      "train loss:0.00015334766170202262\n",
      "train loss:0.0005750052198273736\n",
      "train loss:0.0018557910714922692\n",
      "train loss:0.004327742182392285\n",
      "train loss:0.002356029828531343\n",
      "train loss:0.0016045314397712717\n",
      "train loss:0.11256171391756667\n",
      "train loss:0.024110903680020522\n",
      "train loss:0.0010252240617310841\n",
      "train loss:0.002960270039914889\n",
      "train loss:0.0003575078059259433\n",
      "train loss:0.00024744993427455996\n",
      "train loss:0.006989292128874083\n",
      "train loss:0.0018487108223228495\n",
      "train loss:0.0002498037507996063\n",
      "train loss:0.0017271040863262568\n",
      "train loss:0.002416272198805302\n",
      "train loss:0.0016251500859959533\n",
      "train loss:0.0019812720866116402\n",
      "train loss:0.0011630150990429257\n",
      "train loss:0.0004527603949896603\n",
      "train loss:0.002468925425627837\n",
      "train loss:0.004927947315636614\n",
      "train loss:0.05777766777939494\n",
      "train loss:0.006009829681800745\n",
      "train loss:0.00044533926214028306\n",
      "train loss:0.0005776353540406314\n",
      "train loss:0.023637785920732846\n",
      "train loss:0.0007888718925330078\n",
      "train loss:0.002531295397838017\n",
      "train loss:0.00038711883050758766\n",
      "train loss:0.002043792361292988\n",
      "train loss:0.0038540902316682325\n",
      "train loss:0.00639835193542831\n",
      "train loss:0.0031063177928931656\n",
      "train loss:0.001293359551064322\n",
      "train loss:0.004115090501421836\n",
      "train loss:0.000992430548267425\n",
      "train loss:0.003937747635397368\n",
      "train loss:0.007198547172598971\n",
      "train loss:0.0002418048604960721\n",
      "train loss:0.0032530441237123755\n",
      "train loss:0.0002755768607021454\n",
      "train loss:0.006103326230693482\n",
      "train loss:0.0023905152212468587\n",
      "train loss:0.004423083124090888\n",
      "train loss:5.556514786813687e-05\n",
      "train loss:0.004156624284103089\n",
      "train loss:0.0011192087178206515\n",
      "train loss:0.0004244082939893429\n",
      "train loss:0.00013558167526985022\n",
      "train loss:0.0008616598782006378\n",
      "train loss:0.0008911123758719362\n",
      "train loss:0.010799021412473433\n",
      "train loss:0.0011496705851707395\n",
      "train loss:0.00035522487053507736\n",
      "train loss:0.0012061849938705405\n",
      "train loss:0.0023061388492531536\n",
      "train loss:0.014381711430026844\n",
      "train loss:0.003066700977475425\n",
      "train loss:0.0024091539301137415\n",
      "train loss:0.0022748843583413527\n",
      "train loss:0.018067358898723306\n",
      "train loss:0.0006204886686288224\n",
      "train loss:0.001241114410249529\n",
      "train loss:0.0019905284481911375\n",
      "train loss:0.002934014840007947\n",
      "train loss:0.0012532578113192997\n",
      "train loss:0.013557527975565318\n",
      "train loss:0.0004218284962538105\n",
      "train loss:0.0023727775142957787\n",
      "train loss:0.003967072016604703\n",
      "train loss:0.00019251534916173634\n",
      "train loss:0.001856122921042018\n",
      "train loss:0.0002551908488573383\n",
      "train loss:0.0027366798328271815\n",
      "train loss:0.0032955125927793044\n",
      "train loss:0.00016981092754536297\n",
      "train loss:0.000267780951134662\n",
      "train loss:0.008400217167969688\n",
      "train loss:0.0009892111632679751\n",
      "train loss:0.00046206285304289366\n",
      "train loss:0.0013837043378273225\n",
      "train loss:0.0013860337956395296\n",
      "train loss:0.002907261576875425\n",
      "train loss:0.003828867896146807\n",
      "train loss:0.002040535789077893\n",
      "train loss:0.002962971703435051\n",
      "train loss:0.0003340764026246473\n",
      "train loss:0.0069314979654836175\n",
      "train loss:0.00498527253064568\n",
      "train loss:0.002860423001362839\n",
      "train loss:0.0019341781278184391\n",
      "train loss:0.002682360808711915\n",
      "train loss:0.01087141152215442\n",
      "train loss:0.00022033601179508294\n",
      "train loss:0.013402680743303726\n",
      "train loss:0.0038383592041497184\n",
      "train loss:0.00379452176051519\n",
      "train loss:0.0022450473840275593\n",
      "train loss:0.016645855084674765\n",
      "train loss:0.0021080448626911662\n",
      "train loss:0.0065868009045595335\n",
      "train loss:0.0010043219336170728\n",
      "train loss:0.005569022579045779\n",
      "train loss:0.009108076521361542\n",
      "train loss:0.0087447928264076\n",
      "train loss:0.0027611446996216333\n",
      "train loss:0.002588939122513078\n",
      "train loss:0.000709733770027851\n",
      "train loss:0.0010005902633088697\n",
      "train loss:0.001549988629668936\n",
      "train loss:0.0004990703126476095\n",
      "train loss:0.0011855026862115678\n",
      "train loss:0.0026619649320628012\n",
      "train loss:0.0021910493020788568\n",
      "train loss:0.014209469564480912\n",
      "train loss:0.0073106856198817015\n",
      "train loss:0.008452888563533113\n",
      "train loss:0.0007183935072212781\n",
      "train loss:0.0006919915722548031\n",
      "train loss:0.0025288534929132065\n",
      "train loss:0.0001658382602448857\n",
      "train loss:0.0010832235590758422\n",
      "train loss:0.007073057685090894\n",
      "train loss:0.0017604013032162691\n",
      "train loss:0.0010557082755597242\n",
      "train loss:0.0022847323120163236\n",
      "train loss:0.0002921972091764094\n",
      "train loss:0.0015416535052537206\n",
      "train loss:0.006981052295591131\n",
      "train loss:0.0016381559000996561\n",
      "train loss:0.0003249912035395712\n",
      "train loss:0.0017066505266118046\n",
      "train loss:0.007652185490009516\n",
      "train loss:0.0015942688958691853\n",
      "train loss:0.00022382380960762958\n",
      "train loss:0.0001935003076369255\n",
      "train loss:0.07236237679885849\n",
      "train loss:0.001331142405087564\n",
      "train loss:0.0008453259792818766\n",
      "train loss:0.003395206890171994\n",
      "train loss:0.0010278812438536907\n",
      "train loss:0.00036237002896211324\n",
      "train loss:0.01853814768125535\n",
      "train loss:0.00761856392509248\n",
      "train loss:0.0009596523698072296\n",
      "train loss:0.0008501518941779452\n",
      "train loss:0.0017386311351845244\n",
      "train loss:0.001449496819506792\n",
      "train loss:0.0012454138460106158\n",
      "train loss:0.0006505588182855168\n",
      "train loss:0.006587570809218247\n",
      "train loss:0.0010298737642617391\n",
      "train loss:0.0772893001558233\n",
      "train loss:0.0022694285699633946\n",
      "train loss:0.0008543207438749158\n",
      "train loss:0.04659404267929562\n",
      "train loss:0.003231273720470581\n",
      "train loss:0.004194306085791532\n",
      "train loss:0.002341372291640359\n",
      "train loss:0.0007614917003753972\n",
      "train loss:0.0018580659479166212\n",
      "train loss:0.00021217768340449724\n",
      "train loss:0.0017483271225963984\n",
      "train loss:0.006858919572166016\n",
      "train loss:0.009046016821610986\n",
      "train loss:0.009181802467365911\n",
      "train loss:0.0013308373848112257\n",
      "train loss:0.002758356507727144\n",
      "train loss:0.0010287251860471563\n",
      "train loss:0.015564069107256938\n",
      "train loss:0.01590002990274228\n",
      "train loss:0.00041931270739194377\n",
      "train loss:0.002020901763549397\n",
      "train loss:0.004842172160574426\n",
      "train loss:0.004540182314969276\n",
      "train loss:0.0012852437734295165\n",
      "train loss:0.005401828514833098\n",
      "train loss:0.00047475348697416375\n",
      "train loss:0.0010773950563521828\n",
      "train loss:6.528700611636122e-05\n",
      "train loss:0.0006773342598835094\n",
      "train loss:0.0020541675042025534\n",
      "train loss:0.0006041223860953948\n",
      "train loss:0.0016529638622303467\n",
      "train loss:0.0028396129305711215\n",
      "train loss:0.0003404992782165521\n",
      "train loss:0.0007166463046348547\n",
      "train loss:0.0005282047229774666\n",
      "train loss:0.0016621913703483882\n",
      "train loss:0.003140143760514154\n",
      "train loss:0.00405727961064331\n",
      "train loss:0.0034431019199366265\n",
      "train loss:0.0020985143394768686\n",
      "train loss:0.004042558994444965\n",
      "train loss:0.00040889388377738663\n",
      "train loss:0.008088773485580871\n",
      "train loss:0.0012697053328498827\n",
      "train loss:0.0018398994751352737\n",
      "train loss:0.0026947966857653067\n",
      "train loss:0.04126518615256408\n",
      "train loss:0.0010264597675665131\n",
      "train loss:0.0003766939439000335\n",
      "train loss:0.0015983294110532942\n",
      "train loss:0.0035337910174494543\n",
      "train loss:0.0023124035912818653\n",
      "train loss:0.0001573847008157919\n",
      "train loss:0.0001472507690227704\n",
      "train loss:0.00023253650612139933\n",
      "train loss:0.001408247987905262\n",
      "train loss:0.007299002480354021\n",
      "train loss:0.00045261605863015344\n",
      "train loss:0.0010990787799534164\n",
      "train loss:0.0019027434957110156\n",
      "train loss:0.0027483790144582666\n",
      "train loss:0.001007435863939713\n",
      "train loss:0.0066152324441803665\n",
      "train loss:0.0004229440279479383\n",
      "train loss:0.0004387130748669964\n",
      "train loss:0.000789278130545376\n",
      "train loss:0.0006751217748074049\n",
      "train loss:0.0027663097784129537\n",
      "train loss:0.0005360488629172011\n",
      "train loss:0.0007010110537595686\n",
      "train loss:0.004635199740860137\n",
      "train loss:0.005713742480086346\n",
      "train loss:0.0015821771341229863\n",
      "train loss:0.0020290525518114303\n",
      "train loss:5.535195508164319e-05\n",
      "train loss:0.000876515775180143\n",
      "train loss:0.002878810077070139\n",
      "train loss:0.001117355752476853\n",
      "train loss:0.006328967529135757\n",
      "train loss:0.00018726781293834676\n",
      "train loss:0.003540765097200953\n",
      "train loss:0.00019515205884545518\n",
      "train loss:0.00214913543396321\n",
      "train loss:0.0012128683681469795\n",
      "train loss:0.0001302849409887788\n",
      "train loss:0.009192276293480933\n",
      "train loss:0.0017475212808216246\n",
      "train loss:0.0015004781017956788\n",
      "train loss:0.004124158196313698\n",
      "train loss:0.0046567603115958865\n",
      "train loss:0.0022128366417723043\n",
      "train loss:0.0047726706106765646\n",
      "train loss:0.0022329830881508543\n",
      "train loss:0.0028805702421941803\n",
      "train loss:0.002537106007027824\n",
      "train loss:0.0015336642589875548\n",
      "train loss:0.003962128144535973\n",
      "train loss:0.0052965785019492215\n",
      "train loss:0.0034633989575922237\n",
      "train loss:0.0008855635948314567\n",
      "train loss:0.0011046029737401806\n",
      "train loss:0.013691702240407057\n",
      "train loss:0.0025089374122831422\n",
      "train loss:0.0033063731789217915\n",
      "train loss:0.002108639018537377\n",
      "train loss:0.0003182859257464684\n",
      "train loss:0.0022184318279809627\n",
      "train loss:0.003160130481958206\n",
      "train loss:0.004545549413824326\n",
      "train loss:0.0003367107094751855\n",
      "train loss:0.0015710277345121896\n",
      "train loss:0.0009383155986473869\n",
      "train loss:0.0028878808590623744\n",
      "train loss:0.0012171497276820742\n",
      "train loss:0.0006647257371020723\n",
      "train loss:0.0003714976028923914\n",
      "train loss:0.00043858462373224576\n",
      "train loss:0.0024078496892110794\n",
      "train loss:0.0012866090264943022\n",
      "train loss:0.002565220386652212\n",
      "train loss:0.004397257057371431\n",
      "train loss:0.003044383372562994\n",
      "train loss:0.004439463503870353\n",
      "train loss:0.0023020950795065594\n",
      "train loss:0.004874641730338598\n",
      "train loss:0.0005166235159181816\n",
      "train loss:0.0015861857974445585\n",
      "train loss:0.007104350539885396\n",
      "train loss:0.02537012069279334\n",
      "train loss:0.002701466593818746\n",
      "train loss:0.0012609021814887899\n",
      "train loss:0.0003302595195904287\n",
      "train loss:0.0004392173880235851\n",
      "train loss:0.0007376768854818986\n",
      "train loss:0.004402008882237341\n",
      "train loss:0.0014787773271483099\n",
      "train loss:0.0034049749625941024\n",
      "train loss:0.0015167621062259406\n",
      "train loss:0.0003718820163322762\n",
      "train loss:0.001619458911187299\n",
      "train loss:0.0016558131774161396\n",
      "train loss:0.0029621960922914248\n",
      "train loss:0.0029163611751881085\n",
      "train loss:0.004577259844976788\n",
      "train loss:0.0017605028773895546\n",
      "train loss:0.0017895539302711216\n",
      "train loss:0.002968361726352983\n",
      "train loss:0.0036346756610942145\n",
      "train loss:0.00020405633451625073\n",
      "train loss:0.00040323140948259013\n",
      "train loss:0.0007067083470120439\n",
      "train loss:0.004382501737058984\n",
      "train loss:0.019758029407015754\n",
      "train loss:0.0015455873761084894\n",
      "train loss:0.0006120392051225524\n",
      "train loss:0.0015114843897951436\n",
      "train loss:0.002447632861414799\n",
      "train loss:0.0002882051019531139\n",
      "train loss:0.0021945678929801878\n",
      "train loss:0.0023040710981424954\n",
      "train loss:0.00175180237102037\n",
      "train loss:0.0013195790856589992\n",
      "train loss:0.0018594972750778144\n",
      "train loss:0.00024101541675461576\n",
      "train loss:0.00034466298771575324\n",
      "train loss:0.002230970817748982\n",
      "train loss:0.0006170854794836145\n",
      "train loss:0.002301778974652587\n",
      "train loss:0.0003895074264482228\n",
      "train loss:0.008477974403289965\n",
      "train loss:0.0001042631317682964\n",
      "train loss:0.0020828227231073576\n",
      "train loss:0.0014916760365736713\n",
      "train loss:0.01418700602574161\n",
      "train loss:0.002364400062121015\n",
      "train loss:8.516547878355504e-05\n",
      "train loss:0.0031753487617446523\n",
      "train loss:0.004924778745078651\n",
      "train loss:0.0025128535492138617\n",
      "train loss:0.0007829706728475952\n",
      "train loss:0.00021255340462787855\n",
      "train loss:0.0005764532023128946\n",
      "train loss:0.022748029762072318\n",
      "train loss:0.00037599930819211534\n",
      "train loss:0.0010971058387346739\n",
      "train loss:0.0011939774815111224\n",
      "train loss:0.010633638161355192\n",
      "train loss:0.000497031879065815\n",
      "train loss:0.0024243578118983635\n",
      "train loss:0.004832583318335419\n",
      "train loss:0.000328303724131246\n",
      "train loss:0.0034283996402704685\n",
      "train loss:0.005025024426013571\n",
      "train loss:0.006134722336272503\n",
      "train loss:0.01018461133369999\n",
      "train loss:0.0012894770674993755\n",
      "train loss:0.00111606667351129\n",
      "train loss:0.0019992416744453456\n",
      "train loss:0.0013887815816854517\n",
      "train loss:0.000166581585753128\n",
      "train loss:0.00205462705136025\n",
      "train loss:0.0004807707959736222\n",
      "train loss:0.0007512798306724782\n",
      "train loss:0.0004185107723978308\n",
      "train loss:0.0006101981288632372\n",
      "train loss:0.00014058762565410555\n",
      "=== epoch:15, train acc:0.998, test acc:0.989 ===\n",
      "train loss:0.007173305653082777\n",
      "train loss:0.0015117611584799817\n",
      "train loss:0.002551417614684623\n",
      "train loss:0.0017593551383711453\n",
      "train loss:0.006685370641224077\n",
      "train loss:0.0020761133057657115\n",
      "train loss:0.0006858869772528176\n",
      "train loss:0.0042102039585530035\n",
      "train loss:0.0012210942991290328\n",
      "train loss:0.0012626632821428133\n",
      "train loss:0.00045585947097446453\n",
      "train loss:0.0020978532368014363\n",
      "train loss:0.004323063539228882\n",
      "train loss:0.0011921794202162394\n",
      "train loss:0.0014481696524016486\n",
      "train loss:0.00010034576880830982\n",
      "train loss:0.0032027754751147593\n",
      "train loss:0.0003605030158807656\n",
      "train loss:0.0004956591742009543\n",
      "train loss:6.112129745848578e-05\n",
      "train loss:0.0013041563756439867\n",
      "train loss:0.0008509719034629621\n",
      "train loss:0.0024802766880632717\n",
      "train loss:0.0025581137482704034\n",
      "train loss:0.0002932831979175494\n",
      "train loss:0.0037391985173939766\n",
      "train loss:2.0060896515108984e-05\n",
      "train loss:0.0018400085307616603\n",
      "train loss:0.001899187786537334\n",
      "train loss:0.0008067147171030893\n",
      "train loss:0.0007468288175019631\n",
      "train loss:0.006439797391644947\n",
      "train loss:0.0012597846856048892\n",
      "train loss:0.0006791991539212785\n",
      "train loss:0.00015041463829590658\n",
      "train loss:0.0012203863769235264\n",
      "train loss:0.0019677509647058346\n",
      "train loss:0.0002886427054046854\n",
      "train loss:0.004081390461374429\n",
      "train loss:0.001431509092516909\n",
      "train loss:0.0015751639500358385\n",
      "train loss:0.0013799549071944717\n",
      "train loss:0.002237768097410957\n",
      "train loss:0.001471285567680749\n",
      "train loss:0.0008233333954166653\n",
      "train loss:0.0019439299161516635\n",
      "train loss:0.0006401622174140551\n",
      "train loss:0.002800085240986723\n",
      "train loss:0.00044494591421190006\n",
      "train loss:0.0034554890798475474\n",
      "train loss:0.003340736147061078\n",
      "train loss:0.0003059039909953655\n",
      "train loss:0.0026205726293200733\n",
      "train loss:0.0006666613239352804\n",
      "train loss:0.0008302890554006928\n",
      "train loss:0.0004103572747815875\n",
      "train loss:0.002496298057905913\n",
      "train loss:0.0002231139551882451\n",
      "train loss:0.0017630015586551937\n",
      "train loss:0.00022685946241893676\n",
      "train loss:0.0005215775778358095\n",
      "train loss:0.0009791119601862755\n",
      "train loss:0.00038936329207193325\n",
      "train loss:0.0019930483997408553\n",
      "train loss:0.0020788275006060008\n",
      "train loss:0.0015631038175215376\n",
      "train loss:0.00035262187401390943\n",
      "train loss:0.00016184108931322562\n",
      "train loss:0.0006376329712103019\n",
      "train loss:0.0007174541324219562\n",
      "train loss:0.0016178545939265663\n",
      "train loss:0.0024734317835258977\n",
      "train loss:0.00014953587808088875\n",
      "train loss:0.0031885107648314875\n",
      "train loss:0.001100361150637213\n",
      "train loss:0.00010588149282919264\n",
      "train loss:0.0021681675977818313\n",
      "train loss:0.0010701081747298198\n",
      "train loss:0.0004455243662042456\n",
      "train loss:0.0004908976100059668\n",
      "train loss:0.0031444712551583548\n",
      "train loss:0.003295950763126932\n",
      "train loss:0.001329877316600345\n",
      "train loss:0.0002519040715939075\n",
      "train loss:0.0002008464186721381\n",
      "train loss:0.0010051989012103961\n",
      "train loss:0.004938011086888156\n",
      "train loss:0.000685858122140065\n",
      "train loss:0.00010490280252713962\n",
      "train loss:0.0006152249519125894\n",
      "train loss:0.0004762773879569185\n",
      "train loss:0.0005328013459611614\n",
      "train loss:8.313778441734954e-05\n",
      "train loss:0.00040485433095678277\n",
      "train loss:0.0006908623774858159\n",
      "train loss:0.0009222659993087792\n",
      "train loss:0.0003215280800385639\n",
      "train loss:0.00029830345897850996\n",
      "train loss:0.00015334153040548777\n",
      "train loss:0.0018332377867815316\n",
      "train loss:0.0015877143165086735\n",
      "train loss:0.000621126467723341\n",
      "train loss:0.0011781089183562745\n",
      "train loss:0.0028570356663308854\n",
      "train loss:0.0001671524280008172\n",
      "train loss:0.00044490901316640086\n",
      "train loss:0.0021348327854790235\n",
      "train loss:0.001702504670308817\n",
      "train loss:0.11915017513228619\n",
      "train loss:0.007223733541318785\n",
      "train loss:0.0017134021807591764\n",
      "train loss:0.0008436859185046029\n",
      "train loss:0.0013766321258776653\n",
      "train loss:0.008808595055425018\n",
      "train loss:0.022897957102154084\n",
      "train loss:0.0019034539064272066\n",
      "train loss:0.0025165953195729167\n",
      "train loss:0.004566861306206419\n",
      "train loss:0.00044918582951853075\n",
      "train loss:0.0026881687954282405\n",
      "train loss:0.0018559545698795742\n",
      "train loss:0.0037644015043872985\n",
      "train loss:0.0015874713742554413\n",
      "train loss:0.0012223524235435211\n",
      "train loss:0.0026147574325147164\n",
      "train loss:0.0008231538886856677\n",
      "train loss:0.006297509227710796\n",
      "train loss:0.0006332668065711991\n",
      "train loss:0.0011957053319861248\n",
      "train loss:0.01950170973679467\n",
      "train loss:0.000647102485129119\n",
      "train loss:0.0012346370904324452\n",
      "train loss:0.004680170043764516\n",
      "train loss:0.003620321389365793\n",
      "train loss:0.00030447348306056115\n",
      "train loss:0.0009653307486071861\n",
      "train loss:0.0012616290361475988\n",
      "train loss:0.0005775185493049334\n",
      "train loss:0.017674497821518573\n",
      "train loss:0.0012330941240101347\n",
      "train loss:0.012341559740362544\n",
      "train loss:0.00029107257260093896\n",
      "train loss:0.0021329867792511683\n",
      "train loss:0.0012347074074270591\n",
      "train loss:0.0005052527710002199\n",
      "train loss:0.0007808824892536785\n",
      "train loss:0.012326022078599095\n",
      "train loss:0.000999433545602934\n",
      "train loss:0.006841492184093645\n",
      "train loss:0.0007915518555867496\n",
      "train loss:0.0022511038729657643\n",
      "train loss:0.0007413149156260916\n",
      "train loss:0.0074396722499463774\n",
      "train loss:0.003334453851812274\n",
      "train loss:0.0017083938679016025\n",
      "train loss:0.010781806709084223\n",
      "train loss:0.005341844219492338\n",
      "train loss:0.0006405107465977577\n",
      "train loss:0.001527637765467849\n",
      "train loss:0.0006683871739112914\n",
      "train loss:0.008707364617182769\n",
      "train loss:0.0024898526416476806\n",
      "train loss:0.0010235198622853743\n",
      "train loss:0.0016612550807274858\n",
      "train loss:0.0013347969976648221\n",
      "train loss:0.001925322906496409\n",
      "train loss:0.0009374742144551721\n",
      "train loss:0.0005134548948218751\n",
      "train loss:0.004655302901480043\n",
      "train loss:0.0005756647258768173\n",
      "train loss:0.0015106369070691684\n",
      "train loss:0.00020080182644407153\n",
      "train loss:0.0006662224874253183\n",
      "train loss:0.0016132929264408805\n",
      "train loss:0.0010026028467111144\n",
      "train loss:0.004373829245786755\n",
      "train loss:0.0010098663780284548\n",
      "train loss:0.0057086365698064655\n",
      "train loss:0.0034152990240317793\n",
      "train loss:0.00029879181307981335\n",
      "train loss:0.0006576423024024508\n",
      "train loss:0.0025671572492467643\n",
      "train loss:0.0021105586624148684\n",
      "train loss:0.002044151330908436\n",
      "train loss:0.0006542513911090127\n",
      "train loss:0.0009320976526581685\n",
      "train loss:0.009293510359213051\n",
      "train loss:0.0006166785983998216\n",
      "train loss:0.004020109367842246\n",
      "train loss:0.004218041260996238\n",
      "train loss:0.003961351735484809\n",
      "train loss:0.003976994579825841\n",
      "train loss:0.0033000687560990425\n",
      "train loss:0.0014579325849784894\n",
      "train loss:0.0032610761112085067\n",
      "train loss:0.0020003310988319263\n",
      "train loss:0.027106286207195934\n",
      "train loss:0.0025761144306513635\n",
      "train loss:0.0006800781897824598\n",
      "train loss:0.000417898090511578\n",
      "train loss:0.0013377813335875605\n",
      "train loss:0.0037508011009529567\n",
      "train loss:0.0004382015210491284\n",
      "train loss:0.0017785327200518508\n",
      "train loss:0.00017205344803336795\n",
      "train loss:0.0007646634239112628\n",
      "train loss:0.0018258128023792978\n",
      "train loss:0.00017784852871023676\n",
      "train loss:0.0004776113790489389\n",
      "train loss:0.0017865009161627831\n",
      "train loss:0.0004847133221553794\n",
      "train loss:0.00021358249257542178\n",
      "train loss:0.0006271120138191085\n",
      "train loss:6.302237404148688e-05\n",
      "train loss:0.01822407301445467\n",
      "train loss:0.004609640878449875\n",
      "train loss:0.0005942370371144385\n",
      "train loss:0.00034927692422875053\n",
      "train loss:0.00012175739155024633\n",
      "train loss:0.002860947032851816\n",
      "train loss:0.0005785364447483446\n",
      "train loss:0.0019316870902703683\n",
      "train loss:0.004923196449641957\n",
      "train loss:0.005830694487243861\n",
      "train loss:0.00019958534087948524\n",
      "train loss:0.004113654043823547\n",
      "train loss:0.0017718788720453957\n",
      "train loss:0.0002840373952538984\n",
      "train loss:0.0006736816924068851\n",
      "train loss:0.012784233642196836\n",
      "train loss:0.00013042085684510373\n",
      "train loss:0.0014294436143896308\n",
      "train loss:0.0014869186693643097\n",
      "train loss:0.0003552383139976228\n",
      "train loss:0.0005038901003918395\n",
      "train loss:0.0007871894706641872\n",
      "train loss:0.001250281596493869\n",
      "train loss:0.0018844444174105142\n",
      "train loss:0.0004436181523573491\n",
      "train loss:0.004084701634199612\n",
      "train loss:0.001057782190895007\n",
      "train loss:0.0007069641487187962\n",
      "train loss:0.0018309384910695232\n",
      "train loss:0.00040849515774842737\n",
      "train loss:0.0022538943440074503\n",
      "train loss:0.0006367237741518495\n",
      "train loss:0.002252828682076179\n",
      "train loss:0.0009109574813415933\n",
      "train loss:0.00023966181780572812\n",
      "train loss:0.0020541129612997836\n",
      "train loss:0.0012953844834923903\n",
      "train loss:0.022835402448618248\n",
      "train loss:0.0014715948311112045\n",
      "train loss:0.000839888974627032\n",
      "train loss:0.001001695136831928\n",
      "train loss:0.000778613808820851\n",
      "train loss:0.0008939861699342055\n",
      "train loss:0.0015668678195480804\n",
      "train loss:0.004376409464075834\n",
      "train loss:0.002562131132353098\n",
      "train loss:0.0034121702619770637\n",
      "train loss:0.0004165610355458913\n",
      "train loss:0.00039355059523987117\n",
      "train loss:0.00015411370719548004\n",
      "train loss:0.0002092316773737473\n",
      "train loss:0.0004464437516244889\n",
      "train loss:0.00027712121012634543\n",
      "train loss:0.0009529229519422675\n",
      "train loss:9.656954473476351e-05\n",
      "train loss:0.002127391382992\n",
      "train loss:0.0012413859662538129\n",
      "train loss:0.0013750318387375942\n",
      "train loss:0.0004330624707898346\n",
      "train loss:0.0037324758187928316\n",
      "train loss:0.0014754045497015042\n",
      "train loss:0.003730874090107542\n",
      "train loss:0.0001523137660067547\n",
      "train loss:0.005299310614510345\n",
      "train loss:0.00021300467030366883\n",
      "train loss:0.00013037663183698527\n",
      "train loss:0.0005210848585005891\n",
      "train loss:0.004724234289961625\n",
      "train loss:0.0004917776826340707\n",
      "train loss:0.0009511759643928657\n",
      "train loss:0.002086167090531889\n",
      "train loss:0.0008370610432509321\n",
      "train loss:0.004781089622731819\n",
      "train loss:0.0006083388757615677\n",
      "train loss:0.0033824222320919745\n",
      "train loss:0.002771758674625177\n",
      "train loss:0.005208156245836989\n",
      "train loss:0.004048065991624723\n",
      "train loss:0.0026726399480851404\n",
      "train loss:0.00021663937343422042\n",
      "train loss:0.0027426638788168147\n",
      "train loss:0.0022130284898617754\n",
      "train loss:0.005336668890024356\n",
      "train loss:0.0027424099384778648\n",
      "train loss:0.0013748395087507246\n",
      "train loss:0.0027627080301904088\n",
      "train loss:0.0015511306242353478\n",
      "train loss:0.0010718822091537073\n",
      "train loss:0.0021304544035263308\n",
      "train loss:0.00029129542803227695\n",
      "train loss:0.00232791887427365\n",
      "train loss:0.00015264218809650257\n",
      "train loss:0.004414295168758838\n",
      "train loss:0.0009267686782276331\n",
      "train loss:0.0017945167457594415\n",
      "train loss:0.003972324852451983\n",
      "train loss:0.0015087014902892867\n",
      "train loss:0.006471589952980008\n",
      "train loss:0.0002443313205859295\n",
      "train loss:0.0015741975562628178\n",
      "train loss:0.002015857082951075\n",
      "train loss:0.0008991971346153634\n",
      "train loss:0.0001823704016834135\n",
      "train loss:0.00015379772562949744\n",
      "train loss:0.003989048230183888\n",
      "train loss:0.004014689271181342\n",
      "train loss:0.001692513091666402\n",
      "train loss:0.0004152760246494149\n",
      "train loss:0.0004678747173435016\n",
      "train loss:0.0019651443344433066\n",
      "train loss:0.00020147484375107646\n",
      "train loss:0.0014800702747020764\n",
      "train loss:0.0017385129789311072\n",
      "train loss:0.0012983254744046852\n",
      "train loss:0.0003724249123840767\n",
      "train loss:0.0008377954401776791\n",
      "train loss:0.01516314014811147\n",
      "train loss:0.002271870948815742\n",
      "train loss:0.00035256224188412525\n",
      "train loss:0.0003344466783889229\n",
      "train loss:0.0006756465410502605\n",
      "train loss:0.00030241501214966945\n",
      "train loss:0.001099418968960342\n",
      "train loss:0.0004910189699641632\n",
      "train loss:0.00032717520101724774\n",
      "train loss:0.00522029902369833\n",
      "train loss:0.0013910137110999174\n",
      "train loss:0.00382891350739506\n",
      "train loss:6.600358951349563e-05\n",
      "train loss:0.0010324046655291541\n",
      "train loss:0.0017340111670676958\n",
      "train loss:0.0017132003434443056\n",
      "train loss:0.0009542891117810027\n",
      "train loss:4.072743694483967e-05\n",
      "train loss:0.0009747646746893017\n",
      "train loss:0.004193640468698395\n",
      "train loss:0.0006860579302374767\n",
      "train loss:0.0003956812519898508\n",
      "train loss:0.00383414247307893\n",
      "train loss:0.0035267404800235756\n",
      "train loss:0.008048193681283306\n",
      "train loss:0.0037555695365763535\n",
      "train loss:0.0031467213916877524\n",
      "train loss:0.0016725429343069918\n",
      "train loss:0.006824993904615359\n",
      "train loss:0.00016550836332839772\n",
      "train loss:0.0008639180604754756\n",
      "train loss:0.0009536331264888729\n",
      "train loss:0.0009401156680154818\n",
      "train loss:0.0005880883118713696\n",
      "train loss:0.002398745917946021\n",
      "train loss:0.0028765709447690292\n",
      "train loss:0.0035650792749209815\n",
      "train loss:0.001606670804919249\n",
      "train loss:0.002823925411059666\n",
      "train loss:0.0006324362385159114\n",
      "train loss:0.00296655196830101\n",
      "train loss:0.0037001028395615672\n",
      "train loss:0.0015522599423405806\n",
      "train loss:0.0004432530821531019\n",
      "train loss:0.000930445066265054\n",
      "train loss:0.0006360828813808631\n",
      "train loss:0.00227367040000943\n",
      "train loss:0.0019689517151490975\n",
      "train loss:0.0009305764754229027\n",
      "train loss:0.001990388214055962\n",
      "train loss:0.00036107526874424494\n",
      "train loss:0.0002632536205649318\n",
      "train loss:0.0028417851070508854\n",
      "train loss:0.00034519820268004794\n",
      "train loss:0.0022457527517392374\n",
      "train loss:0.0018350273017456245\n",
      "train loss:6.211567662324749e-05\n",
      "train loss:0.0014759394208460656\n",
      "train loss:0.0002841736007742587\n",
      "train loss:0.0004576654287478299\n",
      "train loss:0.0009872038073931555\n",
      "train loss:0.002521511712733981\n",
      "train loss:0.002432596082850987\n",
      "train loss:0.012319012229016282\n",
      "train loss:0.0016734774254750884\n",
      "train loss:0.0013405272670784418\n",
      "train loss:0.0002816473415341072\n",
      "train loss:0.002028390559989737\n",
      "train loss:0.0003708387522948575\n",
      "train loss:0.00025108974041557897\n",
      "train loss:0.001386352483153034\n",
      "train loss:0.00158642106874024\n",
      "train loss:0.0005240727406675599\n",
      "train loss:0.0017035649031479638\n",
      "train loss:0.00036062679888440564\n",
      "train loss:0.0005503179112434464\n",
      "train loss:0.0016787816202752028\n",
      "train loss:0.0015436312189091204\n",
      "train loss:0.00032873845832637584\n",
      "train loss:0.0009955009973176328\n",
      "train loss:0.0028139153339802915\n",
      "train loss:0.006194725301433545\n",
      "train loss:0.00021459008372102538\n",
      "train loss:0.00045459519761363235\n",
      "train loss:0.004647217710491442\n",
      "train loss:0.00014298265674410416\n",
      "train loss:0.0014252863111800316\n",
      "train loss:0.0031286723381309827\n",
      "train loss:0.0004646054289316555\n",
      "train loss:0.002765426212960034\n",
      "train loss:0.00023936312100890538\n",
      "train loss:0.0010578624838268609\n",
      "train loss:0.0008003151399007154\n",
      "train loss:0.0007898885992653691\n",
      "train loss:0.0004822747300875473\n",
      "train loss:0.001949474663317936\n",
      "train loss:0.0003626366788564626\n",
      "train loss:0.0037053999740527636\n",
      "train loss:0.000658575513445432\n",
      "train loss:0.0019589846991028654\n",
      "train loss:0.0006466618428362964\n",
      "train loss:0.00022073252442117078\n",
      "train loss:0.0004290046317540153\n",
      "train loss:0.002934348512532415\n",
      "train loss:0.00035568709760094554\n",
      "train loss:0.0019558985429245107\n",
      "train loss:0.0012003236724357847\n",
      "train loss:0.00014548808693797775\n",
      "train loss:0.0022675451439930013\n",
      "train loss:0.0006236527536712413\n",
      "train loss:0.00118601894919483\n",
      "train loss:0.028921200157332187\n",
      "train loss:0.00027463345271156885\n",
      "train loss:0.0019699276013966103\n",
      "train loss:0.00015384448823056688\n",
      "train loss:0.003843621870404668\n",
      "train loss:0.004797939605509492\n",
      "train loss:0.0009382605309495546\n",
      "train loss:0.001335934565165793\n",
      "train loss:0.0026871450990288907\n",
      "train loss:0.0008956079381419508\n",
      "train loss:0.0007459302983175895\n",
      "train loss:0.00013900153999239035\n",
      "train loss:0.0005498870552326621\n",
      "train loss:0.0006643936432155987\n",
      "train loss:0.0036745114695595597\n",
      "train loss:0.0001687545893633122\n",
      "train loss:0.00025934062375805106\n",
      "train loss:0.0003345664318871209\n",
      "train loss:0.0010764004954872414\n",
      "train loss:0.001361297745733645\n",
      "train loss:0.017611959658260064\n",
      "train loss:0.0009403323844340704\n",
      "train loss:0.003014109616541707\n",
      "train loss:0.01211339493291393\n",
      "train loss:0.00256858983008328\n",
      "train loss:0.0003824808783500908\n",
      "train loss:0.00033278366344773947\n",
      "train loss:0.00036795645546450364\n",
      "train loss:0.00025693458782499403\n",
      "train loss:0.00072811155592562\n",
      "train loss:0.00011916239414528349\n",
      "train loss:0.00501669315299259\n",
      "train loss:0.0006689822755794096\n",
      "train loss:0.002073719176528881\n",
      "train loss:0.000792666730486063\n",
      "train loss:0.0013150867072221329\n",
      "train loss:0.005759270387282103\n",
      "train loss:0.0002050652137091201\n",
      "train loss:0.001193957862817139\n",
      "train loss:0.0006632742253902918\n",
      "train loss:0.00033732295803241016\n",
      "train loss:0.0011553032578978189\n",
      "train loss:0.0019834584373881066\n",
      "train loss:0.0005413866977498472\n",
      "train loss:0.0030188000247433873\n",
      "train loss:0.003551223423435687\n",
      "train loss:0.0007657285306941431\n",
      "train loss:0.003024261707324739\n",
      "train loss:0.00036510693576602383\n",
      "train loss:0.0003022451058834905\n",
      "train loss:0.000282209794223264\n",
      "train loss:0.0057050187013486\n",
      "train loss:0.0005110505026487181\n",
      "train loss:7.61423359778574e-05\n",
      "train loss:0.00034125509691864986\n",
      "train loss:0.0024752501614607398\n",
      "train loss:0.002281440590119633\n",
      "train loss:0.0011278554975041816\n",
      "train loss:0.0003992528544802455\n",
      "train loss:0.0004702884385354236\n",
      "train loss:0.0010756937504956873\n",
      "train loss:0.00043371712929419966\n",
      "train loss:0.0012038725223610265\n",
      "train loss:0.003334900422509016\n",
      "train loss:0.00021959487935841807\n",
      "train loss:0.00023584876546603724\n",
      "train loss:0.00017583836725897005\n",
      "train loss:0.0006081935300395416\n",
      "train loss:0.002407578972246144\n",
      "train loss:0.0037210486871709497\n",
      "train loss:0.0013232085801023672\n",
      "train loss:0.0004421989414756623\n",
      "train loss:0.002158370349690246\n",
      "train loss:0.0009345010514073513\n",
      "train loss:0.0019641287297772585\n",
      "train loss:0.0003715047705105767\n",
      "train loss:0.0013004430897735429\n",
      "train loss:0.0007195010274351864\n",
      "train loss:0.002180923805187684\n",
      "train loss:0.00023159924915188874\n",
      "train loss:4.252536838576322e-05\n",
      "train loss:3.977321111723798e-05\n",
      "train loss:0.0001865896363983724\n",
      "train loss:0.0017262437632694114\n",
      "train loss:0.0001343192414741718\n",
      "train loss:0.0015385872620773567\n",
      "train loss:0.00040358914141320345\n",
      "train loss:0.008635012315145902\n",
      "train loss:0.0008236929371764718\n",
      "train loss:0.0023900201174999903\n",
      "train loss:0.00044448958477082633\n",
      "train loss:0.0007161334740861631\n",
      "train loss:0.00026535705883366453\n",
      "train loss:0.0007799044654322924\n",
      "train loss:6.72724624320262e-05\n",
      "train loss:0.0014805641916606357\n",
      "train loss:0.026883599546958556\n",
      "train loss:0.0006737966568029586\n",
      "train loss:0.0015294012856834338\n",
      "train loss:0.002035444408791145\n",
      "train loss:0.0032462746565758145\n",
      "train loss:0.004777973502767504\n",
      "train loss:0.0008887942583078773\n",
      "train loss:0.00020454985100501095\n",
      "train loss:0.00041771112505746306\n",
      "train loss:0.002363554935658517\n",
      "train loss:0.000333387447967138\n",
      "train loss:7.652999165729773e-05\n",
      "train loss:0.00212208525314376\n",
      "train loss:0.002696992542989115\n",
      "train loss:0.0007257727168166456\n",
      "train loss:0.001163193797302666\n",
      "train loss:0.000469261724733361\n",
      "train loss:0.003354089820580889\n",
      "train loss:0.0008670988426767936\n",
      "train loss:0.00265470278693267\n",
      "train loss:0.003526348703125433\n",
      "train loss:0.0005376814392012598\n",
      "train loss:0.00026569853513536086\n",
      "train loss:0.005972067553702911\n",
      "train loss:0.004336810470897886\n",
      "train loss:0.0031178244768836553\n",
      "train loss:0.00011214293827215303\n",
      "train loss:0.03540088375819665\n",
      "train loss:0.004001062210556732\n",
      "train loss:0.002611504232954642\n",
      "train loss:0.003865640723166475\n",
      "train loss:0.0011964670040856917\n",
      "train loss:0.002240240334579236\n",
      "train loss:0.0008051313025462808\n",
      "train loss:0.00046797406382583195\n",
      "train loss:0.00290566784658143\n",
      "train loss:0.0020217337744359454\n",
      "train loss:0.0036362122641014484\n",
      "train loss:0.0028106123239584786\n",
      "train loss:0.0026600699637832543\n",
      "train loss:0.002620764450727346\n",
      "train loss:0.0013536210526353123\n",
      "train loss:0.00013241969233579584\n",
      "train loss:0.0027868553585908874\n",
      "train loss:0.07404603348090961\n",
      "train loss:0.004094852683949608\n",
      "train loss:0.014352447948436022\n",
      "train loss:0.011332303394373314\n",
      "train loss:0.03946580539643511\n",
      "train loss:2.944736562840622e-05\n",
      "train loss:0.000363966723242963\n",
      "train loss:0.0007169180827254658\n",
      "train loss:0.0008840475562285656\n",
      "train loss:0.003428061972136458\n",
      "train loss:0.0015451110012409132\n",
      "train loss:4.936021198283598e-05\n",
      "train loss:0.001815262744551818\n",
      "train loss:0.0016074149074704169\n",
      "train loss:0.008799453028150387\n",
      "train loss:0.001611018921428357\n",
      "train loss:0.0022882585833023787\n",
      "train loss:0.010142504367879411\n",
      "train loss:0.0017901066140663879\n",
      "=== epoch:16, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.002865038862438814\n",
      "train loss:0.0024669114537177383\n",
      "train loss:0.0008860889904562904\n",
      "train loss:0.0020144256496661558\n",
      "train loss:0.0008213037170126625\n",
      "train loss:0.0006836878422112774\n",
      "train loss:0.0007922939127144208\n",
      "train loss:0.009265026579341229\n",
      "train loss:0.003520878000330146\n",
      "train loss:0.0012962498286750248\n",
      "train loss:0.0003173225283349707\n",
      "train loss:0.0007563759095967951\n",
      "train loss:0.0006882746357530831\n",
      "train loss:0.0008203953264717943\n",
      "train loss:0.0008558533060739869\n",
      "train loss:0.0052772866478208065\n",
      "train loss:0.00015482711894436262\n",
      "train loss:0.0009202250691508402\n",
      "train loss:0.003629439570112559\n",
      "train loss:0.005350583390227668\n",
      "train loss:0.0008721496216632202\n",
      "train loss:0.004420568070851296\n",
      "train loss:0.0021946225407309086\n",
      "train loss:0.0012250600590368139\n",
      "train loss:0.00010402215499349063\n",
      "train loss:0.0030436261859211776\n",
      "train loss:0.0036430711718701447\n",
      "train loss:0.005388028495632476\n",
      "train loss:0.0008836875499478344\n",
      "train loss:7.723374338743063e-05\n",
      "train loss:0.0013853965435270774\n",
      "train loss:0.006928402889919297\n",
      "train loss:0.003276633237568384\n",
      "train loss:0.0001714299173370326\n",
      "train loss:0.0007920740369810524\n",
      "train loss:0.0005335960223964521\n",
      "train loss:0.005957104879841396\n",
      "train loss:0.005385271901630946\n",
      "train loss:0.00037018974355713393\n",
      "train loss:0.0036460247657914\n",
      "train loss:0.007940837692624311\n",
      "train loss:0.0028750474469549847\n",
      "train loss:0.002399532205787767\n",
      "train loss:0.002019419927990411\n",
      "train loss:0.0009107004447646893\n",
      "train loss:0.0033935257460383224\n",
      "train loss:0.001182085742043703\n",
      "train loss:0.003530723149421258\n",
      "train loss:0.0003162310201979388\n",
      "train loss:0.0002675130945572019\n",
      "train loss:0.0019851077668836562\n",
      "train loss:0.0013753626306328834\n",
      "train loss:0.002426100439908026\n",
      "train loss:0.00717988700248782\n",
      "train loss:0.0016850435489061655\n",
      "train loss:0.0011476910050938237\n",
      "train loss:0.0007033455741669838\n",
      "train loss:0.0018758579602534248\n",
      "train loss:0.003348508917783794\n",
      "train loss:0.0026657107559287644\n",
      "train loss:0.0002741849420090693\n",
      "train loss:9.314485525537885e-05\n",
      "train loss:0.021710714271572104\n",
      "train loss:0.0011795299103489901\n",
      "train loss:0.00201044783136935\n",
      "train loss:0.02557061196945327\n",
      "train loss:0.0009188426512472801\n",
      "train loss:0.015101211322896107\n",
      "train loss:0.00038761356669037814\n",
      "train loss:0.0005759326534854085\n",
      "train loss:0.010292942120761\n",
      "train loss:0.0002709246798467516\n",
      "train loss:0.0026988493036371516\n",
      "train loss:0.0015987124599426256\n",
      "train loss:0.01773524402688458\n",
      "train loss:0.00016450695834384008\n",
      "train loss:0.0005693545077377368\n",
      "train loss:0.0028502307823439384\n",
      "train loss:0.002151578974988594\n",
      "train loss:0.005133975344963643\n",
      "train loss:0.0004116964303780598\n",
      "train loss:0.00013494215461760177\n",
      "train loss:0.0018770994204867471\n",
      "train loss:0.0067568606867224575\n",
      "train loss:0.002989379509742775\n",
      "train loss:0.0002471814752336769\n",
      "train loss:0.0003131423422342301\n",
      "train loss:0.0008554321300008902\n",
      "train loss:0.0025958028583449146\n",
      "train loss:0.0011358492872689007\n",
      "train loss:0.0010127676445910285\n",
      "train loss:0.0006814681336639876\n",
      "train loss:0.0003455035788689632\n",
      "train loss:0.0010101554760878059\n",
      "train loss:0.0017182463783771127\n",
      "train loss:0.0005217935533799504\n",
      "train loss:0.004478080493619356\n",
      "train loss:0.0025779258791256824\n",
      "train loss:0.0004314571671860546\n",
      "train loss:0.004083678751139438\n",
      "train loss:0.0007977126880021439\n",
      "train loss:0.01008467405733479\n",
      "train loss:0.002173596899695371\n",
      "train loss:0.00018960075743813763\n",
      "train loss:0.00030010013873094457\n",
      "train loss:0.0029643478007919033\n",
      "train loss:0.0024549802212202685\n",
      "train loss:0.0008723002246215905\n",
      "train loss:0.004518076765355418\n",
      "train loss:0.006896683092037382\n",
      "train loss:0.0011127831915534894\n",
      "train loss:0.00033799473185000274\n",
      "train loss:0.002945370688502984\n",
      "train loss:0.003156267246605368\n",
      "train loss:0.00019848973126858498\n",
      "train loss:0.0021275156459706138\n",
      "train loss:0.0005523680542349645\n",
      "train loss:0.003219803324342044\n",
      "train loss:0.0006179881281533027\n",
      "train loss:0.0026497425326734774\n",
      "train loss:0.0011962620698902102\n",
      "train loss:0.0014333461173005292\n",
      "train loss:6.553617962778433e-05\n",
      "train loss:0.000588187845496965\n",
      "train loss:0.0012423515810248663\n",
      "train loss:0.00031850111148765234\n",
      "train loss:0.00422660284312722\n",
      "train loss:0.00039725587632458354\n",
      "train loss:0.04870046547001977\n",
      "train loss:0.0009165428880141183\n",
      "train loss:0.0039661133984616945\n",
      "train loss:0.0010305297784145976\n",
      "train loss:9.029209511139147e-05\n",
      "train loss:0.00046880624637061206\n",
      "train loss:0.0008198225169270229\n",
      "train loss:0.0001809394854264318\n",
      "train loss:0.0005398527927168377\n",
      "train loss:0.0002643064834935128\n",
      "train loss:0.0006050681145096551\n",
      "train loss:0.001295810168367133\n",
      "train loss:0.0015569919152377645\n",
      "train loss:0.0009229186017780723\n",
      "train loss:0.002050194434990875\n",
      "train loss:0.00023581866074019644\n",
      "train loss:0.0004365279856776053\n",
      "train loss:0.0027071333451542555\n",
      "train loss:0.00015293179318950063\n",
      "train loss:0.00014545948969510894\n",
      "train loss:0.0015121288788108684\n",
      "train loss:0.0008709278815321895\n",
      "train loss:0.004235523478328914\n",
      "train loss:0.000606211979390223\n",
      "train loss:1.5840083443589834e-05\n",
      "train loss:0.0020020979658237244\n",
      "train loss:0.0015684875832917018\n",
      "train loss:0.002236336330713569\n",
      "train loss:0.005472098856841967\n",
      "train loss:0.0006762334393827399\n",
      "train loss:0.0012507508412918406\n",
      "train loss:0.0022289057294471093\n",
      "train loss:0.0030110176421309785\n",
      "train loss:0.0035196187696343727\n",
      "train loss:0.0007525344885389742\n",
      "train loss:0.0010033050714936648\n",
      "train loss:0.001814238715449618\n",
      "train loss:0.00043086773728246244\n",
      "train loss:0.0021698043216571306\n",
      "train loss:0.004074905239414041\n",
      "train loss:0.001560031262862816\n",
      "train loss:0.0005703709797421018\n",
      "train loss:8.118005347852761e-05\n",
      "train loss:0.004553954639431947\n",
      "train loss:0.0009970006151845527\n",
      "train loss:0.000677887418709563\n",
      "train loss:0.00031257339866504354\n",
      "train loss:0.00012450435365192366\n",
      "train loss:0.0002410351089903396\n",
      "train loss:0.0007012755288217931\n",
      "train loss:0.000917486873282888\n",
      "train loss:0.0032322617527310755\n",
      "train loss:0.0013171004040463622\n",
      "train loss:0.020318804712688952\n",
      "train loss:0.0007449209883356292\n",
      "train loss:0.0015551534629212216\n",
      "train loss:0.002804194258683024\n",
      "train loss:0.0025920414563524764\n",
      "train loss:0.024463399997349606\n",
      "train loss:0.000220342095389727\n",
      "train loss:0.006009861474241746\n",
      "train loss:0.0018839804193216674\n",
      "train loss:0.00043078675789651937\n",
      "train loss:0.005212879929051847\n",
      "train loss:0.0006373161902464167\n",
      "train loss:0.0011243674467123447\n",
      "train loss:0.00026773014546334475\n",
      "train loss:0.00033057115704075474\n",
      "train loss:0.0003023680559693941\n",
      "train loss:0.0016127154588366985\n",
      "train loss:0.0017626457732327846\n",
      "train loss:0.0003517424904335419\n",
      "train loss:0.0008338910898257594\n",
      "train loss:0.0011914164354833317\n",
      "train loss:0.0033335494339708153\n",
      "train loss:0.0033846220164730355\n",
      "train loss:0.0015366782559563896\n",
      "train loss:0.00029094991632986527\n",
      "train loss:0.00013375529884328426\n",
      "train loss:0.00029819134155477384\n",
      "train loss:8.063483710375795e-05\n",
      "train loss:0.006621635345225325\n",
      "train loss:0.001175269685325801\n",
      "train loss:0.001191542908560088\n",
      "train loss:0.0003788149893391382\n",
      "train loss:0.00181400839477025\n",
      "train loss:0.00031344189571645806\n",
      "train loss:0.0002608584557675256\n",
      "train loss:0.0010452789634814894\n",
      "train loss:0.0003804575368816574\n",
      "train loss:0.00010922104880612836\n",
      "train loss:0.0005977200312832125\n",
      "train loss:0.03419013935390346\n",
      "train loss:0.0004918303670802156\n",
      "train loss:0.0037356988736653813\n",
      "train loss:0.001042931920153654\n",
      "train loss:0.0011122683848268945\n",
      "train loss:0.0008639278346429614\n",
      "train loss:0.0014522827905074363\n",
      "train loss:0.0011983657977404974\n",
      "train loss:0.00037511975266828895\n",
      "train loss:0.005297764638398796\n",
      "train loss:0.001182426144433714\n",
      "train loss:0.0010536848065310117\n",
      "train loss:1.2992167716522386e-05\n",
      "train loss:0.00022839819227511086\n",
      "train loss:0.0005061364838187278\n",
      "train loss:0.0006318692395613862\n",
      "train loss:0.0020755485544449908\n",
      "train loss:0.0008027378324806889\n",
      "train loss:0.0006947236492660776\n",
      "train loss:0.0002021540453138227\n",
      "train loss:0.0006211054429549848\n",
      "train loss:0.0011854892896209389\n",
      "train loss:0.001095024799047199\n",
      "train loss:0.0019848254720973096\n",
      "train loss:0.0005156676231951633\n",
      "train loss:0.0010572589526421726\n",
      "train loss:0.001195756945469491\n",
      "train loss:0.000453663928040096\n",
      "train loss:0.010125465166653634\n",
      "train loss:0.008095018459246756\n",
      "train loss:0.0005944221785438782\n",
      "train loss:0.00045577708001763996\n",
      "train loss:0.0013260243352343087\n",
      "train loss:0.0002640718635560101\n",
      "train loss:0.005007956899610672\n",
      "train loss:0.006659481357530741\n",
      "train loss:0.020240960652716865\n",
      "train loss:0.0005228630685286931\n",
      "train loss:0.007523927399653044\n",
      "train loss:0.0035787514619167082\n",
      "train loss:0.0005197192233560258\n",
      "train loss:0.0013046965399100842\n",
      "train loss:0.00029626996755608174\n",
      "train loss:0.0030050649869978376\n",
      "train loss:0.0020896910218021606\n",
      "train loss:0.0032688128566185515\n",
      "train loss:0.0015241085563463769\n",
      "train loss:0.003105211122917316\n",
      "train loss:0.00019369819162603344\n",
      "train loss:0.004164840553050498\n",
      "train loss:0.00492341313003293\n",
      "train loss:0.0033515839353547073\n",
      "train loss:0.0024424670314832538\n",
      "train loss:0.008552686416131673\n",
      "train loss:0.0015987750632217045\n",
      "train loss:0.0022061489666932855\n",
      "train loss:0.0032249724923247712\n",
      "train loss:0.000982619968518773\n",
      "train loss:0.0008111864729372995\n",
      "train loss:0.0012794781283096465\n",
      "train loss:0.0003707150320912706\n",
      "train loss:0.0008109425073538157\n",
      "train loss:0.0014258179392753428\n",
      "train loss:0.00037626151701542035\n",
      "train loss:0.002832488064997148\n",
      "train loss:0.0024092027011116315\n",
      "train loss:0.006300264913497937\n",
      "train loss:0.003220345735568077\n",
      "train loss:0.002756249127948911\n",
      "train loss:0.0014338359991121813\n",
      "train loss:1.4901950310233756e-05\n",
      "train loss:0.0003856193075071341\n",
      "train loss:0.0016907114838187953\n",
      "train loss:0.00042081426762279853\n",
      "train loss:0.005286930818844693\n",
      "train loss:0.013584653240807168\n",
      "train loss:0.0004406628020965904\n",
      "train loss:0.0005799501920926492\n",
      "train loss:0.0005406730481942137\n",
      "train loss:0.0002960703386812978\n",
      "train loss:0.00011965641979442236\n",
      "train loss:0.0003491029120839329\n",
      "train loss:0.0001877140384244996\n",
      "train loss:0.0037744351793288196\n",
      "train loss:6.328013455977412e-05\n",
      "train loss:8.65199258110243e-05\n",
      "train loss:0.0022796386527267234\n",
      "train loss:0.0007489009666802038\n",
      "train loss:0.001717887668949776\n",
      "train loss:0.0006567683037555905\n",
      "train loss:0.0017148691379539937\n",
      "train loss:0.0062138933365705525\n",
      "train loss:0.00014480907927403257\n",
      "train loss:0.00022410245355306647\n",
      "train loss:0.0032918807195701787\n",
      "train loss:0.00014123530561256854\n",
      "train loss:0.001686467630144068\n",
      "train loss:0.0013884923245610528\n",
      "train loss:0.0029668798959884037\n",
      "train loss:0.0007068568453948843\n",
      "train loss:0.00017417784280884585\n",
      "train loss:0.0007980468981389111\n",
      "train loss:0.000141358388306916\n",
      "train loss:0.0016693085052410777\n",
      "train loss:0.0026934811549476556\n",
      "train loss:0.0013618039368420997\n",
      "train loss:0.0005047123070751687\n",
      "train loss:0.00557183729872744\n",
      "train loss:0.010617157711596445\n",
      "train loss:0.0003721314277785634\n",
      "train loss:0.00013218468223312842\n",
      "train loss:0.0023157005534230005\n",
      "train loss:0.0021429188377497994\n",
      "train loss:0.0008336965660982272\n",
      "train loss:0.0024499806553397964\n",
      "train loss:0.0011524696052444292\n",
      "train loss:0.001394787129064958\n",
      "train loss:0.00537250701264862\n",
      "train loss:0.010929845923033804\n",
      "train loss:8.354862505272146e-05\n",
      "train loss:0.00033448678528192645\n",
      "train loss:0.0013083427970035258\n",
      "train loss:0.00031609740473678856\n",
      "train loss:0.002881297586515918\n",
      "train loss:0.0006101019413964502\n",
      "train loss:0.0015912180388452562\n",
      "train loss:0.000943978910601838\n",
      "train loss:0.004648269185922338\n",
      "train loss:0.0006146557145507311\n",
      "train loss:5.564927778755635e-05\n",
      "train loss:0.0013217041398400902\n",
      "train loss:0.0003193216800236934\n",
      "train loss:0.00034342757758170375\n",
      "train loss:0.0008868375150140287\n",
      "train loss:0.0005178016019561733\n",
      "train loss:0.0022846237919859234\n",
      "train loss:0.000901228150285872\n",
      "train loss:0.000615160657805499\n",
      "train loss:0.011713819352721333\n",
      "train loss:8.066417271098551e-05\n",
      "train loss:0.0036401053118467297\n",
      "train loss:0.0014068375516690193\n",
      "train loss:0.001188336475401643\n",
      "train loss:0.00979754836797393\n",
      "train loss:0.0006226163343869878\n",
      "train loss:0.0007620951790368343\n",
      "train loss:0.0014691605198137207\n",
      "train loss:0.002034619907225545\n",
      "train loss:0.002836390000780761\n",
      "train loss:0.00048525468650839463\n",
      "train loss:0.004681043701042879\n",
      "train loss:0.0027506858066866004\n",
      "train loss:3.3939788224174205e-05\n",
      "train loss:0.0058831831414920994\n",
      "train loss:0.002217541159005\n",
      "train loss:0.0005368619703648958\n",
      "train loss:0.002171003722878646\n",
      "train loss:0.0005070801788176124\n",
      "train loss:0.004459073020409468\n",
      "train loss:0.0013475790472893606\n",
      "train loss:0.0019712198518189233\n",
      "train loss:0.003436661417390342\n",
      "train loss:0.0025668140839466085\n",
      "train loss:0.00044199705984869514\n",
      "train loss:0.0005512987278865648\n",
      "train loss:0.00012795037050502997\n",
      "train loss:0.001174632022327706\n",
      "train loss:0.0006490617683059293\n",
      "train loss:0.011602746394412687\n",
      "train loss:0.0017071320422434905\n",
      "train loss:0.001625538180519629\n",
      "train loss:0.003056546416544782\n",
      "train loss:0.0020502526453135485\n",
      "train loss:0.0010991457639574571\n",
      "train loss:2.8460977537692498e-05\n",
      "train loss:0.003795038752986489\n",
      "train loss:0.00024627710610828865\n",
      "train loss:0.002435389745258781\n",
      "train loss:0.0005294060033909065\n",
      "train loss:0.0007626984257415697\n",
      "train loss:0.003928393697794365\n",
      "train loss:0.0008963042093111869\n",
      "train loss:0.0010335772274381472\n",
      "train loss:0.001426096713328753\n",
      "train loss:0.001646946460288591\n",
      "train loss:0.0008580655109438422\n",
      "train loss:0.0009782116150520782\n",
      "train loss:0.0008816980975522895\n",
      "train loss:0.0013994472164807984\n",
      "train loss:0.0004901342338845722\n",
      "train loss:0.0004794084585182904\n",
      "train loss:0.002295060679483786\n",
      "train loss:0.0043741660431002045\n",
      "train loss:0.000352718746694899\n",
      "train loss:0.004700964156188585\n",
      "train loss:8.423170257710739e-05\n",
      "train loss:0.0014219022999466349\n",
      "train loss:0.0013732708407939106\n",
      "train loss:0.0006001125923267198\n",
      "train loss:2.3682101080787367e-05\n",
      "train loss:0.00019222846999447478\n",
      "train loss:0.001826273087198986\n",
      "train loss:9.251346227798156e-05\n",
      "train loss:0.0004190388459361173\n",
      "train loss:0.003469307513207783\n",
      "train loss:0.0002524318986918498\n",
      "train loss:0.010556206526052183\n",
      "train loss:0.0005335407400470209\n",
      "train loss:0.002854414235992309\n",
      "train loss:0.0005287685713993886\n",
      "train loss:0.00027716407018521435\n",
      "train loss:0.0003269801178333025\n",
      "train loss:9.861886765707276e-05\n",
      "train loss:0.0012275914469130535\n",
      "train loss:0.002054506608321949\n",
      "train loss:0.00012153824274840615\n",
      "train loss:0.0020396309868201167\n",
      "train loss:0.00217241555798052\n",
      "train loss:0.0015941763192993577\n",
      "train loss:4.742137673971569e-05\n",
      "train loss:0.002824121349929069\n",
      "train loss:0.001651620272058209\n",
      "train loss:0.0001950090510446259\n",
      "train loss:0.00022933963629386773\n",
      "train loss:0.0010171956906877971\n",
      "train loss:0.001672287498913062\n",
      "train loss:0.001125773594391436\n",
      "train loss:0.00018500906996346206\n",
      "train loss:0.0016234966046070854\n",
      "train loss:0.0017833319065492892\n",
      "train loss:0.0002109165323315423\n",
      "train loss:0.00034895912859818514\n",
      "train loss:0.00013590018818109852\n",
      "train loss:0.0018898184847195593\n",
      "train loss:0.001443676976341668\n",
      "train loss:0.0004192004889649381\n",
      "train loss:0.0016300723362984678\n",
      "train loss:0.0017049346929720482\n",
      "train loss:0.0013208185479487797\n",
      "train loss:0.0023536125084730702\n",
      "train loss:0.000168860396970118\n",
      "train loss:0.00021051644540517216\n",
      "train loss:0.0026488354241001517\n",
      "train loss:9.438216845245094e-05\n",
      "train loss:0.001431620163928159\n",
      "train loss:0.00473992630114001\n",
      "train loss:0.01315177470859797\n",
      "train loss:0.0007388337941801029\n",
      "train loss:0.00031059080469325145\n",
      "train loss:0.0002914324454702973\n",
      "train loss:0.0004893104583432281\n",
      "train loss:0.003482915283409799\n",
      "train loss:0.0009763135475152528\n",
      "train loss:0.00019910030171165188\n",
      "train loss:0.005401015635121641\n",
      "train loss:0.00021295440336552372\n",
      "train loss:0.0029081758644306393\n",
      "train loss:0.005958125156982177\n",
      "train loss:0.0004530102945170922\n",
      "train loss:0.004182148782936334\n",
      "train loss:0.0035951815999548135\n",
      "train loss:0.0012297110280953597\n",
      "train loss:0.0023118474919129957\n",
      "train loss:0.002094070085673144\n",
      "train loss:0.0017831031838040892\n",
      "train loss:0.002051318547071533\n",
      "train loss:0.002555853358892424\n",
      "train loss:0.00013545571212131828\n",
      "train loss:0.0010350043004211087\n",
      "train loss:0.0008750561820077893\n",
      "train loss:0.0016751546618801177\n",
      "train loss:0.0014167543555151014\n",
      "train loss:0.004005848535702975\n",
      "train loss:0.0002546336334056135\n",
      "train loss:0.0012755582555634244\n",
      "train loss:0.0022482804081920067\n",
      "train loss:0.00024314184358574355\n",
      "train loss:0.000784575829234705\n",
      "train loss:0.0006732425868159367\n",
      "train loss:0.0017798089430944826\n",
      "train loss:9.992239580582163e-05\n",
      "train loss:0.0030875243203249566\n",
      "train loss:0.00018121134123855274\n",
      "train loss:0.0008151726110709591\n",
      "train loss:0.002897557677295684\n",
      "train loss:0.0008461259367828578\n",
      "train loss:0.002858122744792891\n",
      "train loss:0.002409681904762733\n",
      "train loss:0.0013869369225484865\n",
      "train loss:0.00010981413092197991\n",
      "train loss:0.0008623712780802692\n",
      "train loss:0.00014985728757055015\n",
      "train loss:0.0003286794573121516\n",
      "train loss:0.002826826395600915\n",
      "train loss:0.0010681070078986013\n",
      "train loss:0.0330213863418552\n",
      "train loss:0.0008077608603219037\n",
      "train loss:0.0018792522945991791\n",
      "train loss:0.00041620556413468325\n",
      "train loss:0.0008734583864982832\n",
      "train loss:8.326582230594959e-05\n",
      "train loss:0.0018531632722979573\n",
      "train loss:0.00040287279657810223\n",
      "train loss:0.0006878305856379824\n",
      "train loss:0.002005720519703027\n",
      "train loss:0.0006649375247570748\n",
      "train loss:0.0005968791313163942\n",
      "train loss:0.005411229873294724\n",
      "train loss:0.0013128459942682914\n",
      "train loss:0.004539886422230724\n",
      "train loss:0.0013928475007901132\n",
      "train loss:0.0015867278031385667\n",
      "train loss:0.0017092746368171847\n",
      "train loss:0.0004961100386874799\n",
      "train loss:0.0033278308364674664\n",
      "train loss:0.000532521112591075\n",
      "train loss:0.0011998403423395172\n",
      "train loss:0.0007827436442298628\n",
      "train loss:0.0005680521933421994\n",
      "train loss:0.0028585971882811585\n",
      "train loss:0.00016588801034393474\n",
      "train loss:0.0011364743069601697\n",
      "train loss:0.0005676412480507153\n",
      "train loss:0.00027606455468575346\n",
      "train loss:0.001294606967702039\n",
      "train loss:0.002591252284098154\n",
      "train loss:0.0022362430993613093\n",
      "train loss:0.0032023143289987704\n",
      "train loss:0.00020944526351567166\n",
      "train loss:0.0014071464412174007\n",
      "train loss:0.0007815333390877991\n",
      "train loss:0.0006601979682428394\n",
      "train loss:0.0014054329811806461\n",
      "train loss:0.0004301334078642825\n",
      "train loss:0.0005159524422896572\n",
      "train loss:0.0007777301722487147\n",
      "train loss:0.0002497360270929131\n",
      "train loss:3.4565123226234194e-05\n",
      "train loss:7.737983646058697e-05\n",
      "train loss:0.0007228010408150819\n",
      "train loss:0.00012090142013662541\n",
      "train loss:0.0012216757264376398\n",
      "train loss:0.0002459554120149316\n",
      "train loss:0.0002566760239838457\n",
      "train loss:0.0011806228860029373\n",
      "train loss:0.004505503816640645\n",
      "train loss:6.408071389870843e-05\n",
      "train loss:0.0019135493595290837\n",
      "train loss:0.00033780317074303784\n",
      "train loss:0.0018412074005418836\n",
      "train loss:0.003162989583688461\n",
      "train loss:0.00013468814951863304\n",
      "train loss:0.007096053617959495\n",
      "train loss:0.0015078627522487544\n",
      "train loss:0.00193127064791315\n",
      "train loss:0.0016122189904017024\n",
      "train loss:0.0004480205174741043\n",
      "train loss:0.00010229156057982273\n",
      "train loss:0.0043444886262895225\n",
      "train loss:0.0038962431782078918\n",
      "train loss:0.00021713456933432414\n",
      "train loss:0.0010266342683894066\n",
      "train loss:0.00039513513107190096\n",
      "train loss:0.005241070449857861\n",
      "train loss:0.0008651265178770646\n",
      "train loss:0.0017572399256466393\n",
      "train loss:0.002764496839913909\n",
      "train loss:3.377559662723258e-05\n",
      "train loss:0.0006995637826293226\n",
      "train loss:0.00017490001518728293\n",
      "train loss:7.35701802662173e-05\n",
      "train loss:0.00023590780804764238\n",
      "train loss:0.0005383486291916835\n",
      "train loss:0.00010378794496784638\n",
      "train loss:0.003105767027512704\n",
      "train loss:0.002406036076015484\n",
      "train loss:0.00019734017561753509\n",
      "train loss:0.0010472625045266021\n",
      "train loss:0.0023486104872054796\n",
      "train loss:0.00012500223868743918\n",
      "=== epoch:17, train acc:0.997, test acc:0.985 ===\n",
      "train loss:0.0027897716042450528\n",
      "train loss:0.00043688434476029574\n",
      "train loss:0.0008914520349800981\n",
      "train loss:0.0019210928460355228\n",
      "train loss:0.00024760494409373934\n",
      "train loss:0.02340015152560059\n",
      "train loss:0.0016029781186774749\n",
      "train loss:0.00034282028214041826\n",
      "train loss:0.0015733924218687306\n",
      "train loss:0.0017802901811120133\n",
      "train loss:0.00011521203581823302\n",
      "train loss:0.0031856429930049407\n",
      "train loss:0.0007909731985824746\n",
      "train loss:0.0038665498313377104\n",
      "train loss:0.0007665041222843684\n",
      "train loss:0.005688207678366062\n",
      "train loss:0.003458129289542833\n",
      "train loss:0.0006368744764207243\n",
      "train loss:0.0016796959093928732\n",
      "train loss:0.0018177828889205353\n",
      "train loss:0.0012070686595680885\n",
      "train loss:0.003937071744862346\n",
      "train loss:0.0005958387720393575\n",
      "train loss:0.0018123539152746157\n",
      "train loss:0.0011443130930999515\n",
      "train loss:2.9280074851698706e-05\n",
      "train loss:0.003384097025187979\n",
      "train loss:0.0011580503808686234\n",
      "train loss:0.00042818487295021436\n",
      "train loss:0.0014113186292644625\n",
      "train loss:0.0004955386505980342\n",
      "train loss:0.0012418205307383162\n",
      "train loss:0.0015987881029248768\n",
      "train loss:0.0016314061365947405\n",
      "train loss:0.0011693581133027378\n",
      "train loss:4.546287290591364e-05\n",
      "train loss:0.0002915415353959934\n",
      "train loss:6.224893189023859e-05\n",
      "train loss:0.0004127492574440452\n",
      "train loss:0.0012098874411985033\n",
      "train loss:0.0010975721719572306\n",
      "train loss:0.00487733611491235\n",
      "train loss:0.0017750665923624903\n",
      "train loss:0.0017314583610751305\n",
      "train loss:0.002220156378208536\n",
      "train loss:0.0002019901805625862\n",
      "train loss:0.0023949769957927703\n",
      "train loss:0.004315328498357629\n",
      "train loss:0.00017387723369034682\n",
      "train loss:0.0037247660286915197\n",
      "train loss:0.0010116025929660828\n",
      "train loss:0.0009441266556823347\n",
      "train loss:0.002671573283724705\n",
      "train loss:0.0007259624678766706\n",
      "train loss:0.0007433472478597121\n",
      "train loss:0.003702645874620306\n",
      "train loss:0.004190348487786086\n",
      "train loss:0.00935905874766118\n",
      "train loss:0.00334099517071341\n",
      "train loss:0.002358816031344971\n",
      "train loss:0.0008091103080971732\n",
      "train loss:0.005505648401599778\n",
      "train loss:0.00013671734083602494\n",
      "train loss:0.004552221198838382\n",
      "train loss:0.0004947819612694431\n",
      "train loss:0.0008673318160043886\n",
      "train loss:0.0010560700947045646\n",
      "train loss:0.0037164823124503444\n",
      "train loss:0.0030950302432584138\n",
      "train loss:0.018523642708711513\n",
      "train loss:0.002396730736161141\n",
      "train loss:0.0002943136650062973\n",
      "train loss:0.00024895963012857593\n",
      "train loss:0.0013211121047101764\n",
      "train loss:0.00010012864183407444\n",
      "train loss:0.00023814225027069986\n",
      "train loss:0.0014092269546755363\n",
      "train loss:0.00019690539798419984\n",
      "train loss:0.0011528689729754106\n",
      "train loss:0.0007922827672251388\n",
      "train loss:0.0018002499777819575\n",
      "train loss:0.001961208205032156\n",
      "train loss:0.00029019316790779233\n",
      "train loss:4.4864299584780875e-05\n",
      "train loss:0.0008697738780125687\n",
      "train loss:0.005467438266744661\n",
      "train loss:0.0006038159829368736\n",
      "train loss:0.00030460449708305477\n",
      "train loss:0.0003061608434206732\n",
      "train loss:0.0005648309426035504\n",
      "train loss:0.0006261542132247195\n",
      "train loss:0.005596867853852622\n",
      "train loss:0.0014452019923881442\n",
      "train loss:0.0017629984273397593\n",
      "train loss:0.0009164098966936997\n",
      "train loss:0.01909834627937543\n",
      "train loss:0.03778633982583175\n",
      "train loss:0.0004927461627050292\n",
      "train loss:0.0008518565770276644\n",
      "train loss:0.0016134623958486151\n",
      "train loss:0.000401917328610701\n",
      "train loss:0.0014856196642937846\n",
      "train loss:0.0010268122879498922\n",
      "train loss:0.0004639148497877338\n",
      "train loss:0.005438343592496723\n",
      "train loss:0.0009769643854437382\n",
      "train loss:0.0032046028865271563\n",
      "train loss:0.009022450105532856\n",
      "train loss:0.0008011739377823049\n",
      "train loss:0.0015516662672299777\n",
      "train loss:0.0035326954202903383\n",
      "train loss:0.017584000082816915\n",
      "train loss:4.288536432744118e-05\n",
      "train loss:0.016109682559486638\n",
      "train loss:0.014344465712148573\n",
      "train loss:0.00022989477389526538\n",
      "train loss:0.004240314608580674\n",
      "train loss:0.0005595205634963986\n",
      "train loss:0.003927897681903375\n",
      "train loss:0.002160279508774424\n",
      "train loss:0.0036615687586640834\n",
      "train loss:0.003202657537379718\n",
      "train loss:0.001425107494017772\n",
      "train loss:0.0003464271032967074\n",
      "train loss:0.004464932481282961\n",
      "train loss:0.0018211039606959869\n",
      "train loss:0.00010108105567148163\n",
      "train loss:0.003350080298724138\n",
      "train loss:0.00011945421550282912\n",
      "train loss:0.012965221286683981\n",
      "train loss:0.05432129810194779\n",
      "train loss:0.0008979868731751113\n",
      "train loss:0.002974797551754396\n",
      "train loss:0.0004305418802175444\n",
      "train loss:0.0015253520707164852\n",
      "train loss:0.00038736210051397614\n",
      "train loss:0.003272382492860683\n",
      "train loss:0.002841198587392871\n",
      "train loss:0.00023542123842295047\n",
      "train loss:0.009342970915401564\n",
      "train loss:0.005971397818754689\n",
      "train loss:0.000816677222507268\n",
      "train loss:0.0019440965453365949\n",
      "train loss:0.009583708686504117\n",
      "train loss:0.0004954911012108948\n",
      "train loss:0.0004536554885562385\n",
      "train loss:0.0012220012329577062\n",
      "train loss:0.0004310000263195577\n",
      "train loss:0.0014883378218529815\n",
      "train loss:0.001649118739147138\n",
      "train loss:0.006334629192593621\n",
      "train loss:0.001024512867395552\n",
      "train loss:0.003875052823909863\n",
      "train loss:0.0018021897162649888\n",
      "train loss:0.0038967347003614964\n",
      "train loss:0.004061625399853422\n",
      "train loss:0.0053208373718247595\n",
      "train loss:0.00032496856896424537\n",
      "train loss:0.001405425277686814\n",
      "train loss:0.003442707773586183\n",
      "train loss:0.006065995535246892\n",
      "train loss:0.004409388550076801\n",
      "train loss:0.005221689189980361\n",
      "train loss:0.005640109883965236\n",
      "train loss:0.000347495320407143\n",
      "train loss:0.001680925778322252\n",
      "train loss:0.00020434459134662506\n",
      "train loss:0.0016379259007369704\n",
      "train loss:0.0014341469924959874\n",
      "train loss:9.930809252038536e-05\n",
      "train loss:0.0012280122617461147\n",
      "train loss:0.001937181239550245\n",
      "train loss:0.0005017932967462087\n",
      "train loss:0.009751305795956153\n",
      "train loss:0.0038003657724421038\n",
      "train loss:0.001203050348552559\n",
      "train loss:0.0001750544360087053\n",
      "train loss:0.003247281380631747\n",
      "train loss:0.0007144750573785997\n",
      "train loss:5.1895878299512706e-05\n",
      "train loss:0.0025874330061075156\n",
      "train loss:0.00037474787020422095\n",
      "train loss:0.003465162715871207\n",
      "train loss:0.0023492755736218055\n",
      "train loss:0.0002223391892026196\n",
      "train loss:0.0005139737811473216\n",
      "train loss:0.009289076087868537\n",
      "train loss:8.662341528967465e-05\n",
      "train loss:0.0006252195464830368\n",
      "train loss:0.001487746169830123\n",
      "train loss:0.00017450200644400005\n",
      "train loss:0.0015273359988483728\n",
      "train loss:0.00056771114414335\n",
      "train loss:0.005200424280662189\n",
      "train loss:0.006441159496315862\n",
      "train loss:0.027895635832283366\n",
      "train loss:0.0017573749217713673\n",
      "train loss:0.0017276035181677965\n",
      "train loss:0.001226551717498566\n",
      "train loss:0.0023740431455129656\n",
      "train loss:0.0006928419767835592\n",
      "train loss:0.0017090688449988088\n",
      "train loss:0.00012352515040467765\n",
      "train loss:0.0023410918417177094\n",
      "train loss:0.0005198920577955695\n",
      "train loss:0.0012695367295189309\n",
      "train loss:0.001325881044039436\n",
      "train loss:0.0002412123719050383\n",
      "train loss:0.0020915279008723604\n",
      "train loss:0.0017439081314622573\n",
      "train loss:0.00016644606844201797\n",
      "train loss:0.0011541953443576823\n",
      "train loss:0.0009762751387820786\n",
      "train loss:0.0005430954284611571\n",
      "train loss:0.0006485810374738407\n",
      "train loss:0.026288121912369625\n",
      "train loss:0.0005275405442087799\n",
      "train loss:0.0010121018352844669\n",
      "train loss:0.00013931119145591504\n",
      "train loss:0.01323626665644932\n",
      "train loss:0.00039229426736486084\n",
      "train loss:0.0004299002121547118\n",
      "train loss:3.612757385035883e-05\n",
      "train loss:0.005094549746300653\n",
      "train loss:0.0005216904402079951\n",
      "train loss:4.600744003736943e-05\n",
      "train loss:0.0037268506670147727\n",
      "train loss:0.0007722296355808946\n",
      "train loss:0.0005983324032111014\n",
      "train loss:0.005256052308724037\n",
      "train loss:0.0009099264945465114\n",
      "train loss:0.0005057238771447121\n",
      "train loss:0.004597698365061396\n",
      "train loss:0.00023228649841414056\n",
      "train loss:0.0016328281273171794\n",
      "train loss:0.009269142186262739\n",
      "train loss:0.0001352424443304285\n",
      "train loss:0.0006174636767158954\n",
      "train loss:0.0011198878757769208\n",
      "train loss:0.0006884879433015563\n",
      "train loss:0.0006062098728080372\n",
      "train loss:0.001600375570275229\n",
      "train loss:0.0007020037251698439\n",
      "train loss:0.003872401256585352\n",
      "train loss:0.0009805556392094978\n",
      "train loss:0.0036676182842523414\n",
      "train loss:0.0007973134199815866\n",
      "train loss:0.0008504398682323411\n",
      "train loss:0.004576647669487706\n",
      "train loss:0.001834593918341153\n",
      "train loss:0.0005835587517595834\n",
      "train loss:0.0004754135545261274\n",
      "train loss:0.0007126605672629658\n",
      "train loss:0.011678389001419877\n",
      "train loss:0.0021431725497415293\n",
      "train loss:0.0024590073278996385\n",
      "train loss:0.0010478517259902558\n",
      "train loss:0.0005630544984436125\n",
      "train loss:0.0006045175696053784\n",
      "train loss:0.00019397960273742455\n",
      "train loss:0.0031900497450224902\n",
      "train loss:0.004286496423307612\n",
      "train loss:0.0017477005524157323\n",
      "train loss:0.00023346132960769606\n",
      "train loss:0.0014557026101728438\n",
      "train loss:0.0005474122375619475\n",
      "train loss:0.00148060055354043\n",
      "train loss:0.0007026958044887297\n",
      "train loss:0.00240176545653869\n",
      "train loss:0.003481571318022336\n",
      "train loss:0.0026691555365602714\n",
      "train loss:0.002268827840309956\n",
      "train loss:0.0007822806397005776\n",
      "train loss:0.007998278672552107\n",
      "train loss:0.004476669815420967\n",
      "train loss:0.0009022276648293129\n",
      "train loss:0.000495091777062954\n",
      "train loss:0.007039840913628056\n",
      "train loss:0.001379351956138673\n",
      "train loss:0.005921365502190861\n",
      "train loss:0.009317167000524177\n",
      "train loss:0.000614276429667274\n",
      "train loss:0.0008770435871742865\n",
      "train loss:0.00013887189600920722\n",
      "train loss:0.005496479430659828\n",
      "train loss:0.0007068006524420358\n",
      "train loss:8.885433927173751e-05\n",
      "train loss:0.001849903076204255\n",
      "train loss:0.001929235108134362\n",
      "train loss:0.0024081223630336244\n",
      "train loss:0.0011702974427880428\n",
      "train loss:0.0021536182512176343\n",
      "train loss:0.0007299113649796983\n",
      "train loss:0.001160157696618299\n",
      "train loss:0.007095170332540277\n",
      "train loss:0.010173772870217961\n",
      "train loss:0.0018278698558785523\n",
      "train loss:0.003992583510115317\n",
      "train loss:0.000487433509897882\n",
      "train loss:0.0010821771022593177\n",
      "train loss:5.850653069176362e-05\n",
      "train loss:0.0005210843932016368\n",
      "train loss:0.0001042370067857826\n",
      "train loss:0.00015228431867026244\n",
      "train loss:0.0004886269432038024\n",
      "train loss:0.005995277333655413\n",
      "train loss:0.0042986599882805085\n",
      "train loss:0.006173550565249914\n",
      "train loss:0.0006931706473206168\n",
      "train loss:0.0006862807328714118\n",
      "train loss:0.0007383751263238622\n",
      "train loss:3.6340713962646376e-05\n",
      "train loss:0.0032045897976657016\n",
      "train loss:0.002039015556737275\n",
      "train loss:0.0012580792866772226\n",
      "train loss:0.0024215045073080047\n",
      "train loss:0.00013430830458537927\n",
      "train loss:0.0035257856198263274\n",
      "train loss:0.0002138951097547051\n",
      "train loss:0.0033367342541839153\n",
      "train loss:0.0010524278206968571\n",
      "train loss:0.0011722211066742872\n",
      "train loss:0.002555202586046869\n",
      "train loss:0.007860868108464621\n",
      "train loss:0.0011650802205428802\n",
      "train loss:0.003697460865663958\n",
      "train loss:0.00039561625852179485\n",
      "train loss:0.004276464973058829\n",
      "train loss:0.0016162108751956031\n",
      "train loss:0.0017820466413806582\n",
      "train loss:0.001565538791096056\n",
      "train loss:0.0018691123995336913\n",
      "train loss:0.010950634534864384\n",
      "train loss:0.00132972095204333\n",
      "train loss:0.0023894403345014904\n",
      "train loss:0.002017907910470114\n",
      "train loss:0.0003008080063812252\n",
      "train loss:9.780017037551599e-05\n",
      "train loss:0.0008384766875952087\n",
      "train loss:0.002579439905443761\n",
      "train loss:9.830783981210594e-05\n",
      "train loss:0.002867820449513798\n",
      "train loss:0.0002564262717852593\n",
      "train loss:0.002088911169365672\n",
      "train loss:0.002145400299383528\n",
      "train loss:0.0011364772772275093\n",
      "train loss:0.00046860431292343024\n",
      "train loss:0.00011170325631429707\n",
      "train loss:0.002867345254250884\n",
      "train loss:0.0002618282130544882\n",
      "train loss:0.0004079737253470094\n",
      "train loss:0.0013998712200142289\n",
      "train loss:0.00024389793524058726\n",
      "train loss:0.0017236164404730078\n",
      "train loss:0.003725408947374104\n",
      "train loss:0.0003050409771964248\n",
      "train loss:0.0009306654060527654\n",
      "train loss:0.0010453641061907526\n",
      "train loss:0.00552382459114048\n",
      "train loss:0.004421479110542531\n",
      "train loss:0.001057007750175953\n",
      "train loss:0.0024442349644517814\n",
      "train loss:0.0007798326644042158\n",
      "train loss:0.001629487988586383\n",
      "train loss:0.004577602723557655\n",
      "train loss:0.0004085374579810913\n",
      "train loss:0.0007328022196523906\n",
      "train loss:0.002592138771005953\n",
      "train loss:0.001920401747791993\n",
      "train loss:0.002083961131728952\n",
      "train loss:0.0011075903532725517\n",
      "train loss:0.003223853274857853\n",
      "train loss:0.00033932402379028876\n",
      "train loss:0.0053210182932379654\n",
      "train loss:0.0012778204467807073\n",
      "train loss:0.0005024291038542377\n",
      "train loss:0.005843459300696604\n",
      "train loss:6.673977401643188e-05\n",
      "train loss:0.001112856389218824\n",
      "train loss:0.0002940529222523424\n",
      "train loss:0.0009146106588813982\n",
      "train loss:0.004241211539414933\n",
      "train loss:0.002088580758036547\n",
      "train loss:0.0006538853922692722\n",
      "train loss:0.0017976894513033433\n",
      "train loss:0.0038178129715227237\n",
      "train loss:0.006304111546455311\n",
      "train loss:0.003515482851759756\n",
      "train loss:0.0030528883569115846\n",
      "train loss:0.00015764607521999625\n",
      "train loss:0.0008340206395531331\n",
      "train loss:0.002238882335057901\n",
      "train loss:0.00109807220271065\n",
      "train loss:0.0020957065526295616\n",
      "train loss:0.01678397224017704\n",
      "train loss:0.0002423696968453733\n",
      "train loss:0.0003502147544323713\n",
      "train loss:0.0013054201452158182\n",
      "train loss:0.0011354927963158623\n",
      "train loss:0.0011131773737836157\n",
      "train loss:0.004079369783532234\n",
      "train loss:0.0006457541849005427\n",
      "train loss:0.004874447500484794\n",
      "train loss:0.009054700784101519\n",
      "train loss:0.0013583877693661847\n",
      "train loss:0.0007837339567498026\n",
      "train loss:0.0016435600470057247\n",
      "train loss:0.001528299347728225\n",
      "train loss:0.0027761221364788428\n",
      "train loss:0.0017812026276146783\n",
      "train loss:0.0002126882741699345\n",
      "train loss:0.004357888905531223\n",
      "train loss:0.0007475294503458709\n",
      "train loss:0.001325099727282632\n",
      "train loss:0.00045558700747572645\n",
      "train loss:5.2232899294461954e-05\n",
      "train loss:0.0018783921722681412\n",
      "train loss:0.0003290192137397722\n",
      "train loss:0.0040307006502984435\n",
      "train loss:0.0019204307198724831\n",
      "train loss:0.001123928679033444\n",
      "train loss:0.0016184822192940197\n",
      "train loss:0.0003006433974787269\n",
      "train loss:0.0011227744606972848\n",
      "train loss:0.00011029975085655262\n",
      "train loss:0.001132598947614682\n",
      "train loss:0.009229571516030313\n",
      "train loss:0.002181761153382697\n",
      "train loss:4.339319351170035e-05\n",
      "train loss:0.0002270299744214753\n",
      "train loss:0.005164351070743062\n",
      "train loss:0.007127393294889876\n",
      "train loss:0.0006494870019659376\n",
      "train loss:0.00115856929924014\n",
      "train loss:0.00031960052258682745\n",
      "train loss:0.00015937469027004704\n",
      "train loss:0.0006781823909005574\n",
      "train loss:0.002886923224875068\n",
      "train loss:0.0021049064430765253\n",
      "train loss:0.000521541396577274\n",
      "train loss:5.81498898079238e-05\n",
      "train loss:0.004852643219196713\n",
      "train loss:0.00019443968583474647\n",
      "train loss:0.0030469567049791393\n",
      "train loss:0.0009050931499118565\n",
      "train loss:0.0012265002416053403\n",
      "train loss:0.0006809934533230016\n",
      "train loss:0.002532551097347865\n",
      "train loss:0.0013598639058070654\n",
      "train loss:0.001748423404683342\n",
      "train loss:0.07897533028075575\n",
      "train loss:0.0004117290870987897\n",
      "train loss:0.0012506609189323781\n",
      "train loss:0.001541417838793971\n",
      "train loss:0.0003493213941027269\n",
      "train loss:0.0031609059582469855\n",
      "train loss:0.0017838303808642559\n",
      "train loss:0.003284467933178829\n",
      "train loss:0.011676330550141872\n",
      "train loss:0.0019108820266742362\n",
      "train loss:9.966649781665622e-05\n",
      "train loss:0.004791216173806383\n",
      "train loss:0.0010658461144411125\n",
      "train loss:0.0007090053174000032\n",
      "train loss:3.2424047334243106e-05\n",
      "train loss:4.249825347418984e-05\n",
      "train loss:0.018954621625993248\n",
      "train loss:5.0385323684114776e-05\n",
      "train loss:0.0014530216084618652\n",
      "train loss:0.0002767418826636617\n",
      "train loss:0.003604003252621198\n",
      "train loss:0.001180352638342768\n",
      "train loss:0.0013954794204286414\n",
      "train loss:0.00023998937942093285\n",
      "train loss:7.065983108688005e-05\n",
      "train loss:0.000887183539223723\n",
      "train loss:0.0012957359224190226\n",
      "train loss:0.0008149537242778558\n",
      "train loss:0.0021420720247774076\n",
      "train loss:4.811726400066576e-05\n",
      "train loss:0.0021655213574652125\n",
      "train loss:0.0012079122641228922\n",
      "train loss:0.0011949562783434423\n",
      "train loss:0.017258532327612323\n",
      "train loss:0.0003217059814462594\n",
      "train loss:0.007959314979994728\n",
      "train loss:0.00030791776512356704\n",
      "train loss:0.0006382349988232104\n",
      "train loss:0.00010226671701367753\n",
      "train loss:0.0009174096962672892\n",
      "train loss:0.004088833734382679\n",
      "train loss:0.002223100412866645\n",
      "train loss:0.0017500301579685172\n",
      "train loss:0.0005314007012604597\n",
      "train loss:0.00019501274895624953\n",
      "train loss:0.0005313761941648156\n",
      "train loss:5.009162168834477e-05\n",
      "train loss:0.0011445957642724578\n",
      "train loss:0.0009309483570633803\n",
      "train loss:0.008624660062081452\n",
      "train loss:0.0018780444511583083\n",
      "train loss:0.01812873824185364\n",
      "train loss:0.0017143096302043406\n",
      "train loss:0.002065089609460387\n",
      "train loss:0.0005200772996670505\n",
      "train loss:0.0005560594829910669\n",
      "train loss:0.0005947120430689461\n",
      "train loss:0.0021252092039853385\n",
      "train loss:0.004016420347092498\n",
      "train loss:0.00032732385994024165\n",
      "train loss:0.0008418909026030877\n",
      "train loss:0.0006131119020237074\n",
      "train loss:0.00206521977133794\n",
      "train loss:0.0006881659587681265\n",
      "train loss:9.794704957480534e-05\n",
      "train loss:0.0013185565782360964\n",
      "train loss:0.009013591860701275\n",
      "train loss:0.0007022817982103673\n",
      "train loss:0.0009531352458021582\n",
      "train loss:0.008346260486359865\n",
      "train loss:0.014332154745373426\n",
      "train loss:0.00015344726434706493\n",
      "train loss:0.001272799834189981\n",
      "train loss:0.0017589807736879787\n",
      "train loss:0.023079458493058397\n",
      "train loss:0.0003647695574802045\n",
      "train loss:0.0024557970046265257\n",
      "train loss:2.854209471127028e-05\n",
      "train loss:0.0004913605674333985\n",
      "train loss:0.00016618557831581959\n",
      "train loss:0.0018980370829837986\n",
      "train loss:0.01027538137070675\n",
      "train loss:0.0011261598313618672\n",
      "train loss:0.0009828009714101013\n",
      "train loss:0.002650177404394277\n",
      "train loss:0.002638370786201613\n",
      "train loss:0.0011168092990956379\n",
      "train loss:0.00011431219562036841\n",
      "train loss:0.00022827822917641236\n",
      "train loss:0.0031653704956323588\n",
      "train loss:0.003827698808375946\n",
      "train loss:0.0012092707815703802\n",
      "train loss:0.00509715290301828\n",
      "train loss:0.0013422638865794527\n",
      "train loss:0.0014889797103261348\n",
      "train loss:0.002035137973780264\n",
      "train loss:0.000706646994357017\n",
      "train loss:0.00048816105657930166\n",
      "train loss:0.0005674913157840886\n",
      "train loss:0.00030991242079245977\n",
      "train loss:0.0016164439109592446\n",
      "train loss:0.001102150464461618\n",
      "train loss:0.0005954269283156464\n",
      "train loss:0.0003606415399616654\n",
      "train loss:0.004406120753406478\n",
      "train loss:0.0008960348957996117\n",
      "train loss:0.0013769028286756703\n",
      "train loss:0.000893300369277842\n",
      "train loss:0.003886008964810999\n",
      "train loss:0.003916271110072574\n",
      "train loss:0.005039069937816732\n",
      "train loss:0.000567650804431882\n",
      "train loss:0.0001586417536659802\n",
      "train loss:0.001974908989724176\n",
      "train loss:0.00012897461911469415\n",
      "train loss:0.00018855952209991726\n",
      "train loss:0.0025338743342492513\n",
      "train loss:0.0077376591224474186\n",
      "train loss:0.0009644397419454457\n",
      "train loss:0.0001023724002532808\n",
      "train loss:9.995235675920977e-05\n",
      "train loss:0.0010668441627073016\n",
      "train loss:0.0032855162898427614\n",
      "train loss:0.0002569999125417792\n",
      "train loss:0.0037555198190381382\n",
      "train loss:0.0002482959313426183\n",
      "train loss:0.02843785173091866\n",
      "train loss:0.001461106059174516\n",
      "train loss:0.0004756759558793639\n",
      "train loss:0.00030633416473958413\n",
      "train loss:0.0005187262837369937\n",
      "train loss:0.0008738992212857442\n",
      "train loss:0.000889177357664698\n",
      "train loss:0.0010841103045623446\n",
      "train loss:0.041970395219524156\n",
      "train loss:0.00040739106971085845\n",
      "train loss:0.0002148208212292808\n",
      "train loss:0.0004205866045879152\n",
      "train loss:6.679738554761756e-05\n",
      "train loss:0.0012580481486422642\n",
      "train loss:0.00010455073250207337\n",
      "train loss:0.0004751320374513274\n",
      "train loss:0.0002793884069247687\n",
      "train loss:0.00027553187591614845\n",
      "train loss:0.000791257019265148\n",
      "train loss:0.00017491997105868504\n",
      "train loss:0.0004648723646568678\n",
      "train loss:3.393160504251104e-05\n",
      "train loss:0.0011986113520242516\n",
      "train loss:0.002003278724039784\n",
      "=== epoch:18, train acc:0.996, test acc:0.985 ===\n",
      "train loss:0.00028583738662431323\n",
      "train loss:0.006954367478449774\n",
      "train loss:0.0011938318527222628\n",
      "train loss:0.00797906277801369\n",
      "train loss:0.0010130615511292787\n",
      "train loss:0.0006188508032239036\n",
      "train loss:0.00035871342534416915\n",
      "train loss:0.005710848389476497\n",
      "train loss:0.0015166893994107856\n",
      "train loss:0.003624233358574318\n",
      "train loss:0.0016531294474285633\n",
      "train loss:0.002145716819641942\n",
      "train loss:0.009535663512167647\n",
      "train loss:0.00036818621805278514\n",
      "train loss:0.0001711537566052119\n",
      "train loss:0.0001718553066546352\n",
      "train loss:0.00022644583797305177\n",
      "train loss:0.00038289886161377225\n",
      "train loss:0.0009347701354809345\n",
      "train loss:0.00034599455809580034\n",
      "train loss:0.003608559612331135\n",
      "train loss:0.0001915677032792343\n",
      "train loss:0.0002912442036481317\n",
      "train loss:0.003030125659628779\n",
      "train loss:0.0001386956910760775\n",
      "train loss:0.0026094738230991927\n",
      "train loss:0.00021165685151078886\n",
      "train loss:0.004906286627037369\n",
      "train loss:0.013513982328624663\n",
      "train loss:0.0008779753937382633\n",
      "train loss:0.0001367602994955917\n",
      "train loss:0.0002602278149459097\n",
      "train loss:0.0004611092945620957\n",
      "train loss:0.0005582081454068146\n",
      "train loss:0.0017406711529341736\n",
      "train loss:0.00035573929222457184\n",
      "train loss:0.00024897277446445554\n",
      "train loss:0.002270875819862077\n",
      "train loss:0.016207279728251554\n",
      "train loss:0.0008313725568859402\n",
      "train loss:0.0016470088358521995\n",
      "train loss:0.003280153079725383\n",
      "train loss:0.0002125140738674541\n",
      "train loss:0.0005215643952182966\n",
      "train loss:0.0021348754078795705\n",
      "train loss:5.159114678095423e-05\n",
      "train loss:0.0007288057215298308\n",
      "train loss:0.0003644556538912984\n",
      "train loss:0.020927136761167708\n",
      "train loss:0.00025137161313193104\n",
      "train loss:0.006760396873256815\n",
      "train loss:0.0002473515265234896\n",
      "train loss:0.00031095122504815254\n",
      "train loss:0.00022958594123190462\n",
      "train loss:0.002108348462779489\n",
      "train loss:0.0006959594078631446\n",
      "train loss:0.0011488468339127158\n",
      "train loss:0.020124400198357897\n",
      "train loss:0.0146753779853665\n",
      "train loss:0.002526066773069774\n",
      "train loss:0.0014817236503997084\n",
      "train loss:0.0007271629293511188\n",
      "train loss:0.0005296030861913537\n",
      "train loss:0.0016473102193882904\n",
      "train loss:0.004455386355266802\n",
      "train loss:0.007983259743445053\n",
      "train loss:0.00015201314591568115\n",
      "train loss:0.0004649165456598665\n",
      "train loss:4.643565379519557e-05\n",
      "train loss:0.0009785749274615896\n",
      "train loss:0.0058627911860711975\n",
      "train loss:0.0014874916825715447\n",
      "train loss:0.0014445315607780993\n",
      "train loss:0.0006233431298464602\n",
      "train loss:0.0001316472567067813\n",
      "train loss:0.0001282031245738464\n",
      "train loss:0.00021168780880497656\n",
      "train loss:0.0009198271410699256\n",
      "train loss:0.0018435571074554421\n",
      "train loss:0.00026692449308452317\n",
      "train loss:0.0007563147757782283\n",
      "train loss:0.0015965413939858807\n",
      "train loss:3.84598145920146e-05\n",
      "train loss:9.773363929934154e-05\n",
      "train loss:0.013327008273716192\n",
      "train loss:0.0004983961796030668\n",
      "train loss:0.0016889067712043129\n",
      "train loss:0.0007821032878337903\n",
      "train loss:0.0021673336358669477\n",
      "train loss:8.253266980481628e-05\n",
      "train loss:2.019698297888741e-05\n",
      "train loss:0.05327266613911148\n",
      "train loss:0.001435581010422707\n",
      "train loss:0.000744766521058611\n",
      "train loss:0.0023161403165579838\n",
      "train loss:0.018371793050291785\n",
      "train loss:1.831765200634005e-05\n",
      "train loss:0.000732644236294583\n",
      "train loss:0.003624068869007019\n",
      "train loss:0.0004202126511758189\n",
      "train loss:0.00039477739341647617\n",
      "train loss:5.898901532632776e-05\n",
      "train loss:0.0001124351006535443\n",
      "train loss:0.0025614658809875305\n",
      "train loss:0.0019098477092034868\n",
      "train loss:0.003702932777903874\n",
      "train loss:0.001339081485564002\n",
      "train loss:0.0006473025294108445\n",
      "train loss:0.0011928173465168713\n",
      "train loss:0.00256335835919082\n",
      "train loss:6.077005798572674e-05\n",
      "train loss:0.0015548082452772716\n",
      "train loss:0.0002882242148924556\n",
      "train loss:0.0016582336204163614\n",
      "train loss:0.00011677816636727797\n",
      "train loss:0.005862371319027148\n",
      "train loss:0.0003387973143199012\n",
      "train loss:0.012804155974759321\n",
      "train loss:0.00017232498910795031\n",
      "train loss:0.0005200694506142975\n",
      "train loss:0.00971639480882861\n",
      "train loss:0.00031473783926926215\n",
      "train loss:0.0019836555352955093\n",
      "train loss:0.00025435011606355913\n",
      "train loss:0.001750363527165153\n",
      "train loss:0.0002487958194817767\n",
      "train loss:7.021211466859382e-05\n",
      "train loss:0.00017633339842998663\n",
      "train loss:0.0014494992738681705\n",
      "train loss:0.0014999732933204523\n",
      "train loss:0.0014503105546877523\n",
      "train loss:0.001753212182645174\n",
      "train loss:0.003994709252334508\n",
      "train loss:0.0004574038267284694\n",
      "train loss:0.004687409449099293\n",
      "train loss:0.015193307475589928\n",
      "train loss:0.0009998800774795084\n",
      "train loss:0.0024365025495467238\n",
      "train loss:0.0015920542976614774\n",
      "train loss:0.0017171942455410224\n",
      "train loss:0.0006123191702418963\n",
      "train loss:0.0010628357151625705\n",
      "train loss:0.001058321968489089\n",
      "train loss:0.001535986829432873\n",
      "train loss:0.0004004303726495613\n",
      "train loss:0.0008882567945806681\n",
      "train loss:0.000403256762555169\n",
      "train loss:0.0006087867336429332\n",
      "train loss:0.0010385254297725773\n",
      "train loss:0.0003549040173265201\n",
      "train loss:0.0005239507848909766\n",
      "train loss:0.001417215813139694\n",
      "train loss:0.0012712036779164554\n",
      "train loss:0.002879111040436079\n",
      "train loss:7.156581129506746e-05\n",
      "train loss:0.0011099541553154465\n",
      "train loss:0.0002590249244033831\n",
      "train loss:0.00048697213573950423\n",
      "train loss:0.0002579968791509192\n",
      "train loss:0.0006592092553415807\n",
      "train loss:0.0026203271386415383\n",
      "train loss:0.0007742088160123772\n",
      "train loss:0.0038028005627909977\n",
      "train loss:0.0023682003325676344\n",
      "train loss:0.0006217384015395299\n",
      "train loss:0.0004363690760374761\n",
      "train loss:0.00017913536140604067\n",
      "train loss:0.0002809859819870734\n",
      "train loss:9.699426316630915e-05\n",
      "train loss:0.002842751669941079\n",
      "train loss:0.00021649492775684768\n",
      "train loss:0.0002198541198059709\n",
      "train loss:9.736620323111982e-05\n",
      "train loss:0.0002652315708103784\n",
      "train loss:0.0034969805161157398\n",
      "train loss:0.00024793754691147726\n",
      "train loss:0.0028978034572062256\n",
      "train loss:0.0008852013929322325\n",
      "train loss:0.0024258196897944816\n",
      "train loss:7.725862592888405e-05\n",
      "train loss:0.0016297272922946734\n",
      "train loss:0.0004546587865332963\n",
      "train loss:0.0009702395729845394\n",
      "train loss:0.00017302773806861577\n",
      "train loss:0.0021957017876705026\n",
      "train loss:0.002698738064961754\n",
      "train loss:0.00037344284921693097\n",
      "train loss:0.00036880744656280043\n",
      "train loss:0.0007394820458988974\n",
      "train loss:0.00010036882710041901\n",
      "train loss:0.0003026680934346265\n",
      "train loss:0.003987005205547629\n",
      "train loss:0.0003262711306438437\n",
      "train loss:0.010049598766814669\n",
      "train loss:3.0105268493314642e-05\n",
      "train loss:0.0005187833625415581\n",
      "train loss:0.011499190900224747\n",
      "train loss:0.0009377850189783353\n",
      "train loss:0.0008323230452668448\n",
      "train loss:0.0025428282653623805\n",
      "train loss:0.0026728418907503897\n",
      "train loss:0.000279600090086608\n",
      "train loss:0.0001085348082727809\n",
      "train loss:0.00033074726295040385\n",
      "train loss:0.004995193607922851\n",
      "train loss:0.0021819503542210242\n",
      "train loss:0.0006195479460236361\n",
      "train loss:0.0015955831759762599\n",
      "train loss:0.0009560433896437391\n",
      "train loss:8.843364355276308e-05\n",
      "train loss:0.0021389788323861814\n",
      "train loss:0.002132960685163737\n",
      "train loss:0.00043617683394571677\n",
      "train loss:0.0020102572675915146\n",
      "train loss:0.0007649500582345542\n",
      "train loss:0.0013043236195173233\n",
      "train loss:0.0019214107235162705\n",
      "train loss:0.0007900926316662081\n",
      "train loss:0.001319272671789774\n",
      "train loss:0.00016933534170955933\n",
      "train loss:0.0048250051014882105\n",
      "train loss:0.002760847976327797\n",
      "train loss:0.0004919944456811847\n",
      "train loss:1.5235570582537379e-05\n",
      "train loss:0.00033943389805313195\n",
      "train loss:0.00011466754757331253\n",
      "train loss:0.0023596610435304755\n",
      "train loss:0.0011969937096370474\n",
      "train loss:0.0018729761331840716\n",
      "train loss:0.000480036888437112\n",
      "train loss:0.001330951708787\n",
      "train loss:0.0008046451736838699\n",
      "train loss:0.0007615934129448155\n",
      "train loss:0.005112374273788827\n",
      "train loss:0.000440027509247407\n",
      "train loss:0.00026698078059142255\n",
      "train loss:0.00011769617878706694\n",
      "train loss:0.00022813175843763525\n",
      "train loss:0.0007925383688991181\n",
      "train loss:0.00032376282486484533\n",
      "train loss:0.0010870285394630654\n",
      "train loss:0.001171724326761975\n",
      "train loss:0.001147850667990605\n",
      "train loss:0.0015061850370411607\n",
      "train loss:0.009836382450444296\n",
      "train loss:0.0017823114373685775\n",
      "train loss:0.00043689234787746027\n",
      "train loss:0.0006922537452004906\n",
      "train loss:0.07893063800212534\n",
      "train loss:0.0002138805748929502\n",
      "train loss:0.00024330205265367635\n",
      "train loss:0.001762858078057253\n",
      "train loss:0.0023962201269046445\n",
      "train loss:0.0012394897111953592\n",
      "train loss:0.002108303158928943\n",
      "train loss:0.001262168389503763\n",
      "train loss:0.008297841979373688\n",
      "train loss:0.00018577235841542078\n",
      "train loss:0.0004427279466639632\n",
      "train loss:0.008174015413553998\n",
      "train loss:0.0001384250656822581\n",
      "train loss:0.00018174215272287477\n",
      "train loss:0.00018375910034424038\n",
      "train loss:0.0029917636237633853\n",
      "train loss:0.00020103064966443422\n",
      "train loss:0.00030924014812364406\n",
      "train loss:0.0016704465703839518\n",
      "train loss:0.00017316696953770334\n",
      "train loss:0.0003911525593482671\n",
      "train loss:0.0019428326577142965\n",
      "train loss:0.0007562103065622138\n",
      "train loss:0.0016652992938075767\n",
      "train loss:0.0009858523237608965\n",
      "train loss:0.0006568612913891224\n",
      "train loss:0.0014443597970230943\n",
      "train loss:0.0023318017255322316\n",
      "train loss:0.0035400475353411388\n",
      "train loss:0.002157584814157303\n",
      "train loss:0.0019670546270945406\n",
      "train loss:0.00018342762570747824\n",
      "train loss:0.011191563507397733\n",
      "train loss:0.004126527945260814\n",
      "train loss:0.00269454235054755\n",
      "train loss:0.001082436133686875\n",
      "train loss:0.0008425091136640861\n",
      "train loss:0.00043919192145013155\n",
      "train loss:0.000409919729630899\n",
      "train loss:0.0005507206254162177\n",
      "train loss:0.0002272149461489884\n",
      "train loss:0.0010058097563021352\n",
      "train loss:0.0017461964865192942\n",
      "train loss:0.002537659126783098\n",
      "train loss:0.0004128050834628972\n",
      "train loss:0.0004060313972768384\n",
      "train loss:0.00013604802179758603\n",
      "train loss:6.173645900660603e-05\n",
      "train loss:0.00039210857316408434\n",
      "train loss:0.001234497451908833\n",
      "train loss:5.293175892597283e-05\n",
      "train loss:0.000585934336883884\n",
      "train loss:9.214190650311642e-05\n",
      "train loss:0.00048383372106288575\n",
      "train loss:0.0029586086261441467\n",
      "train loss:0.00047696115734371746\n",
      "train loss:0.001976877018257846\n",
      "train loss:0.0033223650449340845\n",
      "train loss:0.0004449429160635102\n",
      "train loss:0.00022511402669026282\n",
      "train loss:0.0016311659105560379\n",
      "train loss:0.001558357917785336\n",
      "train loss:0.0012991852951625448\n",
      "train loss:0.00257011007054119\n",
      "train loss:0.0020029858366244794\n",
      "train loss:0.001149511085545462\n",
      "train loss:0.0010019187879511595\n",
      "train loss:0.0005393500121139675\n",
      "train loss:0.002404902611196932\n",
      "train loss:0.0010777376474257073\n",
      "train loss:0.0010368612743324936\n",
      "train loss:0.0013897999624573004\n",
      "train loss:0.000839436006147494\n",
      "train loss:5.3065468779053906e-05\n",
      "train loss:0.0010011281044083912\n",
      "train loss:0.000358651286991587\n",
      "train loss:0.0015599268225379612\n",
      "train loss:0.0006868697196783017\n",
      "train loss:0.002569812401427949\n",
      "train loss:0.00013250072328129962\n",
      "train loss:0.0004076658589974124\n",
      "train loss:0.00020536365910450098\n",
      "train loss:0.0008837482284481632\n",
      "train loss:0.0038179579808661395\n",
      "train loss:0.0021622318218896762\n",
      "train loss:0.0007126691848045191\n",
      "train loss:0.00040702318230112\n",
      "train loss:0.0006406101105348512\n",
      "train loss:0.001352963515885269\n",
      "train loss:0.0013137071885263524\n",
      "train loss:6.762884126773654e-05\n",
      "train loss:0.00026114447467813875\n",
      "train loss:0.00029835016372553347\n",
      "train loss:0.0009421905274374631\n",
      "train loss:0.0006935534011560202\n",
      "train loss:0.002104658744899796\n",
      "train loss:0.0004875215382459529\n",
      "train loss:2.329333562308322e-05\n",
      "train loss:0.0009287581383765355\n",
      "train loss:0.00015259628480728823\n",
      "train loss:0.0003230337127770451\n",
      "train loss:0.00046348787793363817\n",
      "train loss:0.0003669288257699655\n",
      "train loss:0.0012618237879328303\n",
      "train loss:4.994005063553658e-05\n",
      "train loss:0.0009040074059496829\n",
      "train loss:8.054933114777103e-05\n",
      "train loss:0.00016361344682661302\n",
      "train loss:0.0012274491148861193\n",
      "train loss:0.0011299170274787973\n",
      "train loss:0.0001228967852840959\n",
      "train loss:0.0007549484248553725\n",
      "train loss:0.00024490521316977156\n",
      "train loss:0.0016172861490130889\n",
      "train loss:0.00045285748552183284\n",
      "train loss:0.000104060601481753\n",
      "train loss:0.0004546460877756\n",
      "train loss:0.0005405474050089601\n",
      "train loss:0.001812246976953215\n",
      "train loss:0.002415238631674612\n",
      "train loss:0.0005455178753528896\n",
      "train loss:4.561310097911801e-05\n",
      "train loss:0.0002614404796137368\n",
      "train loss:0.00013097793455277604\n",
      "train loss:0.0001675500104425629\n",
      "train loss:0.000530159002403183\n",
      "train loss:0.0020447840823258024\n",
      "train loss:0.00011234443516160073\n",
      "train loss:0.005220372031914306\n",
      "train loss:1.9922844471138206e-05\n",
      "train loss:0.00013071710997251366\n",
      "train loss:0.002890736003860206\n",
      "train loss:0.0002685699811817561\n",
      "train loss:0.0007820972414131467\n",
      "train loss:0.00041009051020319946\n",
      "train loss:0.00040368171326419686\n",
      "train loss:0.0004712186549211755\n",
      "train loss:0.0011754355325103985\n",
      "train loss:0.0001880357506775683\n",
      "train loss:0.002012406780775605\n",
      "train loss:0.0003414548619820295\n",
      "train loss:0.0004692130731401928\n",
      "train loss:0.0013385619772069562\n",
      "train loss:0.00010503884127503437\n",
      "train loss:0.0016122077160454188\n",
      "train loss:0.00011284217802625646\n",
      "train loss:6.674912094900374e-05\n",
      "train loss:0.010767771482405925\n",
      "train loss:0.0001447252705825717\n",
      "train loss:5.729507580522171e-06\n",
      "train loss:0.00038955193538656174\n",
      "train loss:0.0004849323704986059\n",
      "train loss:0.0006649613963308785\n",
      "train loss:0.0002781940216541314\n",
      "train loss:0.00012439107771827472\n",
      "train loss:0.00015186383624250693\n",
      "train loss:0.0025835389353935697\n",
      "train loss:0.00047567051995504926\n",
      "train loss:0.0005330116357299326\n",
      "train loss:0.00039572221599837006\n",
      "train loss:0.00039103077520153366\n",
      "train loss:0.000688647525314746\n",
      "train loss:0.00047593390276044165\n",
      "train loss:0.0009542653539778934\n",
      "train loss:0.0025919444903545834\n",
      "train loss:0.000573669486901421\n",
      "train loss:0.007704108662552755\n",
      "train loss:0.0013447895363577597\n",
      "train loss:0.00021102983273277954\n",
      "train loss:0.0014449660090970107\n",
      "train loss:0.00040754606141800366\n",
      "train loss:0.005867128299573438\n",
      "train loss:0.0012601340911602065\n",
      "train loss:0.0007504544884825424\n",
      "train loss:0.0009414934088746343\n",
      "train loss:0.0009610376883237962\n",
      "train loss:0.0009515926605772033\n",
      "train loss:0.004076904446757596\n",
      "train loss:0.003112319949587395\n",
      "train loss:0.0036740731721368876\n",
      "train loss:0.0033594211612960638\n",
      "train loss:0.00022102176094513648\n",
      "train loss:0.000337155883452565\n",
      "train loss:0.01553100380159336\n",
      "train loss:0.001804404631341292\n",
      "train loss:0.001345416495187054\n",
      "train loss:0.0010013463080434317\n",
      "train loss:0.04257774681633055\n",
      "train loss:0.00031483781477855994\n",
      "train loss:0.0010841934515993584\n",
      "train loss:5.018486251763605e-05\n",
      "train loss:0.0004694609506851398\n",
      "train loss:0.0036295456268428637\n",
      "train loss:0.00027698368835080313\n",
      "train loss:0.002823214377289452\n",
      "train loss:0.005035883776099548\n",
      "train loss:0.0005710003790927238\n",
      "train loss:0.00046613785480212745\n",
      "train loss:0.0017552815615718153\n",
      "train loss:0.003356762105340719\n",
      "train loss:0.002820070265338574\n",
      "train loss:0.0011529442914060876\n",
      "train loss:0.0012925426008154111\n",
      "train loss:0.00039706701348288123\n",
      "train loss:0.002073505262949422\n",
      "train loss:0.0010931758224048747\n",
      "train loss:0.00016234698534079873\n",
      "train loss:0.0004705287475845512\n",
      "train loss:0.0008332549276207995\n",
      "train loss:0.0047797388030064916\n",
      "train loss:0.001765204151956415\n",
      "train loss:0.0015240834953462077\n",
      "train loss:0.003212294153128139\n",
      "train loss:0.0008924474176882194\n",
      "train loss:0.002044378635741847\n",
      "train loss:0.0014391239422660823\n",
      "train loss:0.0027216567714677927\n",
      "train loss:0.0002634201031715191\n",
      "train loss:0.0008428664729520999\n",
      "train loss:0.00029863557623031753\n",
      "train loss:0.003064599531512425\n",
      "train loss:0.0010424566672092605\n",
      "train loss:0.0008494525365660721\n",
      "train loss:0.0004986836537635244\n",
      "train loss:0.0008203593500103319\n",
      "train loss:0.0014276606208534733\n",
      "train loss:0.0004871014652003487\n",
      "train loss:0.0009221730547189884\n",
      "train loss:0.0009668171535187514\n",
      "train loss:0.003317297349768048\n",
      "train loss:0.001399239341441779\n",
      "train loss:0.007582536300754692\n",
      "train loss:0.005485727729051938\n",
      "train loss:0.001357211709408834\n",
      "train loss:0.001316831666508865\n",
      "train loss:0.0027736251395598993\n",
      "train loss:0.0006528454334986581\n",
      "train loss:0.0018424183443478768\n",
      "train loss:0.0008984701758643171\n",
      "train loss:0.00017132295258896413\n",
      "train loss:0.0011136368885347832\n",
      "train loss:0.0005465110977268182\n",
      "train loss:8.124808815973576e-05\n",
      "train loss:0.0010994125180541945\n",
      "train loss:0.00021456185172779186\n",
      "train loss:0.002522980913093295\n",
      "train loss:0.006670676682289747\n",
      "train loss:0.005080488912245354\n",
      "train loss:0.0015851257922736652\n",
      "train loss:0.004193595476221753\n",
      "train loss:0.0024231834014679797\n",
      "train loss:0.00559487861327125\n",
      "train loss:0.003495199687121247\n",
      "train loss:0.00015613774501968945\n",
      "train loss:0.0019696582653267736\n",
      "train loss:0.0001911666813791544\n",
      "train loss:0.00026231115094331394\n",
      "train loss:0.009185393105167161\n",
      "train loss:6.0539551989872814e-05\n",
      "train loss:0.0031027752791921775\n",
      "train loss:0.0008195500320262133\n",
      "train loss:0.00013353818137790133\n",
      "train loss:0.001180566596840702\n",
      "train loss:0.0010203330971050892\n",
      "train loss:0.001841212878722639\n",
      "train loss:0.0001566092124765102\n",
      "train loss:5.0562030400925255e-05\n",
      "train loss:0.0002559904790496469\n",
      "train loss:0.006191958398396046\n",
      "train loss:0.0004398643581201784\n",
      "train loss:0.002997867283396543\n",
      "train loss:8.919822064537377e-05\n",
      "train loss:0.0006593229805977319\n",
      "train loss:0.001994068252338956\n",
      "train loss:0.0014498183059950985\n",
      "train loss:0.00010163750901956989\n",
      "train loss:0.0018746426867772739\n",
      "train loss:0.002171972395285676\n",
      "train loss:5.181421130176015e-05\n",
      "train loss:8.245976667862969e-05\n",
      "train loss:0.0007604373581800988\n",
      "train loss:0.0003173588443829519\n",
      "train loss:0.0013938549039077064\n",
      "train loss:0.0023082496710786424\n",
      "train loss:0.0012430880039939075\n",
      "train loss:0.00021705413756945325\n",
      "train loss:0.007837924783448608\n",
      "train loss:0.0003833156863716465\n",
      "train loss:0.001643890240932035\n",
      "train loss:0.00043125925875534286\n",
      "train loss:0.0005545894189471286\n",
      "train loss:0.0013636276128656216\n",
      "train loss:0.00023381708064918944\n",
      "train loss:0.0019513621822543415\n",
      "train loss:0.012437715635470723\n",
      "train loss:0.0006879403005848794\n",
      "train loss:0.004400216381450821\n",
      "train loss:0.0002513270203086332\n",
      "train loss:0.0007810623278236602\n",
      "train loss:0.004321159500522615\n",
      "train loss:0.0008406705204370071\n",
      "train loss:0.0011004825881561389\n",
      "train loss:0.0009527385982403652\n",
      "train loss:0.004341265598883405\n",
      "train loss:0.0007635717433799232\n",
      "train loss:0.0002873191483222272\n",
      "train loss:0.0012505388686888822\n",
      "train loss:0.00015127744374914163\n",
      "train loss:0.0011731505401158637\n",
      "train loss:0.0006956509001225042\n",
      "train loss:0.0003391038391920193\n",
      "train loss:0.001634292438175447\n",
      "train loss:0.0008814301592583287\n",
      "train loss:0.004735591482791514\n",
      "train loss:0.0012473525016587557\n",
      "train loss:0.0027039597884398153\n",
      "train loss:0.00013415778096499873\n",
      "train loss:0.0016581170574672657\n",
      "train loss:0.0504773670394419\n",
      "train loss:8.1301165744357e-05\n",
      "train loss:0.010648114635753055\n",
      "train loss:0.001419563289502955\n",
      "train loss:8.912466297912307e-05\n",
      "train loss:0.0018919034033913742\n",
      "train loss:0.0008606978136012845\n",
      "train loss:0.0006254666340960497\n",
      "train loss:0.0001874386211398956\n",
      "train loss:0.0002516719255391038\n",
      "train loss:0.00945454167665846\n",
      "train loss:0.0002584830617712415\n",
      "train loss:0.00023682818820529457\n",
      "train loss:5.769037487225124e-05\n",
      "train loss:0.0007349396927962072\n",
      "train loss:0.0003694985501661033\n",
      "train loss:0.000466084768835395\n",
      "train loss:0.0014188159336277581\n",
      "train loss:0.00034063784172607125\n",
      "train loss:0.00020065823405646165\n",
      "train loss:0.002551548261666412\n",
      "train loss:0.001398009536571506\n",
      "train loss:0.0018413115050076353\n",
      "train loss:0.0011110826944708608\n",
      "train loss:1.4373776064696536e-05\n",
      "train loss:0.0011151909085977733\n",
      "train loss:0.0026213389467842426\n",
      "train loss:0.0037013672788162545\n",
      "train loss:0.001380667179809026\n",
      "train loss:0.06445628836709882\n",
      "train loss:0.0033169667793419722\n",
      "train loss:0.003930654106103874\n",
      "train loss:0.004035583118131148\n",
      "train loss:0.000905812116983137\n",
      "=== epoch:19, train acc:0.998, test acc:0.984 ===\n",
      "train loss:0.004003985432853572\n",
      "train loss:0.031536580376884366\n",
      "train loss:0.004669142128054161\n",
      "train loss:0.00018971981094981522\n",
      "train loss:0.0008416702955078045\n",
      "train loss:0.0010639944049311261\n",
      "train loss:0.0011278689530963306\n",
      "train loss:0.0034807561623048113\n",
      "train loss:0.007133077050940184\n",
      "train loss:0.002181097221033662\n",
      "train loss:0.0024089595754511564\n",
      "train loss:0.0011883393369559129\n",
      "train loss:0.002958228141129397\n",
      "train loss:0.00028414078814235184\n",
      "train loss:0.00411729723305622\n",
      "train loss:0.01145989101078945\n",
      "train loss:0.0001178497267096015\n",
      "train loss:0.0006488520867172189\n",
      "train loss:0.0020667027813926035\n",
      "train loss:0.003728145706818645\n",
      "train loss:0.007738920624104596\n",
      "train loss:0.002627634240939219\n",
      "train loss:0.0033513643869556857\n",
      "train loss:0.006070446108319631\n",
      "train loss:0.00010195310670559077\n",
      "train loss:0.0004065651158510546\n",
      "train loss:0.0003532453620690532\n",
      "train loss:0.001558756116431835\n",
      "train loss:0.0001603373676587261\n",
      "train loss:0.006561595480679019\n",
      "train loss:0.0005390330315454773\n",
      "train loss:0.0006822283811712295\n",
      "train loss:0.002247030550963503\n",
      "train loss:0.00046948948615468234\n",
      "train loss:0.0002650502938282372\n",
      "train loss:0.0015163723509054373\n",
      "train loss:0.00013869771923793767\n",
      "train loss:0.005726888866359117\n",
      "train loss:0.001987481390640575\n",
      "train loss:0.00042311971105656683\n",
      "train loss:0.00024176371882426528\n",
      "train loss:0.0031861025115325877\n",
      "train loss:0.0018220656849667013\n",
      "train loss:0.008386980467093665\n",
      "train loss:0.00016368906533824367\n",
      "train loss:0.0007239163538123848\n",
      "train loss:0.0015912032594403705\n",
      "train loss:6.958228908516103e-05\n",
      "train loss:0.01938055501621587\n",
      "train loss:0.0003745406964823904\n",
      "train loss:0.0024312458882918284\n",
      "train loss:0.00366679651565482\n",
      "train loss:0.001835071980385588\n",
      "train loss:0.001009630208241333\n",
      "train loss:0.0010920521444567023\n",
      "train loss:0.0010166769161344452\n",
      "train loss:0.000978023262885596\n",
      "train loss:0.0004388423094987347\n",
      "train loss:0.008228486223392551\n",
      "train loss:0.0024377716632050283\n",
      "train loss:0.004176045547130665\n",
      "train loss:0.010526870084838246\n",
      "train loss:0.0008541736849482878\n",
      "train loss:0.0017102180042178044\n",
      "train loss:0.0002823554320993275\n",
      "train loss:0.0016472291954880989\n",
      "train loss:0.0008301806243347084\n",
      "train loss:0.0002184137901515927\n",
      "train loss:0.002300543548439152\n",
      "train loss:0.034089371216991605\n",
      "train loss:0.00010975867700666687\n",
      "train loss:0.0015987898699313322\n",
      "train loss:0.0006104357642317982\n",
      "train loss:0.00035107573062650153\n",
      "train loss:5.710617269749576e-05\n",
      "train loss:0.004484520319949484\n",
      "train loss:0.0003836876899279978\n",
      "train loss:0.00015582334190749917\n",
      "train loss:0.002809225282517872\n",
      "train loss:0.00020286253648286459\n",
      "train loss:0.0002590093554295321\n",
      "train loss:0.0008952911411534073\n",
      "train loss:0.0004905827422960582\n",
      "train loss:0.0029990365617739456\n",
      "train loss:0.00027620202361667136\n",
      "train loss:0.0005365766939652373\n",
      "train loss:0.0027085487012329878\n",
      "train loss:5.752275805186021e-05\n",
      "train loss:0.0013199012005431735\n",
      "train loss:0.0019838979598274507\n",
      "train loss:0.0014699377276349904\n",
      "train loss:3.6430001425630645e-05\n",
      "train loss:0.00949556002283492\n",
      "train loss:0.00035696824884544115\n",
      "train loss:0.0008572127576325721\n",
      "train loss:0.00018595163652459384\n",
      "train loss:0.0011850822048941124\n",
      "train loss:0.0003306117732645933\n",
      "train loss:0.0010765948275780197\n",
      "train loss:0.002072194402810317\n",
      "train loss:0.000353432163076706\n",
      "train loss:0.001001384887755825\n",
      "train loss:0.00013923381148017377\n",
      "train loss:7.076886001966479e-05\n",
      "train loss:0.000778744056833156\n",
      "train loss:0.00173231206977045\n",
      "train loss:0.0014183597538257485\n",
      "train loss:0.0004604197903943884\n",
      "train loss:0.000911453660812407\n",
      "train loss:0.0004034377841958812\n",
      "train loss:0.0029854653373097726\n",
      "train loss:0.0009217741226842244\n",
      "train loss:0.0014256438899472243\n",
      "train loss:0.005184097097868691\n",
      "train loss:0.004255469439341225\n",
      "train loss:0.00012443879129523218\n",
      "train loss:7.623809569489618e-05\n",
      "train loss:0.0008683861689860736\n",
      "train loss:0.0016404133825767872\n",
      "train loss:7.465219756659293e-05\n",
      "train loss:0.0001403922121452781\n",
      "train loss:9.552193958682392e-05\n",
      "train loss:0.0015826676801209453\n",
      "train loss:0.00019215533673288887\n",
      "train loss:0.0004040511912003899\n",
      "train loss:0.0003254450625017938\n",
      "train loss:0.0023017213140252\n",
      "train loss:0.0012438076188642122\n",
      "train loss:0.0006234654272041889\n",
      "train loss:0.00012741642421259839\n",
      "train loss:4.3245033143765446e-05\n",
      "train loss:0.0004914279225503316\n",
      "train loss:0.0036967575835151006\n",
      "train loss:0.0056919714603639\n",
      "train loss:0.005087894687904412\n",
      "train loss:0.002908501413790781\n",
      "train loss:0.0006550902874557463\n",
      "train loss:4.224330847755193e-05\n",
      "train loss:6.712807679442371e-05\n",
      "train loss:0.0023452298561466626\n",
      "train loss:0.004639007934315793\n",
      "train loss:0.0003700932512015213\n",
      "train loss:0.0025567450864231534\n",
      "train loss:0.0010375934022998365\n",
      "train loss:0.0001406388289764014\n",
      "train loss:0.00018470958709374373\n",
      "train loss:0.00013070637915786116\n",
      "train loss:0.0014847384922012455\n",
      "train loss:0.0024161911477198904\n",
      "train loss:0.0016218175863373812\n",
      "train loss:0.0006416243448372185\n",
      "train loss:0.00018810631990487137\n",
      "train loss:0.0006723389272978005\n",
      "train loss:0.0014231045576686278\n",
      "train loss:0.001450525767938683\n",
      "train loss:0.003017756786497036\n",
      "train loss:0.008980643643767161\n",
      "train loss:0.04221922331025962\n",
      "train loss:0.0037306911418630954\n",
      "train loss:9.058600471705874e-05\n",
      "train loss:0.00021161211082862746\n",
      "train loss:0.002673661684567242\n",
      "train loss:0.0015858887544051414\n",
      "train loss:0.0015115348393082379\n",
      "train loss:0.017908100837857398\n",
      "train loss:0.005180125672450974\n",
      "train loss:0.0007165664666961825\n",
      "train loss:0.00024646487503987016\n",
      "train loss:0.004466460555840481\n",
      "train loss:0.00014688156998577667\n",
      "train loss:0.0003294887026400729\n",
      "train loss:0.0028614976587467526\n",
      "train loss:0.0036552986595805564\n",
      "train loss:0.000723930103463171\n",
      "train loss:0.0015139714662326833\n",
      "train loss:0.0036734395372834366\n",
      "train loss:0.0012990272126288133\n",
      "train loss:0.0001632470887887353\n",
      "train loss:0.005063530206444268\n",
      "train loss:0.004399791535079595\n",
      "train loss:0.001647284730643595\n",
      "train loss:0.008550238092570753\n",
      "train loss:0.0011907029632524705\n",
      "train loss:0.004427381037322941\n",
      "train loss:0.0036343503729929054\n",
      "train loss:0.0007429832872918803\n",
      "train loss:0.00013057401805817917\n",
      "train loss:0.0008571524057642871\n",
      "train loss:0.0007212257401987702\n",
      "train loss:0.0005679766231094402\n",
      "train loss:0.0020448918842796648\n",
      "train loss:0.002240810630692677\n",
      "train loss:0.002864945105362633\n",
      "train loss:0.0007336614121825251\n",
      "train loss:0.0013934607352570898\n",
      "train loss:0.003110343243053547\n",
      "train loss:0.007237505659862178\n",
      "train loss:0.002757521662801093\n",
      "train loss:0.004487131016888742\n",
      "train loss:0.0006703765811912965\n",
      "train loss:0.00208224670632886\n",
      "train loss:0.0028058172867976433\n",
      "train loss:0.0012484306584256775\n",
      "train loss:0.00019555724707129442\n",
      "train loss:0.0028736140641176886\n",
      "train loss:0.00012711263667389104\n",
      "train loss:0.0017269696363375966\n",
      "train loss:0.0014927815922047916\n",
      "train loss:0.0010763989193510006\n",
      "train loss:0.0013140371651544835\n",
      "train loss:0.004492444000216954\n",
      "train loss:0.0002744318958186964\n",
      "train loss:0.0007056761318562837\n",
      "train loss:0.006495355084420415\n",
      "train loss:0.0014651399456670575\n",
      "train loss:0.001525263493532083\n",
      "train loss:0.00020161914854605477\n",
      "train loss:0.0007207057367881053\n",
      "train loss:0.000875115502724661\n",
      "train loss:1.4290808205320518e-05\n",
      "train loss:0.0009455801984533821\n",
      "train loss:0.00032326703977259724\n",
      "train loss:0.0005678101985206672\n",
      "train loss:0.0003608831209971694\n",
      "train loss:0.005219969168194772\n",
      "train loss:0.012727218274146024\n",
      "train loss:0.0017288587724061716\n",
      "train loss:6.371680033937099e-05\n",
      "train loss:6.114580194625913e-05\n",
      "train loss:0.0023048702677717537\n",
      "train loss:0.00038142609177472836\n",
      "train loss:0.0006978286471249659\n",
      "train loss:0.0007961345281091605\n",
      "train loss:0.0007949688293972388\n",
      "train loss:4.836107910919589e-05\n",
      "train loss:0.00027258967110872437\n",
      "train loss:0.002792424988186158\n",
      "train loss:0.001597529266386637\n",
      "train loss:6.90501663898559e-05\n",
      "train loss:0.00030622037155673173\n",
      "train loss:0.0003116684116697185\n",
      "train loss:0.0003005041039904586\n",
      "train loss:0.00021225143281837958\n",
      "train loss:0.0005090275184410918\n",
      "train loss:0.00025602205475651964\n",
      "train loss:0.000332002196017414\n",
      "train loss:0.0002235128151497541\n",
      "train loss:7.536333023359057e-05\n",
      "train loss:0.0007567968845940226\n",
      "train loss:0.0005901408692876306\n",
      "train loss:0.0010080635638900527\n",
      "train loss:0.001018582232121003\n",
      "train loss:3.0289469885398075e-05\n",
      "train loss:0.0007485618107954087\n",
      "train loss:0.0011099753876437158\n",
      "train loss:0.00024069809014950306\n",
      "train loss:0.0001502641336833792\n",
      "train loss:0.0017809663613944083\n",
      "train loss:0.000493563163637241\n",
      "train loss:5.73682617948033e-05\n",
      "train loss:0.0003033006169396143\n",
      "train loss:0.0024648001290172037\n",
      "train loss:0.00020735041522059044\n",
      "train loss:0.0015209767225433546\n",
      "train loss:0.0003976583093527177\n",
      "train loss:2.729961692404492e-05\n",
      "train loss:0.0015723066506921186\n",
      "train loss:0.0018527604953455356\n",
      "train loss:0.00010111123306949303\n",
      "train loss:0.000722836686557554\n",
      "train loss:0.0005904669697961452\n",
      "train loss:0.004632204994433966\n",
      "train loss:0.000602009508813666\n",
      "train loss:0.00020898476965590994\n",
      "train loss:0.0020420463432758965\n",
      "train loss:0.00010715713218659672\n",
      "train loss:0.00018144945806436902\n",
      "train loss:0.000500681115370168\n",
      "train loss:0.00019154544582609137\n",
      "train loss:0.0017471057354568533\n",
      "train loss:0.00042245127944736115\n",
      "train loss:0.0004400020597692858\n",
      "train loss:0.0009676267094979728\n",
      "train loss:0.00021277144045157465\n",
      "train loss:0.0009389385947338479\n",
      "train loss:0.0013592877791390693\n",
      "train loss:0.003634820978188989\n",
      "train loss:0.001569883120237639\n",
      "train loss:0.0013449865060750977\n",
      "train loss:0.00015293930950717322\n",
      "train loss:0.0005599678542112653\n",
      "train loss:0.005021655481265774\n",
      "train loss:0.00015820688347690124\n",
      "train loss:0.00018572322855695122\n",
      "train loss:0.0002192936040152885\n",
      "train loss:0.0012489386770017184\n",
      "train loss:0.00019844827489954174\n",
      "train loss:0.0006850883174960828\n",
      "train loss:0.000885070393172869\n",
      "train loss:0.0015644466910122257\n",
      "train loss:0.0027475287430301465\n",
      "train loss:0.0009089961790334954\n",
      "train loss:0.0024475796361688737\n",
      "train loss:0.0007322486023262514\n",
      "train loss:0.00541796157208874\n",
      "train loss:0.0007257118382367611\n",
      "train loss:0.0002020555532953542\n",
      "train loss:0.00041443521185937054\n",
      "train loss:0.00040754869887532576\n",
      "train loss:0.004217648658463674\n",
      "train loss:0.0011672831223376553\n",
      "train loss:0.001334899879312901\n",
      "train loss:0.000258230051487917\n",
      "train loss:0.002948027378266954\n",
      "train loss:0.0017361853285378381\n",
      "train loss:0.000884439184205161\n",
      "train loss:0.0001509888348815392\n",
      "train loss:9.653355900656934e-05\n",
      "train loss:0.00014183968037015748\n",
      "train loss:9.403509755462218e-05\n",
      "train loss:0.0003448603758520731\n",
      "train loss:0.0013194276269486729\n",
      "train loss:0.0013006169277030599\n",
      "train loss:0.0009645468842823696\n",
      "train loss:0.0011976152669290758\n",
      "train loss:0.004045747424229494\n",
      "train loss:0.0012532621172276675\n",
      "train loss:0.0028772624520034635\n",
      "train loss:0.00020361307081688095\n",
      "train loss:0.00016379554841247692\n",
      "train loss:0.0005975757070785749\n",
      "train loss:0.00044054552596852175\n",
      "train loss:0.00013808560511951903\n",
      "train loss:0.0007083075862418847\n",
      "train loss:0.007693813442568837\n",
      "train loss:0.00034368624088326993\n",
      "train loss:0.0004994807272083218\n",
      "train loss:0.0013319429219908372\n",
      "train loss:0.00018441956754517385\n",
      "train loss:2.072190645728046e-05\n",
      "train loss:0.0015583456955451601\n",
      "train loss:0.00014318245029547175\n",
      "train loss:0.000552693241653658\n",
      "train loss:0.00010880143517647913\n",
      "train loss:0.00038057610686314044\n",
      "train loss:0.003088517959919414\n",
      "train loss:0.0002261619143100592\n",
      "train loss:0.0009905819221031817\n",
      "train loss:0.0001620980660935357\n",
      "train loss:0.0013858648960711748\n",
      "train loss:0.0012452048371953323\n",
      "train loss:0.001180791122611387\n",
      "train loss:0.0025734591941974\n",
      "train loss:0.0010265464857116518\n",
      "train loss:0.00033208448188961113\n",
      "train loss:0.00016233695262305185\n",
      "train loss:2.0383435220702835e-05\n",
      "train loss:0.0004863148916188064\n",
      "train loss:0.00010293747447243269\n",
      "train loss:0.0004574528461856762\n",
      "train loss:0.0021710655683675945\n",
      "train loss:0.0020237085760432083\n",
      "train loss:0.0006838181644550457\n",
      "train loss:9.244458478325522e-05\n",
      "train loss:7.556946357611064e-05\n",
      "train loss:0.005722549416508148\n",
      "train loss:0.0007739473220181835\n",
      "train loss:0.00027846106345505764\n",
      "train loss:0.002323744462453322\n",
      "train loss:0.00013384445545952\n",
      "train loss:0.00012380207264074496\n",
      "train loss:0.0019260701744839245\n",
      "train loss:9.741085198776315e-05\n",
      "train loss:0.0008389572990642577\n",
      "train loss:0.0032844492846316837\n",
      "train loss:0.003636809207769037\n",
      "train loss:0.009348735032754346\n",
      "train loss:0.002643684326175238\n",
      "train loss:7.370711597281836e-05\n",
      "train loss:0.0004811352196688391\n",
      "train loss:0.0002188455448616371\n",
      "train loss:0.00014142668801799167\n",
      "train loss:0.0006422060627112856\n",
      "train loss:0.0008273280948066291\n",
      "train loss:0.0031246207180942783\n",
      "train loss:0.002583780719475489\n",
      "train loss:0.0014505564483843195\n",
      "train loss:0.000849523762234063\n",
      "train loss:0.0023726299615075067\n",
      "train loss:0.00042146970005264915\n",
      "train loss:0.0018292942633654022\n",
      "train loss:0.006088188709423545\n",
      "train loss:0.0010678143625363129\n",
      "train loss:0.0006361066727871553\n",
      "train loss:0.0008763792027617371\n",
      "train loss:0.00020135707309669522\n",
      "train loss:0.0005726586678731689\n",
      "train loss:4.9857121761529896e-05\n",
      "train loss:0.0017938274755175312\n",
      "train loss:0.00626149677432057\n",
      "train loss:0.00042542309911726916\n",
      "train loss:0.0007105096959843979\n",
      "train loss:0.0009942515347306396\n",
      "train loss:0.0005822080304762928\n",
      "train loss:0.0008516477889538605\n",
      "train loss:0.004579512327013727\n",
      "train loss:0.0020741946986930914\n",
      "train loss:0.0022110793813596916\n",
      "train loss:0.0010664521555844796\n",
      "train loss:0.0005393684000108792\n",
      "train loss:0.0001585673866428722\n",
      "train loss:0.0036908238523913122\n",
      "train loss:0.003476063139225054\n",
      "train loss:0.00012561038229335172\n",
      "train loss:0.0008759029480848547\n",
      "train loss:0.0021411487342582114\n",
      "train loss:0.0011824158535007837\n",
      "train loss:0.0002945663449093757\n",
      "train loss:0.00024899559238624505\n",
      "train loss:0.0007416231132883276\n",
      "train loss:0.0011846392775328911\n",
      "train loss:0.00040972354294739567\n",
      "train loss:0.0008282954794564217\n",
      "train loss:0.0008161267942632083\n",
      "train loss:0.0017149293616087243\n",
      "train loss:0.002594126414163268\n",
      "train loss:0.006688148624700154\n",
      "train loss:0.0003553827127818782\n",
      "train loss:0.0014758335080315354\n",
      "train loss:0.00022308520181803983\n",
      "train loss:0.00017390963680005315\n",
      "train loss:0.003878271940110454\n",
      "train loss:0.0003644158179410223\n",
      "train loss:0.0016858968443480124\n",
      "train loss:0.0004486890393000814\n",
      "train loss:0.001066946707937217\n",
      "train loss:0.0027540619700068864\n",
      "train loss:2.769615889806549e-05\n",
      "train loss:0.0028590520490436393\n",
      "train loss:0.0003427915793867066\n",
      "train loss:0.00475922976669325\n",
      "train loss:0.0009004913414529882\n",
      "train loss:0.0021978879949381396\n",
      "train loss:0.0006628297696777333\n",
      "train loss:0.00013135751173387362\n",
      "train loss:0.0008214082546921797\n",
      "train loss:0.00014329646024495847\n",
      "train loss:0.006526647408828887\n",
      "train loss:0.003168506639802219\n",
      "train loss:0.00013956737906157822\n",
      "train loss:0.0018308894576405806\n",
      "train loss:5.4893295431514014e-05\n",
      "train loss:0.0009067877838640721\n",
      "train loss:0.0016843013960617615\n",
      "train loss:0.005196268786407335\n",
      "train loss:4.3435992619525414e-05\n",
      "train loss:0.0070158970400952736\n",
      "train loss:0.0009831926922907767\n",
      "train loss:0.003024734380114022\n",
      "train loss:0.0013490169019342295\n",
      "train loss:0.0004350975193203782\n",
      "train loss:0.0002241541828488407\n",
      "train loss:0.0015997975895529143\n",
      "train loss:0.000492765765871142\n",
      "train loss:3.928465976041418e-05\n",
      "train loss:0.0032384768379504765\n",
      "train loss:0.002348104559129701\n",
      "train loss:0.01517045817900683\n",
      "train loss:0.0010726563343055643\n",
      "train loss:9.678467455057344e-05\n",
      "train loss:0.0008447129586712751\n",
      "train loss:8.658068117554398e-05\n",
      "train loss:0.001759576395107394\n",
      "train loss:8.576232875808554e-05\n",
      "train loss:0.005074857683285564\n",
      "train loss:0.0003228403211082189\n",
      "train loss:0.0008272718975302273\n",
      "train loss:2.36560354651863e-05\n",
      "train loss:0.0005005222597607946\n",
      "train loss:0.005833006735582348\n",
      "train loss:0.014432048784840903\n",
      "train loss:0.0006516513714601137\n",
      "train loss:0.0004792879070772359\n",
      "train loss:0.00014858950856548226\n",
      "train loss:0.0002574627864344928\n",
      "train loss:0.002732468611039909\n",
      "train loss:0.0011726693842736909\n",
      "train loss:0.0003246417231795525\n",
      "train loss:0.0016605912594969139\n",
      "train loss:0.00038079624368048544\n",
      "train loss:0.002121951514766343\n",
      "train loss:0.002786036662527991\n",
      "train loss:0.00011141341011699994\n",
      "train loss:0.0020489124813535937\n",
      "train loss:0.0008757824208085914\n",
      "train loss:0.001349676088824067\n",
      "train loss:0.00016615506975277978\n",
      "train loss:0.003641854699195431\n",
      "train loss:0.0004896417399004786\n",
      "train loss:0.0011300250812492718\n",
      "train loss:0.002194786651491277\n",
      "train loss:0.023177757516385386\n",
      "train loss:0.00015544737174356493\n",
      "train loss:0.002078761785691434\n",
      "train loss:1.8517258854161012e-05\n",
      "train loss:0.0017202199575442245\n",
      "train loss:0.000632229637448742\n",
      "train loss:0.0003083654551747858\n",
      "train loss:0.0014013416976967935\n",
      "train loss:0.0019874456079673063\n",
      "train loss:0.0009664424478272629\n",
      "train loss:0.001912915173451197\n",
      "train loss:9.780361801615892e-05\n",
      "train loss:0.0009317108272565764\n",
      "train loss:2.6374053285494278e-05\n",
      "train loss:0.0029984705199035283\n",
      "train loss:0.0013668289799818065\n",
      "train loss:0.0012262888232528414\n",
      "train loss:0.0025998120525999556\n",
      "train loss:0.00017649073500877066\n",
      "train loss:0.0013608421305876272\n",
      "train loss:0.00010074048407239868\n",
      "train loss:0.0008548301292724621\n",
      "train loss:0.0027675029782633725\n",
      "train loss:0.0019550623115388178\n",
      "train loss:0.003126266884377688\n",
      "train loss:0.00035400678957894246\n",
      "train loss:0.00011902418640996143\n",
      "train loss:0.0010421469319984767\n",
      "train loss:0.0007519741248046577\n",
      "train loss:0.000601609897245588\n",
      "train loss:2.7368532448421466e-05\n",
      "train loss:0.00025008337269550094\n",
      "train loss:0.0023549229936839326\n",
      "train loss:0.0013620085399375717\n",
      "train loss:0.0007446008050393431\n",
      "train loss:0.0023628606958500035\n",
      "train loss:0.0010905027257172323\n",
      "train loss:0.0036753528929639573\n",
      "train loss:0.0012029659752616883\n",
      "train loss:0.00021132705431212818\n",
      "train loss:2.453101462251447e-05\n",
      "train loss:0.0006543441925026907\n",
      "train loss:0.00023808888241045966\n",
      "train loss:0.0001668274293071164\n",
      "train loss:2.0700824464227034e-05\n",
      "train loss:0.00015548275921324156\n",
      "train loss:0.00015507685058195017\n",
      "train loss:0.00015101827369309753\n",
      "train loss:0.0004154056094863534\n",
      "train loss:0.0018509928539702832\n",
      "train loss:0.0007658772242638768\n",
      "train loss:0.0002166907126951192\n",
      "train loss:0.0004624738258672044\n",
      "train loss:4.966379619352194e-05\n",
      "train loss:0.0008057905978213644\n",
      "train loss:0.0036670282021354383\n",
      "train loss:0.0006910545605389549\n",
      "train loss:0.0012473821204828262\n",
      "train loss:0.00015158336478338953\n",
      "train loss:0.000802009945690687\n",
      "train loss:0.003204378593805326\n",
      "train loss:3.7920503856103056e-05\n",
      "train loss:5.3151736105960725e-05\n",
      "train loss:0.0003735173257125874\n",
      "train loss:0.0005714355700201444\n",
      "train loss:0.002903740261359707\n",
      "train loss:5.345809697567075e-06\n",
      "train loss:0.0010878156432691179\n",
      "train loss:0.00010404708582663686\n",
      "train loss:0.0007476318056019262\n",
      "train loss:0.0007902922833137488\n",
      "train loss:0.0001785713067096734\n",
      "train loss:0.000802621479846805\n",
      "train loss:0.0005246616743943034\n",
      "train loss:0.0027947517484711248\n",
      "train loss:0.003142245217502904\n",
      "train loss:0.00037825357662677557\n",
      "train loss:0.0016520346977029585\n",
      "train loss:5.4029990423300537e-05\n",
      "train loss:0.00018021817620512894\n",
      "train loss:0.00030904142322138597\n",
      "train loss:0.00016873328385702088\n",
      "train loss:0.0007449447588861438\n",
      "train loss:0.00010466491376788139\n",
      "train loss:0.0006056565788757141\n",
      "train loss:0.00017006345660604087\n",
      "train loss:0.00017786119726351135\n",
      "train loss:0.0005772491525149521\n",
      "train loss:0.0005064331123484525\n",
      "train loss:0.0037073961296780426\n",
      "train loss:0.002628204007706452\n",
      "train loss:0.0015762742666064128\n",
      "train loss:0.0027756772872619107\n",
      "train loss:7.886494784124985e-05\n",
      "train loss:0.0004616792074324007\n",
      "train loss:0.0015510046746069906\n",
      "train loss:0.0006151558722069845\n",
      "train loss:0.00020688334936887372\n",
      "train loss:7.036020044057928e-05\n",
      "=== epoch:20, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.00023587432250617938\n",
      "train loss:0.0021056996011407873\n",
      "train loss:0.0029842801436243517\n",
      "train loss:0.00017756776813196578\n",
      "train loss:0.0004863907867334597\n",
      "train loss:0.0009658832375657906\n",
      "train loss:0.0005783123913188828\n",
      "train loss:5.703318399216608e-05\n",
      "train loss:0.0029024867312906592\n",
      "train loss:0.0006281041568763247\n",
      "train loss:0.0013543135309436144\n",
      "train loss:0.00194073315057385\n",
      "train loss:0.00042786077299738427\n",
      "train loss:0.004733551433085932\n",
      "train loss:0.0005176728798141147\n",
      "train loss:0.0003266981993917329\n",
      "train loss:0.0020067380430391236\n",
      "train loss:0.0002760118528611467\n",
      "train loss:0.0010571817687688172\n",
      "train loss:0.002616873186410683\n",
      "train loss:0.0009695536156379715\n",
      "train loss:0.0008511237066530874\n",
      "train loss:0.002308606975344121\n",
      "train loss:0.002324982792328424\n",
      "train loss:0.00020742606898214303\n",
      "train loss:0.00035525332645867003\n",
      "train loss:4.708250922496644e-05\n",
      "train loss:0.0039002680568117495\n",
      "train loss:0.000303665156198525\n",
      "train loss:0.0011905999937457748\n",
      "train loss:0.0019175047682786126\n",
      "train loss:0.0005051246163112226\n",
      "train loss:0.010247676185971671\n",
      "train loss:5.644428974739016e-05\n",
      "train loss:0.001977507204086372\n",
      "train loss:0.00038239195638133897\n",
      "train loss:0.00011630078221468793\n",
      "train loss:0.0012207184326478407\n",
      "train loss:0.0010078098195018767\n",
      "train loss:0.0008420619335979466\n",
      "train loss:0.0038845029327998475\n",
      "train loss:0.00040968827319798383\n",
      "train loss:0.0002897123602858346\n",
      "train loss:0.0006103108414430978\n",
      "train loss:0.0008836449527857609\n",
      "train loss:0.0003662513473611927\n",
      "train loss:0.00021139781955477986\n",
      "train loss:0.00018906288751732313\n",
      "train loss:0.00033128600087227044\n",
      "train loss:0.00013299189402037667\n",
      "train loss:0.0009951052405225776\n",
      "train loss:0.0006022730687881843\n",
      "train loss:0.0012337830629932658\n",
      "train loss:0.0001886546103633772\n",
      "train loss:5.8737629494000996e-05\n",
      "train loss:0.001794030491063201\n",
      "train loss:0.0032238218129432405\n",
      "train loss:0.006064079986546769\n",
      "train loss:0.0003413936048601927\n",
      "train loss:0.00019935761430214357\n",
      "train loss:0.005087026086288627\n",
      "train loss:0.0010874003379367017\n",
      "train loss:0.0018707907620400246\n",
      "train loss:0.000769462574212405\n",
      "train loss:0.0025686477532314727\n",
      "train loss:7.52244207954118e-05\n",
      "train loss:0.0011820095486150726\n",
      "train loss:0.00029393325562505863\n",
      "train loss:8.140159191996059e-05\n",
      "train loss:0.003262854119552792\n",
      "train loss:9.950979734507251e-05\n",
      "train loss:0.00023264538997415433\n",
      "train loss:0.00022508443521327475\n",
      "train loss:0.0007514804411638648\n",
      "train loss:1.5061823842785816e-05\n",
      "train loss:0.0011195828590016379\n",
      "train loss:0.008995831232336063\n",
      "train loss:0.0016214977980547865\n",
      "train loss:0.002206183111001556\n",
      "train loss:0.00019069424436667649\n",
      "train loss:0.00019316007576065944\n",
      "train loss:4.722132618606204e-05\n",
      "train loss:0.0006560524201178228\n",
      "train loss:0.0048402499315972096\n",
      "train loss:0.0004869223236661145\n",
      "train loss:0.004771192163659208\n",
      "train loss:5.8725227600563e-05\n",
      "train loss:6.052768972586694e-06\n",
      "train loss:0.0017706151778826304\n",
      "train loss:0.0002790279389804271\n",
      "train loss:0.00026852999040994\n",
      "train loss:0.000356002072991234\n",
      "train loss:0.00199015768516646\n",
      "train loss:0.00010552693444547954\n",
      "train loss:1.0413212997102427e-05\n",
      "train loss:0.0001539502302756169\n",
      "train loss:0.00033108266065431843\n",
      "train loss:5.91546935341537e-05\n",
      "train loss:0.0006443327901677744\n",
      "train loss:3.694636000524953e-05\n",
      "train loss:0.0015176585925123717\n",
      "train loss:0.00029077721683118163\n",
      "train loss:0.00017711435694917988\n",
      "train loss:0.0010289315530920553\n",
      "train loss:0.0015158674326928101\n",
      "train loss:0.0002489663605783724\n",
      "train loss:0.00047494078534359574\n",
      "train loss:0.000340135055462863\n",
      "train loss:0.00034095425100578536\n",
      "train loss:0.00031128981413317366\n",
      "train loss:0.00046395396780894965\n",
      "train loss:0.0003287998525032935\n",
      "train loss:0.0020540108245887608\n",
      "train loss:0.0003039588206107389\n",
      "train loss:0.00016703005302573268\n",
      "train loss:0.000790983555583195\n",
      "train loss:0.006562119512025668\n",
      "train loss:0.00032911978281403224\n",
      "train loss:0.0007710260500490418\n",
      "train loss:0.0007632558581402745\n",
      "train loss:0.0019341791620546196\n",
      "train loss:0.007497530362391695\n",
      "train loss:0.0009426124538541182\n",
      "train loss:0.0017220501304987378\n",
      "train loss:0.000492972882247346\n",
      "train loss:3.059281298233233e-05\n",
      "train loss:0.0013803306154771175\n",
      "train loss:0.00018101155013596865\n",
      "train loss:0.00012792286640222764\n",
      "train loss:0.0005808240148612219\n",
      "train loss:0.00023011527106860786\n",
      "train loss:0.0025981569489526924\n",
      "train loss:0.00042105374003675714\n",
      "train loss:0.00016447079316761956\n",
      "train loss:9.979148929409021e-05\n",
      "train loss:0.0011391122690892562\n",
      "train loss:0.0018394952835369442\n",
      "train loss:0.009120584421618498\n",
      "train loss:0.0002472521475628656\n",
      "train loss:0.000871046947993275\n",
      "train loss:0.0013470592045259659\n",
      "train loss:0.0008013287222057268\n",
      "train loss:7.902407146995019e-06\n",
      "train loss:0.0025387825224706044\n",
      "train loss:0.00016596564914436545\n",
      "train loss:0.00012329233602261303\n",
      "train loss:5.148640584815699e-05\n",
      "train loss:0.0037314670822875934\n",
      "train loss:0.0006605048317695686\n",
      "train loss:0.0011236244009233474\n",
      "train loss:0.0019002146100232217\n",
      "train loss:0.001941015807459892\n",
      "train loss:0.0014369174934103389\n",
      "train loss:5.8872802906191025e-05\n",
      "train loss:0.0004734934065783718\n",
      "train loss:7.765756913642139e-05\n",
      "train loss:6.343170440856713e-05\n",
      "train loss:0.002272487019286051\n",
      "train loss:0.00010562796502992665\n",
      "train loss:1.0880264828003566e-05\n",
      "train loss:0.00019624805611115868\n",
      "train loss:0.0012964839126238406\n",
      "train loss:0.0022928746684101713\n",
      "train loss:7.895499970319906e-05\n",
      "train loss:4.8895876922794835e-05\n",
      "train loss:0.0013902620851836975\n",
      "train loss:0.0014914798243320928\n",
      "train loss:0.00470829248611905\n",
      "train loss:7.909938522302858e-05\n",
      "train loss:0.002761886473336655\n",
      "train loss:0.0010875147134069164\n",
      "train loss:0.000635514836884431\n",
      "train loss:0.0009022386496070801\n",
      "train loss:0.0031235811157222806\n",
      "train loss:0.002474139906454889\n",
      "train loss:0.0017369507388329012\n",
      "train loss:0.0007901756129648218\n",
      "train loss:0.0038213127191139636\n",
      "train loss:0.0009193342391304485\n",
      "train loss:0.000358075442379381\n",
      "train loss:0.007828156756914988\n",
      "train loss:0.00033053682932527044\n",
      "train loss:0.0002720175059250463\n",
      "train loss:0.000569526433035334\n",
      "train loss:0.00013515075009777388\n",
      "train loss:0.0011416350664452256\n",
      "train loss:0.005125265013668864\n",
      "train loss:0.007110343747847294\n",
      "train loss:0.0006401544592226168\n",
      "train loss:0.001992370513142757\n",
      "train loss:0.004486265606364994\n",
      "train loss:0.0043979370669363586\n",
      "train loss:0.011695420252750418\n",
      "train loss:0.00040739007451246883\n",
      "train loss:0.0001743324216626944\n",
      "train loss:0.0003428705115415108\n",
      "train loss:0.0012113997852225026\n",
      "train loss:0.00328148488857465\n",
      "train loss:0.0014235686904158756\n",
      "train loss:4.1859766256495755e-05\n",
      "train loss:0.0036965612884562672\n",
      "train loss:0.0008411849786090542\n",
      "train loss:0.0037711463434131117\n",
      "train loss:0.0029189481847064257\n",
      "train loss:0.0010819887555114107\n",
      "train loss:0.0002633404566553487\n",
      "train loss:7.191327953759918e-05\n",
      "train loss:0.0014719993242166807\n",
      "train loss:0.00046453736244343816\n",
      "train loss:0.0018685123719656752\n",
      "train loss:0.003875367975188918\n",
      "train loss:0.003126370573428661\n",
      "train loss:0.00043629568754163946\n",
      "train loss:0.0009351205159096024\n",
      "train loss:0.0031153205157553676\n",
      "train loss:0.008237981128719651\n",
      "train loss:0.000671880901949658\n",
      "train loss:0.016798468544543334\n",
      "train loss:0.010027834685902771\n",
      "train loss:0.0003408063739833869\n",
      "train loss:0.0016702983860005644\n",
      "train loss:9.553674309506065e-05\n",
      "train loss:0.0014358595503650776\n",
      "train loss:0.0008397692839723519\n",
      "train loss:0.0005313764982425215\n",
      "train loss:0.0006948263900677026\n",
      "train loss:0.0016566493861219097\n",
      "train loss:0.00122634577641548\n",
      "train loss:0.001014672191825908\n",
      "train loss:0.0005533087967452601\n",
      "train loss:0.052513206504273234\n",
      "train loss:0.0018076730268523295\n",
      "train loss:0.0009231248100304103\n",
      "train loss:0.003196168407124701\n",
      "train loss:0.00010197665644732137\n",
      "train loss:5.900480247310062e-05\n",
      "train loss:0.0013238896535953495\n",
      "train loss:0.0028619528587917734\n",
      "train loss:0.0021416901982152015\n",
      "train loss:0.0011915133213948586\n",
      "train loss:0.016723238669936368\n",
      "train loss:0.005729730887719582\n",
      "train loss:0.00010322889281184928\n",
      "train loss:0.0003103573850564975\n",
      "train loss:0.00258834476650615\n",
      "train loss:0.00044807086431726117\n",
      "train loss:0.0006120819785963193\n",
      "train loss:0.003995660965017291\n",
      "train loss:0.0001552254460455842\n",
      "train loss:0.003514208419953147\n",
      "train loss:0.009942371177641119\n",
      "train loss:0.0007262174963841886\n",
      "train loss:0.004284136002921918\n",
      "train loss:0.0034397392369985473\n",
      "train loss:0.0014274347158139999\n",
      "train loss:0.011380004654976794\n",
      "train loss:0.010994771787484188\n",
      "train loss:0.0018382829495211103\n",
      "train loss:0.0018355101972648926\n",
      "train loss:0.00048081875887349393\n",
      "train loss:0.004657281429478954\n",
      "train loss:0.00130325646505105\n",
      "train loss:0.007388633490040663\n",
      "train loss:0.0008137959870479396\n",
      "train loss:0.0009149613162192774\n",
      "train loss:0.00022555609732787272\n",
      "train loss:0.000568726126448442\n",
      "train loss:0.0005604272969729098\n",
      "train loss:0.0002093448316309098\n",
      "train loss:0.008201506415018746\n",
      "train loss:0.004349277572773054\n",
      "train loss:0.0005410705940779642\n",
      "train loss:0.0016674279947051411\n",
      "train loss:0.0005534386887159785\n",
      "train loss:0.00010424033139819637\n",
      "train loss:0.0020900550433238267\n",
      "train loss:0.0013710123810788727\n",
      "train loss:0.002219214590759054\n",
      "train loss:0.004680038558232657\n",
      "train loss:0.004067652966947047\n",
      "train loss:0.0006210418613815581\n",
      "train loss:0.006339345178954539\n",
      "train loss:0.0013479676455264373\n",
      "train loss:0.0007160746469525245\n",
      "train loss:0.00010090601664423101\n",
      "train loss:0.0006844791814872793\n",
      "train loss:0.0005453082518029446\n",
      "train loss:0.0023426975418294462\n",
      "train loss:0.00711635965306938\n",
      "train loss:0.000285143087725588\n",
      "train loss:0.0003797899346318245\n",
      "train loss:0.002032280812361992\n",
      "train loss:0.0032249338799477\n",
      "train loss:0.00015524352293445453\n",
      "train loss:0.0015969677842490272\n",
      "train loss:0.0007994986022808874\n",
      "train loss:0.00020740687013111426\n",
      "train loss:0.00037454792562957687\n",
      "train loss:0.003248030492531154\n",
      "train loss:0.007353713744396823\n",
      "train loss:0.00021725729631486774\n",
      "train loss:0.0004343271215075384\n",
      "train loss:0.0002251940870249916\n",
      "train loss:0.006745591636866034\n",
      "train loss:0.004347444487804137\n",
      "train loss:0.0018443407987528842\n",
      "train loss:0.0037996373893155718\n",
      "train loss:0.00623184538581129\n",
      "train loss:0.001387804163927497\n",
      "train loss:0.001393961341346165\n",
      "train loss:0.0007883011878365465\n",
      "train loss:7.787090211389346e-05\n",
      "train loss:0.0025252166211231237\n",
      "train loss:0.00038668514404889445\n",
      "train loss:0.002515256195236018\n",
      "train loss:0.004244390655080021\n",
      "train loss:0.0016480577081009675\n",
      "train loss:0.0003977907338414797\n",
      "train loss:0.0006705689884689346\n",
      "train loss:0.0006820376505424731\n",
      "train loss:0.0018830707353207476\n",
      "train loss:0.00047209748393634737\n",
      "train loss:0.016750950381985156\n",
      "train loss:0.0036274678491340045\n",
      "train loss:0.00015042515780851063\n",
      "train loss:0.001343636677531464\n",
      "train loss:0.00019724239556007713\n",
      "train loss:0.00021588253836531173\n",
      "train loss:5.4634719775285366e-05\n",
      "train loss:0.0002056734762554795\n",
      "train loss:0.0004256665815210503\n",
      "train loss:0.0010258379262784285\n",
      "train loss:0.001599098650730916\n",
      "train loss:0.005596610283038733\n",
      "train loss:0.0024990322830591985\n",
      "train loss:0.0004741193205814929\n",
      "train loss:0.0001456898387761137\n",
      "train loss:0.0007333343421710699\n",
      "train loss:0.00012743365789223956\n",
      "train loss:0.0015193306061482843\n",
      "train loss:0.0008637813104751893\n",
      "train loss:0.003192187880839997\n",
      "train loss:0.005482584386085027\n",
      "train loss:0.01083330843009527\n",
      "train loss:0.0013569683546723146\n",
      "train loss:3.15164107049759e-05\n",
      "train loss:0.0002978429631042567\n",
      "train loss:0.0038006912251273527\n",
      "train loss:1.558650333291234e-05\n",
      "train loss:0.00011319154345476563\n",
      "train loss:0.000773594925398557\n",
      "train loss:0.0008882151931845062\n",
      "train loss:0.001296907003279713\n",
      "train loss:0.00027832000851936043\n",
      "train loss:0.0001528087191345686\n",
      "train loss:0.0003818832972747973\n",
      "train loss:0.002789894480516461\n",
      "train loss:0.0008547279774981466\n",
      "train loss:0.00017656866196795565\n",
      "train loss:0.00046047585857041226\n",
      "train loss:0.0006495175401006972\n",
      "train loss:1.723068537636744e-05\n",
      "train loss:0.0035538744033752905\n",
      "train loss:0.0002997585058146237\n",
      "train loss:0.001250687441765019\n",
      "train loss:0.002480149717358329\n",
      "train loss:0.0005627696695549003\n",
      "train loss:0.0038148053186846005\n",
      "train loss:0.0028415013975873846\n",
      "train loss:2.51037412430565e-05\n",
      "train loss:0.0008064894313886833\n",
      "train loss:0.03665778275894124\n",
      "train loss:0.0017800404035684398\n",
      "train loss:0.00033526117222233183\n",
      "train loss:7.024437335998856e-05\n",
      "train loss:0.0015183174477666566\n",
      "train loss:0.0003127814672210336\n",
      "train loss:0.0001613730680848033\n",
      "train loss:0.0035735428017887494\n",
      "train loss:0.0033879385626836593\n",
      "train loss:7.394587446457012e-05\n",
      "train loss:2.497042197051887e-05\n",
      "train loss:0.0004078848891633097\n",
      "train loss:6.721902322666741e-05\n",
      "train loss:0.00019077709291876382\n",
      "train loss:0.005733380022369312\n",
      "train loss:0.002806083594710089\n",
      "train loss:0.0015027737981060988\n",
      "train loss:6.987841147889697e-05\n",
      "train loss:0.0005951574036680115\n",
      "train loss:0.0004009246228897838\n",
      "train loss:0.0006095664994285924\n",
      "train loss:0.002651792053220868\n",
      "train loss:0.0018618983487533392\n",
      "train loss:0.0001986821277535393\n",
      "train loss:0.003851720112636651\n",
      "train loss:0.0003668792955798842\n",
      "train loss:0.001284493580603692\n",
      "train loss:8.838978786823521e-05\n",
      "train loss:0.001447225602632034\n",
      "train loss:0.0015497988998462917\n",
      "train loss:0.0024046673896969263\n",
      "train loss:0.0007906888826195059\n",
      "train loss:9.084081809379493e-05\n",
      "train loss:0.00018546697039265733\n",
      "train loss:0.006549243178339763\n",
      "train loss:0.0025733003900911392\n",
      "train loss:9.821837367603967e-05\n",
      "train loss:0.00011564125150597308\n",
      "train loss:0.004623884513398201\n",
      "train loss:0.001379248381517077\n",
      "train loss:0.0014309530128479076\n",
      "train loss:0.0001612064334571227\n",
      "train loss:0.00012890488673010002\n",
      "train loss:0.0003779543926410236\n",
      "train loss:0.0014269333092409673\n",
      "train loss:0.0003932160816475643\n",
      "train loss:0.0009680625829218111\n",
      "train loss:0.003040813219861266\n",
      "train loss:0.00023915340740723176\n",
      "train loss:0.0010357061411811605\n",
      "train loss:0.00019045527201185322\n",
      "train loss:0.0015886954239722442\n",
      "train loss:0.0005641474541666429\n",
      "train loss:0.0005943686556645036\n",
      "train loss:0.0006243809522472085\n",
      "train loss:6.397788056670411e-05\n",
      "train loss:0.0010447306922241213\n",
      "train loss:0.0005298949264336488\n",
      "train loss:0.0007652023190331785\n",
      "train loss:0.002244503297761968\n",
      "train loss:0.0009172139067202093\n",
      "train loss:6.735467836974087e-05\n",
      "train loss:7.820544490846998e-05\n",
      "train loss:0.007923273511528633\n",
      "train loss:0.00013530361893295662\n",
      "train loss:0.000225862600339582\n",
      "train loss:0.0019002111751783308\n",
      "train loss:0.0003800661478749624\n",
      "train loss:2.4341365144689417e-05\n",
      "train loss:0.0013440155982979974\n",
      "train loss:0.0012042682269575644\n",
      "train loss:0.00029808769175019146\n",
      "train loss:0.0033674587128720555\n",
      "train loss:0.00204014152496737\n",
      "train loss:0.000708806045583276\n",
      "train loss:0.0029872749341952644\n",
      "train loss:0.004455380034494909\n",
      "train loss:0.0016104337752025693\n",
      "train loss:0.0004181630259241016\n",
      "train loss:0.00032729813225458354\n",
      "train loss:0.00014894322280511357\n",
      "train loss:0.049442902596073764\n",
      "train loss:0.0007526427920331788\n",
      "train loss:0.0027520006827893235\n",
      "train loss:0.002744638118702631\n",
      "train loss:0.00041751653745435033\n",
      "train loss:0.0009777301555956178\n",
      "train loss:0.0009727165836353137\n",
      "train loss:3.2819902680352624e-05\n",
      "train loss:1.604631023381517e-05\n",
      "train loss:7.345787198810997e-05\n",
      "train loss:0.0004036714585989835\n",
      "train loss:0.0004889598770139376\n",
      "train loss:0.0006494105775593927\n",
      "train loss:2.8093133945663284e-05\n",
      "train loss:0.0008216037008375704\n",
      "train loss:0.00041835585707281347\n",
      "train loss:0.0006722383424516102\n",
      "train loss:0.0006863050769957095\n",
      "train loss:0.0006437846077915566\n",
      "train loss:0.000126336908830989\n",
      "train loss:0.002282593983076049\n",
      "train loss:0.000128342627208246\n",
      "train loss:0.0001233131854855705\n",
      "train loss:0.0002847770921014872\n",
      "train loss:5.04715341782807e-05\n",
      "train loss:6.704279225679506e-06\n",
      "train loss:2.9745639829475413e-05\n",
      "train loss:0.0007614513676425909\n",
      "train loss:0.0017478135248758344\n",
      "train loss:0.00058862768110357\n",
      "train loss:0.0016272911383646241\n",
      "train loss:9.073900587063624e-05\n",
      "train loss:0.0008613591803993398\n",
      "train loss:0.00013586422731817508\n",
      "train loss:9.326755994325313e-05\n",
      "train loss:0.0006146554431513508\n",
      "train loss:5.9685596309607136e-05\n",
      "train loss:0.0039793379031369\n",
      "train loss:0.003043521005627902\n",
      "train loss:8.681137719833511e-05\n",
      "train loss:0.00016139868585181072\n",
      "train loss:0.0009504884765617105\n",
      "train loss:0.002992206207038273\n",
      "train loss:0.001227109817136694\n",
      "train loss:0.0007085790110386604\n",
      "train loss:0.0003212047895329772\n",
      "train loss:0.00017282986719199591\n",
      "train loss:0.005173016027898949\n",
      "train loss:0.02610832278895493\n",
      "train loss:5.274129513872689e-05\n",
      "train loss:7.908099097670022e-05\n",
      "train loss:0.0027456280039700643\n",
      "train loss:0.00240745864804095\n",
      "train loss:0.0008467301862241098\n",
      "train loss:0.0006044373100184894\n",
      "train loss:0.00033167993325176713\n",
      "train loss:0.0014978322485953944\n",
      "train loss:0.0018540671149394209\n",
      "train loss:0.0008564318011551441\n",
      "train loss:0.003430479870932411\n",
      "train loss:0.008804714577847247\n",
      "train loss:0.00024986957959894816\n",
      "train loss:2.6495576906132986e-05\n",
      "train loss:2.899380946912686e-05\n",
      "train loss:0.0010383772482792674\n",
      "train loss:5.851865160728651e-05\n",
      "train loss:0.0011519503333472403\n",
      "train loss:0.0059825827159160315\n",
      "train loss:0.0011115885745616378\n",
      "train loss:0.010846466492006837\n",
      "train loss:0.007428914695279451\n",
      "train loss:0.0009751799579566039\n",
      "train loss:0.00044396732470227876\n",
      "train loss:0.00027191003526986205\n",
      "train loss:0.0001715088686861812\n",
      "train loss:3.5872039125703984e-05\n",
      "train loss:0.0023254515193985763\n",
      "train loss:0.001726541392053288\n",
      "train loss:0.0018299592712624597\n",
      "train loss:0.0001813979144062602\n",
      "train loss:6.258275127880213e-05\n",
      "train loss:0.00464910120934933\n",
      "train loss:0.004040006061745521\n",
      "train loss:0.0017569771832364994\n",
      "train loss:0.010421543230011446\n",
      "train loss:6.64836654049303e-05\n",
      "train loss:0.0006954576786594297\n",
      "train loss:0.000340325685653243\n",
      "train loss:0.0008663314016461424\n",
      "train loss:0.00040843211751759724\n",
      "train loss:0.00040530321858645447\n",
      "train loss:0.00017725000197447513\n",
      "train loss:1.1027259794982906e-05\n",
      "train loss:0.0009326430937724133\n",
      "train loss:0.00027804159836375994\n",
      "train loss:0.006847982659984464\n",
      "train loss:0.00011702664712406179\n",
      "train loss:0.0007053636596407538\n",
      "train loss:0.00012820078220996002\n",
      "train loss:0.004513903469612663\n",
      "train loss:0.003255879900599741\n",
      "train loss:3.6454938988074016e-05\n",
      "train loss:0.0004912941588547531\n",
      "train loss:0.00045845447410156564\n",
      "train loss:0.00017757997041969068\n",
      "train loss:0.0029659528139204263\n",
      "train loss:0.0022423316466444877\n",
      "train loss:0.00010165673605825585\n",
      "train loss:3.180479914057914e-05\n",
      "train loss:0.00014523525536426358\n",
      "train loss:0.004338663938739483\n",
      "train loss:6.462215011176065e-05\n",
      "train loss:0.001661025289442986\n",
      "train loss:0.0001952421123091356\n",
      "train loss:0.00032967058183805035\n",
      "train loss:0.0005226093560539258\n",
      "train loss:0.0018393626374828061\n",
      "train loss:0.0019638529818336945\n",
      "train loss:0.00030505510324620926\n",
      "train loss:0.0050438984661770395\n",
      "train loss:0.00029501309391604844\n",
      "train loss:9.902186110676518e-05\n",
      "train loss:0.003130773790885557\n",
      "train loss:0.0020720492618114946\n",
      "train loss:0.0010347720748262509\n",
      "train loss:0.002163641344843567\n",
      "train loss:0.023966403710891104\n",
      "train loss:0.0017433582551626603\n",
      "train loss:0.003904212165055348\n",
      "train loss:3.117009718499548e-05\n",
      "train loss:0.000894283837185732\n",
      "train loss:0.003619498719457444\n",
      "train loss:0.0011059523849573838\n",
      "train loss:0.0008636650851852148\n",
      "train loss:0.02715520200086109\n",
      "train loss:7.116909217722838e-06\n",
      "train loss:0.0003441423339903798\n",
      "train loss:0.006006730752261894\n",
      "train loss:0.0007990978339861293\n",
      "train loss:0.0002551621735137155\n",
      "train loss:0.00027915570548791066\n",
      "train loss:0.0013338320964910685\n",
      "train loss:0.00047053053644673543\n",
      "train loss:0.0005373373602104979\n",
      "train loss:0.00011301480308123466\n",
      "train loss:0.005314007892974717\n",
      "train loss:0.00011278543765652223\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9883\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
